we_have_moved_the_main_AE_pages Description 1
Description Managing_the_configuration_files 2
Description Setup_for_Google_Cloud_Instances 2
Description System_dependencies 2
Description Set_up 2
Description Download_the_needed_files 2
Packed_data Running_the_model 32
Example_2 Description_of_how_the_=results_text.tar.gz=_file_was_prepared 37
Requirements 2._Directions 128
Requirements Quick_Start_Guide 1
Requirements Steps_to_download_data 2
Steps_to_download_data =dev-clean-wav/=_*_=dev-other-wav/=_*_=test-clean-wav/=_* 39
Steps_to_download_data Steps_to_launch_training 3
NVIDIA_DGX_A100_(single_node) Alternative_launch_with_nvidia-docker 33
Alternative_launch_with_nvidia-docker Steps_to_launch_training_on_multiple_nodes 26
Alternative_launch_with_nvidia-docker 3._Dataset/Environment 32
Hyperparameter_settings 3._Dataset/Environment 39
Hyperparameter_settings 3._Quality 27
Hyperparameter_settings Dataset/Environment 38
Test_data_order 4._Model 46
Test_data_order 3._Model 2
Loss_function 5._Quality 37
Loss_function Submission_functions 1
Publication/Attribution 2._Directions 29
Publication/Attribution Quality 38
Publication/Attribution 5._Quality 6
The_MLPerf_Subset Model 38
=--opt-level=_=O1=_and_=O2=_both_use_dynamic_loss_scaling_by Summary 11
Summary =generate_final_report.py= 4
Summary =pack_submission.sh=_(Deprecated) 4
Summary =repository_checks.sh= 4
Summary MLPerf_inference_-_Python_-_ResNet50_FP32_-_ImageNet_-_TVM_-_CPU_- 2
Summary The_next_steps 4
Summary MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_ONNX_- 2
Summary MLPerf_inference_-_C++_-_RetinaNet_FP32_-_Open_Images_-_ONNX_-_GPU_- 2
Summary MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_PyTorch_- 2
training*_below_for_more_detail) =--opt-level_O2=_("Almost_FP16"_mixed_precision._More_dangerous 11
=--opt-level_O2=_("Almost_FP16"_mixed_precision._More_dangerous Distributed_training 11
Distributed_training Expected_Output(s) 1
 Currently,_the_non-=-devel=_images_on_Pytorch_Dockerhub_do 11
  200
 Fixing_INVALID_results 6
 Tuning_parameters_for_better_performance 31
 you_run_into_issues,_invalid_results,_or_would_like_to_improve_your 31
 Model 3
 Steps_to_do_calibration_for_RNNT 1
 Steps_to_run_RNNT 5
 (optional)_>=_8.4_GA 1
 License 1
 FileSet 1
 RecordSet 1
 Field 1
 DataSource 1
 extract 1
 fileProperty 1
 JSON_Text_that_matches_the_fields_of_the_=RecordSet=. 1
 Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s 1
 Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s 1
 CK_based_object_detection_DSE 2
 Notes 2
 Recap 2
 Rules 1
 Known_Issues 1
 stopping*__under_the_new_rules,_/min_query_count/_is_no_longer_a 75
 Steps_to_run_RNN-T_with_three_options 32
 Steps_to_run_GPT-J 1
 Steps_to_calibrate_GPT-J 1
 Download_the_COCO_training_dataset 1
 Unit-tests 2
 ImageNet_validation_dataset_(required_for_calibration) 1
 Data_ 2
 logger* 2
 Customize_the_Training 1
 Running_multiple_experiments_(optional) 1
 Pose_estimation 2
 Image_segmentation 2
 Smart_reply 2
 is_an 2
 Known_problems 2
 on_model_validation* 1
 Build_the_markdown_documentation 1
 POC_2_-_Pancreas_Segmentation 1
 POC_3_-_Surgical_Workflow_Phase_Recognition 1
 POC_4_-_Cloud_Experiments 1
 How_to_Use_MedPerf 1
 Dependency 1
Currently,_the_non-=-devel=_images_on_Pytorch_Dockerhub_do Running_your_Apex_container 11
Running_your_Apex_container Option_2__Install_Apex_in_a_running_container 11
and_*run.sh*_show_an_example_using_Amp is_intended_purely_as_an_instructional_example,_not_a_performance 11
[[https_//github.com/mcarilli/mixed_precision_references/tree/master/GTC_2019][GTC Contents 11
Contents Requirements 4
Contents Walkthrough 4
Use_[[https_//pytorch.org/docs/stable/amp.html][PyTorch 2._Distributed_Training 11
is_deprecated._Use Synchronized_Batch_Normalization 11
Use Checkpointing 11
Checkpointing Installation 11
Installation Part_1._Concurrent_inference_and_dynamic_batching 1
Installation Guidelines_(alpha_version) 1
Installation MLCube_execution 1
[Experimental]_Windows Custom_C++/CUDA_Extensions_and_Install_Options 11
[[https_//github.com/NVIDIA/apex/tree/master/examples/FP16_Optimizer_simple/distributed_apex][Simple Synchronized_Batch_Normalization 11
CPU_path Important_arguments 11
Transform_unstructured_sparsity_to_structured_sparsity_(as_in_Figure References 11
References Appendix 2
Test_your_own_range! Performance_Comparisons 11
Build_and_deploy_HabanaLabs_MLPERF_training_3.0_container_in_the Resnet50 1
Run_and_time_PyTorch_Resnet50 Bert_TF 2
to_download_Dataset_and_Checkpoint_* Preparation_*_In_order_to_use_dataset_one_needs_to_preprocess 2
to_download_Dataset_and_Checkpoint_* Training_data_packing 1
Preparation_*_In_order_to_use_dataset_one_needs_to_preprocess Run_and_time 2
Run_and_time Bert_PT 2
Scaling_out_the_training_to_64_Gaudi2 GPT3-175B_PT 1
Installing_requirements Prepare_checkpoint 1
Run_GPT3_on_HLS-Gaudi2-N48-PT_system UNet3D 1
do_not_report_security_vulnerabilities_through_public_GitHub Preferred_Languages 2
Model_Tests Contributor_License_Agreement 2
DeepSpeed-Compression DeepSpeed_Software_Suite 2
DeepSpeed_on_Azure DeepSpeed_Adoption 2
Code_of_Conduct Publications 2
this_step_frequently_hangs_when_connected_to_a_VPN_(including Update_the_Readthedocs.io_API_documentation 1
all_processes_must_call_this_method_and_not_just_the DeepSpeed_Configuration 1
DeepSpeed_Configuration Launching_DeepSpeed_Training 1
MPI_and_AzureML_Compatibility Resource_Configuration_(single-node) 1
Running_BingBertSquad DeepSpeed_Integration 1
Weight_updates Evaluation 1
Evaluation Recipe 1
Fine-tuning_Results Enabling_DeepSpeed's_Transformer_Kernel_for_better_Throughput 1
out!*_1)_The_NCCL-based_implementation_requires_PyTorch_>=_1.8 1._Overview 3
out!*_This_NCCL-based_implementation_requires_PyTorch_>=_1.8._It 1.2.2_MPI-based_implementation 3
1.2.2_MPI-based_implementation 1.3_0/1_Adam_Algorithm 1
1.2.2_MPI-based_implementation 1.3_1-bit_LAMB_Algorithm 1
1.2.2_MPI-based_implementation 1.3_1-bit_Algorithm 1
out!*_0/1_Adam_relies_on_an_compression_error_compensation 2._BERT_Pre-training_with_0/1_Adam 1
is_DeepSpeed_Compression_*_DeepSpeed_Compression_is_a_library use_DeepSpeed_Compression_*_DeepSpeed_Compression_offers_novel 1
to_use_DeepSpeed_Compression_*_The_first_section_General_Tutorial 1._General_Tutorial 1
to_use_layer_reduction* to_use_layer_reduction* 1
to_use_layer_reduction* 1.2_Weight_Quantization 1
to_use_weight_quantization* to_use_weight_quantization* 1
to_use_weight_quantization* 1.3_Activation_Quantization 1
to_use_activation_quantization* to_use_activation_quantization* 1
to_use_activation_quantization* 1.4_Pruning 1
is_pruning* 1.4.1_Sparse_Pruning 1
to_use_sparse_pruning* to_use_sparse_pruning* 1
to_use_row_pruning* to_use_row_pruning* 1
to_use_head_pruning* to_use_head_pruning* 1
to_use_channel_pruning* to_use_channel_pruning* 1
to_use_channel_pruning* 2._Tutorial_for_ZeroQuant__efficient_and_affordable_post-training 1
to_use_ZeroQuant* to_use_ZeroQuant* 1
to_use_ZeroQuant* 3._Tutorial_for_XTC__simple_yet_effective_compression_pipeline_for 1
to_use_XTC* to_use_XTC* 1
of_XTC_methods_*_To_accommodate_users_who_do_not_have_a 3.1_One-bit_or_Two-bit_BERT-base_(12-layer)_with_8-bit_activation 1
Currently_DeepSpeed_Transformer_Kernels_do_not_support_Sparse *Integrate_Transformer_Kernel* 1
Currently_DeepSpeed_Transformer_Kernels_do_not_support_Sparse How_to_use_sparse_attention_with_DeepSpeed_launcher 1
DeepSpeed_MoE_requires_Pytorch_1.8_or_above._{__.notice--info} Expert_groups_initialization 1
Combining_ZeRO-Offload_and_DeepSpeed_MoE_for_very_large_models Random_Token_Selection 1
Currently,_DeepSpeed_Sparse_Attention_can_be_used_only_on_NVIDIA Sparse_attention_modules 1
For_large_model_training,_see AlexNet 1
the_=lambda=_in_the_middle_of_=layers=_above_is_not_a Inputs_and_Outputs 1
The_pipeline_engine_expects_data_loaders_to_return_a_=tuple=_of out!*_The_pipeline_engine_/pulls/_data_from_an_iterator_instead 1
out!*_The_pipeline_engine_/pulls/_data_from_an_iterator_instead Advanced_Topics 1
DeepSpeed_now_supports_PreLayerNorm_as_the_default_way_for Fine-tuning_with_DeepSpeed_on_GLUE_Tasks 1
On_08/15/2022_we_have_added_another_BERT Pre-training_Bing_BERT_without_DeepSpeed 1
/Downloading_and_pre-processing_instructions_are_coming_soon./ Running_the_Bing_BERT_model 1
Running_the_Bing_BERT_model Enabling_DeepSpeed 1
Training Checkpoints_Saving_&_Loading 1
Start_Training Reproducing_Fastest_BERT_Training_Results_with_DeepSpeed 1
Custom_Monitoring Note_-_Some_Monitor_backends_don't_support_mixed_sample_values._Be 1
[[https_//pytorch.org/][PyTorch]]_must_be_installed_/before/ Install_DeepSpeed_from_source 1
PyTorch Example__Tuning_for_Large_Batch_Sizes 1
In_the_case_where_we_use_gradient_accumulation,_backward_on_the Configuration 1
Run_DCGAN_Model_with_DeepSpeed_Enabled Performance_Comparison 1
key_to_the_DeepSpeed_JSON_configuration._A_full Training_a_1.5B_Parameter_GPT-2_model 1
vs_ZeRO-Offload_*_DeepSpeed_first_included_offloading Allocating_Massive_Megatron-LM_Models 1
DeepSpeed_version_=0.3.15=_introduced_automatic_external Extracting_weights 1
gains/*,_and_*/memory_footprint_reduction/*_from_using Training_GPT-2_with_the_Original_Megatron-LM 1
Running_Unmodified_Megatron-LM_GPT2_model Enabling_DeepSpeed 1
Loss_Scaling Checkpoint_Saving_&_Loading 1
Train_scripts DeepSpeed_Evaluation_using_GPT-2 1
out!*_1-bit_LAMB_relies_on_an_compression_error_compensation 2._BERT_Pre-training_with_1-bit_LAMB 1
1._=cycle_min_mom=__minimum_momentum_in_cycle_phase_2. Required_Model_Configuration_Changes 1
*PyTorch_model* Batch_Scaling_Example 1
This_tutorial_is_updated_on_03/04/2021_to_reflect_the_1-bit_Adam out!*_1)_The_NCCL-based_implementation_requires_PyTorch_>=_1.8 1
out!*_1-bit_Adam_relies_on_an_compression_error_compensation 2._BingBertSQuAD_Fine-tuning_with_1-bit_Adam 1
For_details_about_loading_checkpoint,_argument_parsing, 2.1_Running_BingBertSQuAD_with_DeepSpeed_and_1-bit_Adam 1
The_results_are_summarized_in_the_table_below._The_total Speed_and_Scalability_/* 1
Speed_and_Scalability_/* 3._BERT_Pre-training_with_1-bit_Adam 1
based_technologies*__In_simple_terms,_ZeRO_is_a_memory_efficient Parallelism_based_technologies*__3D_Parallelism_refers_to_a 1
Parallelism_based_technologies*__3D_Parallelism_refers_to_a Deciding_which_technology_to_use 1
based_technologies*__For_most_training_scenarios,_ZeRO_offer Understanding_performance_tradeoff_between_ZeRO_and_3D_Parallelism 1
Eigenvalue_Parameters How_to_Use_MoQ_for_GLUE_Training_Tasks 1
Example__Megatron-LM Usage_Outside_the_DeepSpeed_Runtime 2
Example__Bert In_Model_Training_Workflow 2
This_tutorial_was_updated_on_10/29/2021._Changes_include__1)_A 1._Configurations_and_tuning_strategy 1
1.3_fixed_discrete_schedule 2._Curriculum_learning_for_Megatron-LM_GPT-2_pre-training 1
out!*_After_the_update_on_10/29/2021,_now_there_are_two 2.1_Training_data_truncation 1
that_CUDA_profiling_incurs_non-negligible_overhead. Profile_memory_consumption 1
1.2_Challenges_in_applying_error-compensation_to_Adam 2._Compressing_communication_with_1-bit_Adam 1
2.2_Addressing_system_challenges_for_1-bit_Adam 3._Benefits_of_1-bit_Adam_on_communication-constrained_systems 1
in_model_size*_as_well_as_*increase_in_number_of_GPUs*._As Experimental_Setup 1
Training_setup_using_Azure_VMSS Performance_Evaluation_on_Various_Model_Configurations 1
TFLOPs/GPU*_on_128_NDm_A100_v4-series_A100_systems_(i.e.,_1024 Scaling_the_1T_and_2T_models 1
Scaling_the_1T_and_2T_models How_to_run_training_experiments_on_Azure? 1
Customized_Inference_Kernels_for_Boosted_Compute_Efficiency_of Kernel-Fusion 1
for_Transformers_*_For_transformer-based_models_such_as Inference_with_Tensor-Slicing_*_For_massive_models_such_as 1
Inference_with_Tensor-Slicing_*_For_massive_models_such_as Inference_with_ZeroQuant_*_For_massive_models_with_tens_or 1
for_Resource_Constrained_Systems_*_Models_such_as_Bloom Optimizations_*_When_applicable,_MII_automatically_applies 1
Optimizations_*_When_applicable,_MII_automatically_applies MII-Public_and_MII-Azure 1
Cost_Sensitive_Scenarios Deployment_Options 1
MII-Azure_Deployment Concluding_Remarks 1
rematerialization.*_When_fusing_kernels_of_the_different (b)_Invertible_operators_to_save_memory_and_run_large_batches 1
(b)_Invertible_operators_to_save_memory_and_run_large_batches Overlapping_I/O_with_Computation_through_Asynchronous_Prefetching 1
Alternative_approach__Host_some_model_weights_in_GPU_memory Model_Scaling_on_1_GPU 1
Impact_of_generation_output_length Using_ZeRO-Inference 1
and_allow_*large_batch_sizes*._Alternative How_to_use_ZeRO-Inference 1
How_to_use_ZeRO-Inference Conclusion 1
*_*gradient_accumulation*_*_number_of [integer] 1
[integer] [integer] 11
[integer] Optimizer_Parameters 1
[integer] BFLOAT16_training_options 1
[integer] [boolean] 4
[integer] Optimizer_offloading 1
[integer] [string] 2
[integer] Flops_Profiler 1
[integer] [list_of_integer] 1
[dictionary] Scheduler_Parameters 1
[dictionary] Communication_options 1
[dictionary] [integer] 1
[dictionary] Curriculum_Learning 1
[dictionary] [dictionary] 7
[dictionary] Elastic_Training_Config_(V0.1_and_V0.2) 1
[dictionary] Compression 1
[dictionary] Weight_Quantization 1
[dictionary] Activation_Quantization 1
[dictionary] Sparse_Pruning 1
[dictionary] Row_Pruning 1
[dictionary] Head_Pruning 1
[dictionary] Channel_Pruning 1
[dictionary] Checkpoint_options 1
[boolean] [boolean] 7
[boolean] FP16_training_options 1
[boolean] Automatic_mixed_precision_(AMP)_training_options 1
[boolean] params/*__[various] 1
[boolean] [dictionary] 1
[boolean] *cpu_offload*_is_deprecated_and_will_be_removed_in_future, 1
[boolean] Asynchronous_I/O 1
[boolean] Logging 1
[boolean] Autotuning 1
[boolean] [string] 1
[boolean] [integer] 1
[boolean] Sparse_Attention 1
[boolean] Data_Type_options 1
[float] [boolean] 1
[float] ZeRO_Optimizations_for_FP16_Training 1
this_mode_cannot_be_combined_with_the_=fp16=_mode_described [dictionary] 1
params/*__[various] Gradient_Clipping 1
*cpu_offload*_is_deprecated_and_will_be_removed_in_future, Parameter_offloading 1
[string] [string] 1
[string] Activation_Checkpointing 1
[string] [integer] 1
[int] [int] 1
[list_of_integer] [list_of_integer] 1
[list_of_integer] Monitoring_Module_(TensorBoard,_WandB,_CSV) 1
Compression GRPC_Options 1
*Compression*_has_seven_different_components,_including_layer Layer_Reduction 1
Single-GPU,_Multi-GPU,_and_Multi-Node_Training Pipeline_Parallelism 1
Integration_with_Megatron-LM The_Zero_Redundancy_Optimizer 1
Contiguous_Memory_Optimization_(CMO) ZeRO-Offload 1
Communication_Overlapping Training_Features 1
Automatic_loss_scaling_with_mixed_precision Training_Optimizers 1
Memory-Efficient_Training_with_ZeRO_Optimizer Training_Agnostic_Checkpointing 1
1Cycle_Learning_Rate_Schedule Simplified_Data_Loader 1
Communication_Logging Sparse_Attention 1
Latest_News Extreme_Speed_and_Scale_for_DL_Training_and_Inference 1
Windows Features 1
Windows CM_CLI_testing 2
Windows Run_a_container_and_record_experiments_locally 2
Windows DCO 1
Features Dependencies 1
Features Configure_Contributor_License_Agreement_within_two_minutes 1
Learning_rate_scaling_when_the_effective_batch_size_changes Configuring_ZeRO_configurations 1
Configuring_ZeRO_configurations Autotuning_Output 1
Autotuning_Metric "throughput"__training_samples_per_second_(calculated_as 1
Max_Train_Batch_Size Model_Parallelism_Size 1
Megatron-DeepSpeed_on_AzureML Workspace_Setup 1
End-to-end_Faster_and_Mask_R-CNN_baselines Comparison_with_Detectron_and_mmdetection 27
PASCAL_VOC_Annotations_in_COCO_Format Creating_Symlinks_for_Cityscapes_ 27
Training_and_test_data_separation 4._Model 34
Optimizer 5._Quality 38
Optimizer 4._Quality 18
If_the_repository_is_not_in_the_PYTHONPATH,_make_sure_to_update Build_and_Deploy_HabanaLabs_MLPerf_Training_2.1_Container 2
Training_Data_Packing Training_Data_for_ResNet50 2
TTT_(Time_to_Train)_Calculation_for_BERT Training_ResNet50 2
TTT_(Time_to_Train)_Calculation_for_ResNet50 Supported_Configurations 2
Convert_NumPy_dataset_to_raw_format. Specify_the_preprocessed_data_paths_in_the_training_script. 6
the_Bug* Steps/Code_to_Reproduce_the_Bug* 1
Model_checkpoint 5._Quality 2
Evaluation_thoroughness 6._Additional_notes 2
Evaluation_thoroughness 6._Other 2
Evaluation_thoroughness MLCommons_Inference 2
Evaluation_thoroughness 5._Steps_to_run_the_model 2
Evaluation_thoroughness Reference_runs 2
NF5**8_(single_node) Alternative_launch_with_nvidia-docker 1
Checkpoint Prepare_enviroment 1
Checkpoint Running_the_model 1
Dataset Prepare_environment 1
Setup_Conda_Environment_and_Build_Dependencies Run_Benchmark 2
Run_Benchmark Setup_with_Docker 6
Pretrained_backbone Running_the_model 1
NVIDIA_DGX_H100_(single_node) Alternative_launch_with_nvidia-docker 1
Build_the_container_and_push_to_a_docker_registry. Running_training 1
Alternative_launch_with_docker Steps_to_launch_training_on_multiple_nodes 1
Clean_up Running_the_model 6
Clean_up Librispeech 1
Decide_benchmark_name*_|_name_|_framework_|_acc._|_AUC_|_dataset Disclaimer 2
Disclaimer Prerequisites_and_Installation 7
Disclaimer 2._Directions 2
Calibration_set Running_the_benchmark 7
GPU Examples_for_testing 7
Usage License 12
Usage Contact_us 6
License Credits 1
Take_into_account_that_we_only_update_the_published_wheels_after Testing_your_Installation 2
Installation_-_C++ Quick_start__Loadgen_Over_the_Network 2
The_MLPerf_spec_is_/always/_right._Please_file_a_LoadGen_bug_so_it Q__How_can_I_file_a_bug? 5
On_GitHub__https_//github.com/mlcommons/inference/issues/new Q__Can_I_make_local_modifications_to_the_LoadGen_for_submission? 5
No. To_keep_the_playing_field_level,_please_upstream_any_local Q__Where_can_I_find_the_results_of_a_test? 5
By_default,_the_loadgen_will_output_an_/mlperf_log_summary.txt/ Q__The_reference_implementation_for_</some_model/>_prints_out_results 5
They_are_not._The_LoadGen_results_are_the_ground_truth_for Q__I'm_getting_linker_errors_for_LoadgenVersion_definitions._Where_is 5
If_you_have_a_custom_build_setup,_make_sure_you_run_the Q__What_is_this_/version_generator.py/_script? 5
The_LoadGen_records_git_stats_(if_available)_and_the_SHA1_of_all Q__How_do_I_view_the_/mlperf_log_trace.json/_file? 5
This_file_uses_the_[Trace_Event_Format] Q__Why_is_the_code_littered_with_so_many_lambdas?_My_eyes_hurt. 4
This_file_uses_the_[Trace_Event_Format] Q__What_is_the_difference_between_the_MultiStream_and_MultiStreamFree 1
Lambdas_are_a_convenient_and_efficient_way_to_ship_arbitrary_data_+ Q__What_C++_version_does_the_LoadGen_target? 5
It_currently_targets_and_requires_C++14._It_should_compile_with Q__What_dependencies_does_the_LoadGen_code_have? 5
aware_of_how_to_score_the_accuracy_of_a_model's_outputs._*_*NOT* Submission_Considerations 5
Choose_your_TestSettings_carefully! Responsibilities_of_a_LoadGen_User 5
Assess_Accuracy LoadGen_over_the_Network 4
QDL_Additional_Methods Example 4
Example META_is_config_valid() 37
Example META_search_callback() 37
Example Reusable_automation_actions 2
Example Interaction_with_custom_artifact_stores 1
Example In-Process_Triton_Server_API 1
Example Extract 1
Example Model_versioning 1
Setup RNNT 2
Setup 3d-unet 2
Setup Resnet50 2
Setup Retinanet 2
Setup Bert 2
Setup GPT-J 2
Setup GCS_for_simple_task_signaling 8
One_liner_to_do_an_end-to-end_submission_using_the_reference Please_adjust_the_=target_qps=_value_as_per_your_system_performance 10
One_liner_to_do_an_end-to-end_submission_using_the_reference Please_modify_the_=--adr.gptj-model.checkpoint=_value_to_the_path 2
Below_we_give_an_/essential/_sequence_of_steps_that_should_result Table_of_Contents 6
Table_of_Contents Description 1
Table_of_Contents Getting_Started 2
Table_of_Contents [[https_//github.com/d3/d3-array/blob/master/README.md][Arrays 1
CK_can_normally_detect_available_Python_interpreters Install_implicit_dependencies_via_pip 6
These_dependencies_are_/implicit/,_i.e. CK_will_not_try_to_satisfy Install_explicit_dependencies_via_CK_(also_via_=pip=,_but_register 13
Validate_accuracy_for_ssd-mobilenet_and_ssd-resnet34_benchmarks Datasets 5
Datasets Running 1
This_part_is_only_necessary_if_the_accuracy_check_in_Part_II each_target_accuracy_metric,_the_delta_between_the_two_accuracy 2
This_part_is_only_necessary_if_the_accuracy_check_in_Part_II delta_between_the_two_accuracy_metrics_should_be_within_1%_for_the 3
Path_to_.csv_output_file_of_the Outputs 4
Outputs =log_parser.py= 4
Outputs =submission_checker.py= 4
Outputs =truncate_accuracy_log.py= 4
Outputs =preprocess_submission.py= 2
Outputs Parameters 2
Outputs Calibration 1
Outputs Load_and_run_a_model_in_Python 2
Flag_to_avoid_checking_if_mandatory Summary 2
Path_to_directory_containing_your_submission_*output*__Path_to Outputs 4
Running_other_datasets_ 3._Dataset 5
Expected_time_to_do_benchmark_runs Validity_of_the_submission 2
Reviewing_other_submissions Changes_from_MLCommons_Inference_3.0 2
This_document_is_autogenerated_from_internal_documentation._If Make_Targets 31
This_document_is_autogenerated_from_internal_documentation._If HPE-NVIDIA_MLPerf_Quantization 1
This_document_is_autogenerated_from_internal_documentation._If What_if_I_have_permission_issues_when_I_attempt_to_write_to_the 31
This_document_is_autogenerated_from_internal_documentation._If Before_you_continue 29
This_document_is_autogenerated_from_internal_documentation._If MLPerf_Inference_Policies_and_Terminology 30
This_document_is_autogenerated_from_internal_documentation._If Heterogeneous_MIG_Workloads_for_Multi-MIG_Systems 28
This_document_is_autogenerated_from_internal_documentation._If NVIDIA_MLPerf_Quantization 37
This_document_is_autogenerated_from_internal_documentation._If NVIDIA_Submissions 3
This_document_is_autogenerated_from_internal_documentation._If MLPerf_Quantization 1
Make_sure_your_performance_tuning_changes_(i.e. any_change Difference_system_configurations_that_use_the_same_GPU_configuration 31
that_this_flag_is_only_supported_/_allowed_on_the_following you_wish_to_use_both_start_from_device_and_end_on_device,_you_must 31
in_order_to_use_start_from_device_or_end_on_device_in_a Using_NUMA_configurations 31
an_eye_out_for_this_announcement,_as_it_will_also_include_a submission_that_does_not_use_one_of_these_commit_hashes_will_not_be 30
submission_that_does_not_use_one_of_these_commit_hashes_will_not_be Minimal_Query_Count 30
The_way_audit_tests_function_is_by_placing_an_=audit.conf= Truncating_the_Accuracy_Logs 30
Make_sure_that_no_files_and_directories_exist_in_the_project The 30
Make_sure_that_no_files_and_directories_exist_in_the_project Encrypting_your_project_for_submission 1
The Packaging_your_project_for_submission 30
that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and Download_the_Datasets 25
that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and Download_the_datasets 6
that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and Download_the_dataset_and_the_model 1
that_you_do_not_need_to_download_the_datasets_or_models_for Downloading_the_Model_files 25
that_you_do_not_need_to_download_the_datasets_or_models_for Downloading_the_model_files 6
proceeding,_double_check_that_you_have_downloaded_both_the Preprocessing_the_datasets_for_inference 31
Preprocessing_the_datasets_for_inference Running_NEUCHIPS_DLRM_benchmark 1
your_system_is_not_listed_above,_you_must_add_your_system_to_our Running_your_first_benchmark 30
enter_closed/HPE*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment 1
notes_/* Building_the_binaries 1
notes_/* Launching_the_environment_on_a_MIG_(Multi-Instance_GPU)_instance 8
notes_/* Launching_the_environment_on_Jetson_Orin_systems 6
notes_/* Launching_the_environment_on_Jetson_Orin_AGX/NX 14
notes_/* Further_reading 1
notes_/* Adding_a_New_or_Custom_System 2
This_command_does_not_need_to_be_run_every_time_you_enter_the Running_the_actual_benchmark 31
engines_is_only_required_if* Building_and_running_engines_for_the_"High_Accuracy_Target" 31
Preprocessing_the_dataset_for_use Model 57
Downloading_/_obtaining_the_model Optimizations 197
Downloading_/_obtaining_the_model Dataset 70
Embedding_Table_Sorting_and_Splitting Instructions_for_Auditors 57
Preprocessing_the_dataset_for_usage Model 177
Preprocessing_the_dataset_for_usage Optimizations 70
Soft_Dropping Instructions_for_Auditors 87
Goal_of_this_Benchmark Dataset 151
Preprocessing_the_dataset Model 140
Generating_model_binaries_and_running_INT8_calibration Instructions_for_Auditors 102
Generating_model_binaries_and_running_INT8_calibration Instructions_for_Audits 49
Sequence_Splitting Instructions_for_Audits 37
Model_Source Optimizations 23
Lower_Precision Instructions_for_Audits 11
Lower_Precision Calibration 2
Preprocessing_data Model 11
Replace_ReLU6_with_ReLU Instructions_for_Audits 12
Removal_of_Softmax Calibration 38
Calibration Instructions_for_Audits 40
TransposedConvolution_->_Convolution_+_PixelShuffle_Conversion Instructions_for_Auditors 83
Training_(MobileNetV1-SSD)** Quantization_(ResNet50)** 1
enter_closed/NVIDIA*._From_now_on,_all_of_the_commands_detailed Launching_the_environment 20
enter_closed/NVIDIA*._From_now_on,_all_of_the_commands_detailed Launching_the_environment_on_datacenter/desktop_systems 5
=g292_z43_q16= Performance 8
=g292_z43_q16= Power_(full) 1
Performance Benchmark_via_the_"neoclassical"_CK_interface 190
Performance SingleStream_scenario 8
Performance Prepare_your_submission 42
Performance Run_experiments_(via_cmdgen) 2
=g292_z43_q16=_[optional] Power 7
=r282_z93_q5= Performance 8
=r282_z93_q5=_[optional] Power 8
precision_fp16 =g292_z43_q16= 20
precision_fp16 Performance 10
precision_fp16 =g292_z43_q16=_[optional] 10
precision_fp16 Power 10
precision_fp16 =r282_z93_q5= 12
precision_fp16 =r282_z93_q8= 12
precision_fp16 =r282_z93_q5=_[optional] 6
precision_fp16 =r282_z93_q8=_[optional] 6
Fixed_SOC_Pstate_=_P0 DF_Common_Options 3
ACPI_SRAT_L3_Cche_As_NUMA_Domain_=_Disabled CPU_Common_Options 3
L2_Up/Down_Prefetcher_=_Auto Management_Firmware_Settings 3
Run_the_below_commands_with_=sudo=_or_as_superuser. Generic 7
=g++= =r282_z93_q5=__use_QAIC_settings_(ECC_on) 7
Please_detect_only_one_Python_interpreter._We_recommend_Python Python_v3.8 2
CK_can_normally_detect_compilers_automatically,_but_we_are_playing Install_implicit_dependencies_via_pip 7
These_dependencies_are_/explicit/,_i.e. CK_will_try_to_satisfy Compile_the_Server/Offline_model_for_the_PCIe_server_cards 2
These_dependencies_are_/explicit/,_i.e. CK_will_try_to_satisfy Hint 2
SingleStream Compile_and_install_the_models_to_the_16_NSP_AEDK 5
SingleStream Info 5
SingleStream Compile_and_install_the_models_to_the_20W_AEDK 4
Please_detect_only_one_Python_interpreter._Python_3.6,_the_default Python_v3.6_(default) 5
Hint Select_the_calibration_dataset 1
Hint Detect_a_pregenerated_profile 1
Since_the_preprocessed_=1200x1200=_COCO_dataset_takes_up_21G,_you Calibrate_on_your_own 2
Since_the_preprocessed_=1200x1200=_COCO_dataset_takes_up_21G,_you Use_precalibrated_profiles 4
For_more_information,_please_see_the Use_precalibrated_profiles 2
For_more_information,_please_see_the Compilation_for_15w_AEDKs_(edge_category) 4
Offline SingleStream 4
Since_the_preprocessed_ImageNet_dataset_takes_up_7.1G,_you_may Download_the_MLPerf_TensorFlow_model 2
The_input_tensor's_shape_gets_updated_("fixed")_from_=?x224x224x3= Obtain_a_profile_using 2
1_sample_per_batch_(for_the_Single_Stream_scenario) Calibrate_on_your_own 2
1_sample_per_batch_(for_the_SingleStream_scenario) Compile_the_Server/Offline_model_for_the_PCIe_server_cards 2
1_sample_per_batch_(for_the_SingleStream_scenario) Prerequisites 1
Accuracy_benchmark Quantization_and_calibration 2
MultiStream_corresponds_to_the_official_MLPerf_scenario_for Q__Why_is_the_code_littered_with_so_many_lambdas?_My_eyes_hurt. 1
This_excludes_"uber"_packages_which_can_be_used_to_install_all Run_the_TensorFlow_(Python)_Image_Classification_client 3
When_using_the_batch_count_of_*N*,_the_program_classifies_*N* Benchmark_the_accuracy 6
When_using_the_batch_count_of_*N*,_the_program_classifies_*N* ResNet 6
For_the_=imagenet-2012-val-min=_dataset,_change Using_Collective_Knowledge 6
For_the_=imagenet-2012-val-min=_dataset,_change ResNet 6
Please_[[file_info@dividiti.com][let_us_know]]_if_you_would_like Install_the_models_for_TFLite 3
MobileNet_quantized Bonus__other_MobileNets_models 3
MobileNet_quantized Benchmark_the_accuracy 6
MobileNet_quantized Example__OpenCV_preprocessing_(default),_MobileNet_non-quantized 3
MobileNet_quantized Example__universal_OpenCV_preprocessing_(default),_MobileNet 3
Bonus__other_MobileNets_models Compile_the_TFLite_Image_Classification_client 3
Bonus__other_MobileNets_models Compile_the_TensorFlow_(C++)_Image_Classification_client 3
OpenCV_preprocessing MobileNet_non-quantized 3
OpenCV_preprocessing MobileNet_quantized 3
The_prediction_from_=tflite=_differs_from_that_from_=tf-cpp=. Benchmark_the_performance 3
If_you_would_like_to_get_a_feel_of_CK_workflows,_you_can_skip Install_common_tools_and_libraries 6
Care_must_be_taken_not_to_mix_Python_3_and_Python_2_packages._If Install_required_Python_3_packages 6
Option_3__User-space_installation_via_CK_(under_=$HOME=_and [Optional]_Install_Android_SDK_and_NDK 3
On_Ubuntu_18.04,_NDK_r13b_gets_installed._On_Ubuntu_16.04, Pull_CK_repositories 3
Transitive_dependencies_include Install_a_small_dataset_(500_images) 3
Transitive_dependencies_include Install_the_COCO_2017_validation_dataset_(5,000_images) 3
ImageNet_dataset_descriptions_are_in Install_the_full_dataset_(50,000_images) 3
If_you_already_have_the_ImageNet_validation_dataset_downloaded_in Preprocess_datasets 3
The_TFLite_weights_are_in_the_=mobilenet_v1_1.0_224*.tflite=_file. Inspecting_recorded_experimental_results 3
Image_cropping Visualizing_experimental_results 3
The_ResNet_model_has_a Install_models_for_TensorFlow_(C++) 3
TensorFlow_preprocessing MobileNet_non-quantized 3
TensorFlow_preprocessing_(*NOT_APPLICABLE!*) MobileNet_quantized 3
TensorFlow_preprocessing_(*NOT_APPLICABLE!*) Benchmark_the_performance 3
Install_the_ResNet_model Run_the_ONNX_Image_Classification_client 3
MobileNet,_NCHW Benchmark_the_performance 3
Install_the_quantized_finetuned_model_(courtesy_of Run_the_TensorFlow_(Python)_Object_Detection_client_on_50_images 3
When_using_the_batch_count_of_*N*,_the_program_runs_object Benchmark_the_accuracy 6
Currently_we_have_no_TFLite_1.13.1_prebuilt_packages._Please Install_the_SSD-MobileNet_models_for_TFLite 3
This_TFLite_model_has_been Compile_the_TFLite_Object_Detection_client 3
We_are_working_on_resolving_the_difference_in_mAP_between_the_TF Benchmark_the_performance 3
We_are_working_on_resolving_the_difference_in_mAP_between_the_TF Using_Collective_Knowledge 3
Option_3__user-space_installation_via_CK_(under_=$HOME=_and Pull_CK_repositories 3
If_you_have_previously_installed_the_COCO_2017_validation_dataset Preprocess_the_COCO_2017_validation_dataset_(first_50_images) 3
COCO_2017_validation_dataset Prerequisites_and_Installation 1
Part_III___Compare_performance_of_TEST04-A_with_TEST04-B Help 1
SSD_ResNet34_int8 ONNXRuntime_PTQ 1
[[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate Accuracy 1788
[[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate OpenCL 7641
[[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate "All-in-one" 7914
[[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate Note_that_unlike_[[#mobilenet_v1][MobileNet-v1]], 2532
Accuracy Known_issues 1
Accuracy =llvm_-mcpu=cortex-a72_-mfloat-abi=hard= 8
Accuracy Setup_with_docker_image 21
Accuracy Get_the_Results 7
Accuracy CPU 2
Accuracy MobileNet-v2 1
Accuracy MobileNet-v3 1
Accuracy EfficientNet 1
Accuracy Direct_usage 2
OpenCL Performance 12735
OpenCL Compliance 2548
OpenCL Accuracy 12676
OpenCL Benchmark_via_the_"neoclassical"_CK_interface 96
OpenCL MobileNet-v1 1
OpenCL "All-in-one" 2532
Compliance Notes 2
Use_a_uniform_target_latency [[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate 2547
=model-tflite-mlperf-efficientnet-lite4= [[https_//github.com/arm-software/armnn-mlperf#preprocess-on-an-x86-machine-and-detect-on-an-arm-dev-board][Detect 192
[[https_//github.com/arm-software/armnn-mlperf#preprocess-on-an-x86-machine-and-detect-on-an-arm-dev-board][Detect Benchmark_performance_via_the_"classical"_CK_interface 190
[[https_//github.com/arm-software/armnn-mlperf#preprocess-on-an-x86-machine-and-detect-on-an-arm-dev-board][Detect Run_once_(classical_CK_interface) 2
AutoSinian Benchmarks 1
Inside_the_Docker_container,_[[file_closed/Alibaba]]_will_be Prerequisites 1
Run_harness_on_engines Notes_on_runtime_and_performance 2
Run_Calibration Instructions_for_Auditors 1
Install_Python_and_IPex Download_Model 7
2._SW_requirements Steps_to_run_DLRM 19
2._SW_requirements Run_DLRM 1
Run_command Setup_with_docker 31
dataset_ 2.Start_a_container 3
dataset_ 2.load_images 3
2._into_container 3.Run_SSD-Resnet34 3
4._Run_command_for_server_and_offline_mode Setup_with_Docker 5
model_ 2.Start_and_log_into_a_container 5
(2)_into_container 3.Run_DLRM 5
(2)_into_container 4.Run_Resnet50 3
Install_Dependencies_for_Resnet50 Download_Model 3
Note_on_Server_scenario Setup_with_Docker 5
To_verify_accuracy_of_your_workload,_run_your_command_with Code_Diagram 11
for_short). How_the_HeteroMIG_harness_is_designed 29
refer_to_Intel's_readme_under_/closed/Intel_for_detailed Dell_Submission_Systems 1
Dell_Submission_Systems GPU_Implementations 1
refer_to_/closed/NVIDIA_for_detailed_instructions,_including Dell_Submission_Systems 2
Inside_the_Docker_container,_[[file_closed/Fujitsu]]_will_be Before_you_run_commands 1
Inside_the_Docker_container,_[[file_closed/Fujitsu]]_will_be Prerequisites 1
Run_Compliance_Tests_and_Update_Compliance_Logs Instructions_for_Auditors 5
Triton_Harness NVIDIA_Submissions 1
Inside_the_Docker_container,_[[file_closed/NVIDIA]]_will_be Prerequisites 3
Run_Triton_Harness Multi-MIG_Harness 1
*(DOCKER)*_Run_the_benchmark_ SSD-Resnet34 1
*(DOCKER)*_Run_the_benchmark_ Run_the_BERT_benchmark 1
*(DOCKER)*_Run_the_benchmark_ Run_the_DLRM_benchmark 1
*(DOCKER)*_Run_the_benchmark_ Run_the_3D_U-Net_benchmark 1
*(DOCKER)*_Run_the_benchmark_ Limitations_and_Best_Practices_for_Running_MLPerf 1
you_add_your_entry_into_config.json*,_you_will_have_to_add_your Different_system_configurations_that_use_the_same_GPU_configuration 1
Different_system_configurations_that_use_the_same_GPU_configuration NUMA_configuration 1
MultiStream Fix_INVALID_results 1
MultiStream Tune_parameters_for_better_performance 1
MultiStream Other_performance_tips 1
permission_issue_when_container_tries_to_write_to_local get_=useradd__user_'root'_already_exists=_when_running 1
do_I_install_programs_like_valgrind_in_the_container?* get_=nvcc_fatal_____Unsupported_gpu_architecture_'compute_80'=_error 1
sure_you_run_the_below_commands_after_=results/=_is_populated_with Truncate_Accuracy_Logs 1
The_current_MLPerf_Inference_Results_Chair_is_Guenther Common_issues 1
Run_harness Notes_on_runtime_and_performance 2
enter_closed/Inspur*._From_now_on,_all_of_the_commands_detailed Launching_the_environment 1
Prepare_your_submission Visualize_MLPerf_results 26
See_all_installed_packages_and_detected_components Resources 8
See_all_installed_packages_and_detected_components Reproducibility_report__design_space_exploration 4
See_all_installed_packages_and_detected_components Reproducibility_report__benchmarking 16
See_all_installed_packages_and_detected_components Install_TFLite_model_(MobileNet_v2__Large__Minimalistic__224__1.0_ 2
See_all_installed_packages_and_detected_components Install_PyTorch_model_(Resnet50__int8__quantized) 2
See_all_installed_packages_and_detected_components Install_CK_workflow_Python_dependencies 2
WIP__DEFINE_PROD_AWS_ACCOUNT_OWNER_ID_=_{prod_aws_account_owner_id} Task_Owner_Setup 1
Filling_in_the_rest_of_the_config Filling_in_=eval_config= 1
2_*_Install_mlsphere_utility_and_download_the_image. Run 1
Run Open_discussions_and_developments 2
[NOTICE]_POSSIBLY_OUTDATED Web_Interface 1
Running_the_API_server Frontend 1
Concrete_example_that_illustrates_the_different_components_ Table_of_Contents 1
to_inform_their_work_or_research._The_way_a_given_task_is Codebase 1
If_any_linter_doesn't_pass,_your_pull_request_is_not_going_to_be Migrations 1
docker* virtualenv* 1
your_model* Run_select_task 2
The_cost_of_this_service_depends_on_the_instance_you_choose_and Creating_EC2_instance 1
Open_EC2_ports_to_receive_requests Setting_up_AWS_environment 1
This_service_is_free. Creating_user 1
This_service_is_free. Creating_S3_bucket 1
This_service_is_free. Creating_ECS_cluster 1
The_cost_for_this_service_depends_on_the_size_of_the_files_that Creating_ECS_execution_role 1
Create_SQS_queue Starting_the_app 1
Foldes_contents Resources_folder 1
Checking_output_format Requirements 1
Run_Fast_api_swagger Test_your_endpoints 1
Removed [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-5-1][8.5.1 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.07][22.07]]_- 1
Removed [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-4-1][8.4.1 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.05][22.05]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.04][22.04]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.03][22.03]]_- 1
Removed [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-2-1][8.2.1 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.10][21.10]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.09][21.09]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.08][21.08]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.07][21.07]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.05][21.05]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.03][21.03]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.02][21.02]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.12][20.12]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.11][20.11]]_- 1
Removed [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.10][20.10]]_- 1
Removed [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-7.html#rel_7-2-1][7.2.1]]_- 1
Removed 21.02_Container_Release_-_2021-01-18 1
Removed 20.12_Container_Release_-_2020-12-17 1
Removed v0.41.1_(2022-08-25) 1
Removed v0.40.4_(2022-08-17) 1
Removed v0.39.0_(2022-07-01) 1
Removed v0.37.3_(2022-05-04) 1
Removed v0.34.2_(2021-11-29) 1
Removed v0.33.2_(2021-10-21) 1
Removed v0.31.1_(2021-07-16) 1
Removed v0.27.0_(2021-04-06) 1
Removed v0.25.1_(2021-03-15) 1
Removed v0.23.1_(2021-02-05) 1
Removed v0.13.4_(2020-03-25) 1
Removed v0.7.1_(2019-08-29) 1
Removed v0.3.0_(2021-02-12) 1
Removed v0.2.2_(2020-06-17) 1
Changed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.02][22.02]]_- 1
Changed [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.04][21.04]]_- 1
Changed TensorRT_8.5_GA_Release_-_2022-11-2 1
Changed Removed 1
Changed v0.47.0_(2023-03-28) 1
Changed v0.46.0_(2023-02-10) 1
Changed v0.45.2_(2023-01-25) 1
Changed v0.45.1_(2023-01-19) 1
Changed v0.40.2_(2022-08-12) 1
Changed v0.40.0_(2022-07-29) 1
Changed v0.37.2_(2022-04-20) 1
Changed v0.37.1_(2022-04-18) 1
Changed v0.36.4_(2022-04-12) 1
Changed v0.36.2_(2022-03-31) 1
Changed v0.35.0_(2022-01-06) 1
Changed v0.33.0_(2021-09-16) 1
Changed v0.31.0_(2021-07-02) 1
Changed v0.29.0_(2021-04-28) 1
Changed v0.28.3_(2021-04-22) 1
Changed v0.23.3_(2021-02-13) 1
Changed v0.23.2_(2021-02-11) 1
Changed v0.20.6_(2020-09-18) 1
Changed v0.14.1_(2020-04-17) 1
Changed v0.14.0_(2020-04-09) 1
Changed v0.13.3_(2020-03-20) 1
Changed v0.12.0_(2020-03-06) 1
Changed v0.11.2_(2020-02-11) 1
Changed v0.10.3_(2019-11-18) 1
Changed v0.10.1_(2019-10-31) 1
Changed v0.9.8_(2019-10-24) 1
Changed v0.9.6_(2019-10-15) 1
Changed v0.9.5_(2019-10-9) 1
Changed v0.9.3_(2019-10-1) 1
Changed v0.9.1_(2019-10-1) 1
Changed v0.9.0_(2019-09-30) 1
Changed v0.8.1_(2019-09-26) 1
Changed v0.8.0_(2019-09-18) 1
Changed v0.6.0_(2019-07-17) 1
Changed v0.3.21_(2022-08-19) 1
Changed v0.3.8_(2021-04-15) 1
Changed v0.3.1_(2021-02-12) 1
Changed v0.2.8_(2020-10-08) 1
Changed v0.2.6_(2020-09-25) 1
Changed v0.2.5_(2020-09-21) 1
Changed v0.1.3_(2020-02-26) 1
Changed v0.1.0_(2020-02-11) 1
Changed v0.0.7_(2022-08-10) 1
Changed v0.0.5_(2020-07-21) 1
Changed v0.0.4_(2020-07-18) 1
Changed v0.0.2_(2020-07-05) 1
Notes [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.06][21.06]]_- 1
Version*_ GPU*_ 1
Version*_ Relevant_Files 1
Driver_Version*_ Version*_ 1
link*_ Steps_To_Reproduce 1
or_scripts*_ you_tried_[[https_//developer.nvidia.com/tensorrt][the_latest 1
you_tried_[[https_//developer.nvidia.com/tensorrt][the_latest this_model_run_on_other_frameworks?*_For_example_run_ONNX_model 1
Version_Info Setup 1
Since_the_datasets_and_checkpoints_are_stored_in_the_directory (Optional)_Trying_a_different_configuration 1
(Optional)_Trying_a_different_configuration Advanced 1
TensorRT_inference_process Accuracy 1
the_TensorRT_engine*_ a_question*_ 1
F1_score*_ Performance 1
The_time_measurements_do_not_include_the_time_required_to_copy Results 1
Results  2
Megatron_Large_with_Sparsity Inference_performance__NVIDIA_A30 1
Software_Versions Quick_Start_Guide 1
TensorRT_inference_benchmark Results 1
Types_of_changes [1.3.4]_-_2023-02-02 1
note_that_due_to_end-of-life,_Python_<=_3.6_is_no_longer File_Structure 1
Ubuntu_20.04_on_x86-64_with_cuda-11.6.2_(default)* Step_1__PyTorch_model_to_ONNX_model 1
Install_required_packages Running_demoDiffusion 1
=getPluginCreator()_could_not_find_Plugin_<operator_name>_version_1= Custom_Layer_Support 1
Deprecated TensorRT_8.4_GA_Release_-_2022-6-6 1
Fixes TensorRT_8.2_GA_Release_-_2021-11-23 1
Fixes TensorRT_8.2_EA_Release_-_2021-10-04 1
Fixes 21.03_Container_Release_-_2021-03-09 1
Fixes TensorRT_7.2.1_Release_-_2020-10-20 1
Updated TensorRT_8.0_Release_-_2021-07-02 1
Updated 21.05_Container_Release_-_2021-05-17 1
Version*__*ONNX-TensorRT_Version_/_Branch*__*GPU_Type*_ Driver_Version*__*CUDA_Version*__*CUDNN_Version*__*Operating 1
or_Container_(if_container_which_image_+_tag)*_ Relevant_Files 1
Full_Dimensions_+_Dynamic_Shapes  1
Supported_Operators Installation 1
InstanceNormalizaiton_Performance Executable_Usage 1
Python_Modules ONNX-TensorRT_Python_Backend_Usage 1
Tests Pre-trained_Models 1
Add_PyConfig.h Build_Python_bindings 1
GA_build*_* Packages*_*_[[https_//developer.nvidia.com/cuda-toolkit][CUDA]] 1
Packages*_*_[[https_//developer.nvidia.com/cuda-toolkit][CUDA]] Recommended_versions__*_cuda-12.2.0_+_cuDNN-8.8_*_cuda-11.8.0_+ 1
Packages*_*_Containerized_build_* Downloading_TensorRT_Build 1
Building_TensorRT-OSS References 1
Common_Pitfalls Appendix 1
Terminology NVIDIA_Copyright 1
Terminology Pretraining_on_the_source_dataset 1
Yapf Test 1
Quantization_mode Misc 1
NGC_Container Resources 1
A_Possible_Solution Running_The_Example 1
/This_example_requires_TensorRT_8.4_or_later./ Using_The_=--layer-precisions=_Option 1
Run_the_network_script_but_allow_TensorRT_to_ignore See_Also 1
Comparing_Different_Models Further_Reading 1
TIP__Generating_Script_Templates_Automatically Running_The_Example 1
Comparing_Per-Layer_Outputs_Between_ONNX-Runtime_And_TensorRT Further_Reading 1
Fixed v0.46.2_(2023-02-28) 1
Fixed v0.46.1_(2023-02-27) 1
Fixed v0.45.3_(2023-01-25) 1
Fixed Removed 1
Fixed v0.44.1_(2022-12-06) 1
Fixed v0.44.0_(2022-11-30) 1
Fixed v0.43.1_(2022-10-12) 1
Fixed v0.43.0_(2022-10-06) 1
Fixed 0.42.2_(2022-09-22) 1
Fixed v0.42.1_(2022-09-07) 1
Fixed v0.42.0_(2022-09-01) 1
Fixed v0.41.0_(2022-08-24) 1
Fixed v0.40.3_(2022-08-17) 1
Fixed v0.40.1_(2022-08-08) 1
Fixed v0.38.0_(2022-05-24) 1
Fixed v0.36.3_(2022-04-07) 1
Fixed v0.36.1_(2022-03-25) 1
Fixed v0.36.0_(2022-02-24) 1
Fixed v0.35.2_(2022-02-03) 1
Fixed v0.35.1_(2022-01-14) 1
Fixed v0.33.1_(2021-10-08) 1
Fixed v0.32.0_(2021-08-10) 1
Fixed v0.30.3_(2021-06-25) 1
Fixed v0.30.2_(2021-06-15) 1
Fixed v0.30.1_(2021-06-07) 1
Fixed v0.30.0_(2021-05-26) 1
Fixed v0.29.2_(2021-04-30) 1
Fixed v0.28.7_(2021-04-26) 1
Fixed v0.28.6_(2021-04-23) 1
Fixed v0.28.5_(2021-04-23) 1
Fixed v0.28.2_(2021-04-22) 1
Fixed v0.28.1_(2021-04-22) 1
Fixed v0.28.0_(2021-04-20) 1
Fixed v0.26.1_(2021-04-01) 1
Fixed v0.26.0_(2021-03-30) 1
Fixed v0.25.0_(2021-03-01) 1
Fixed v0.24.2_(2021-02-25) 1
Fixed v0.24.1_(2021-02-22) 1
Fixed v0.24.0_(2021-02-19) 1
Fixed v0.23.4_(2021-02-15) 1
Fixed v0.23.0_(2021-02-02) 1
Fixed v0.22.0_(2021-01-20) 1
Fixed v0.21.1_(2021-01-12) 1
Fixed v0.20.13_(2020-10-08) 1
Fixed v0.20.12_(2020-10-01) 1
Fixed v0.20.10_(2020-09-23) 1
Fixed v0.20.9_(2020-09-22) 1
Fixed v0.20.8_(2020-09-22) 1
Fixed v0.20.7_(2020-09-22) 1
Fixed v0.20.4_(2020-09-14) 1
Fixed v0.20.3_(2020-09-11) 1
Fixed v0.20.2_(2020-09-11) 1
Fixed v0.20.1_(2020-09-09) 1
Fixed v0.20.0_(2020-09-08) 1
Fixed v0.17.0_(2020-07-20) 1
Fixed v0.16.0_(2020-06-11) 1
Fixed v0.15.0_(2020-05-05) 1
Fixed v0.13.1_(2020-03-17) 1
Fixed v0.13.0_(2020-03-17) 1
Fixed v0.11.3_(2020-02-25) 1
Fixed v0.11.0_(2020-01-28) 1
Fixed v0.10.6_(2019-12-11) 1
Fixed v0.10.5_(2019-12-9) 1
Fixed v0.10.4_(2019-12-4) 1
Fixed v0.10.2_(2019-11-11) 1
Fixed v0.9.7_(2019-10-18) 1
Fixed v0.9.4_(2019-10-7) 1
Fixed v0.7.0_(2019-07-30) 1
Fixed v0.3.25_(2022-10-14) 1
Fixed v0.3.24_(2022-08-31) 1
Fixed v0.3.23_(2022-08-24) 1
Fixed v0.3.22_(2022-08-22) 1
Fixed v0.3.19_(2022-04-13) 1
Fixed v0.3.17_(2022-03-18) 1
Fixed v0.3.15_(2022-01-18) 1
Fixed v0.3.14_(2021-10-14) 1
Fixed v0.3.13_(2021-09-21) 1
Fixed v0.3.10_(2021-05-20) 1
Fixed v0.3.7_(2021-03-31) 1
Fixed v0.3.6_(2021-03-27) 1
Fixed v0.3.5_(2021-03-24) 1
Fixed v0.3.4_(2021-03-10) 1
Fixed v0.3.3_(2021-03-04) 1
Fixed v0.3.2_(2021-02-13) 1
Fixed v0.2.9_(2021-02-01) 1
Fixed v0.2.7_(2020-09-29) 1
Fixed v0.2.4_(2020-09-14) 1
Fixed v0.2.3_(2020-06-17) 1
Fixed v0.2.1_(2020-06-10) 1
Fixed v0.1.2_(2020-02-19) 1
Fixed v0.0.6_(2020-07-21) 1
Fixed v0.0.1_(2022-06-23) 1
Added v0.45.0_(2023-01-12) 1
Added v0.38.1_(2022-06-22) 1
Added v0.37.0_(2022-04-18) 1
Added v0.34.1_(2021-11-24) 1
Added v0.34.0_(2021-11-22) 1
Added v0.29.1_(2021-04-28) 1
Added v0.28.4_(2021-04-23) 1
Added v0.21.0_(2020-11-30) 1
Added v0.20.11_(2020-09-25) 1
Added v0.20.5_(2020-09-16) 1
Added v0.13.2_(2020-03-20) 1
Added v0.11.1_(2020-02-11) 1
Added v0.10.0_(2019-10-28) 1
Added v0.9.2_(2019-10-1) 1
Added Changed 1
Added v0.3.20_(2022-07-12) 1
Added v0.3.18_(2022-03-31) 1
Added v0.3.16_(2022-02-23) 1
Added v0.3.12_(2021-08-24) 1
Added v0.3.11_(2021-07-14) 1
Added v0.3.9_(2021-04-20) 1
Added v0.2.0_(2020-04-15) 1
Added v0.1.1_(2020-02-11) 1
Added v0.0.3_(2020-07-15) 1
Adding_Tests Design_Principles 1
Generating_Golden_Values Tips_And_Tricks 1
Reduction_Modes Further_Reading 1
Sanity-checking_for_FP16_limitations Debugging_accuracy_failures 1
*Polygraphy_supports_only_Python_3.6_and_later.*_*Before Installing_Prebuilt_Wheels 1
/On_Linux,_the_command-line_toolkit_is_usually_installed_to Building_From_Source 1
Building_Manually Installing_Dependencies 1
Building_Manually Examples 1
/By_default,_dependencies_will_be_installed_using_the_current Installing_Manually 1
Installing_Manually Command-line_Toolkit 1
Python_API Examples 1
Examples Raw_Binary_Request 1
Examples Unload 1
Examples Reference 2
Examples Determinism_when_scanning 2
Examples *ai.onnx.ml.Binarizer* 1
Examples *ai.onnx.ml.CastMap* 1
Examples *ai.onnx.ml.LinearClassifier* 1
Examples *Acosh* 1
Examples *Add* 1
Examples *AffineGrid* 1
Examples *And* 1
Examples *ArgMax* 1
Examples *ArgMin* 1
Examples *Asin* 1
Examples *Asinh* 1
Examples *Atan* 1
Examples *Atanh* 1
Examples *AveragePool* 1
Examples *BatchNormalization* 1
Examples *Bernoulli* 1
Examples *BitShift* 1
Examples *BitwiseAnd* 1
Examples *BitwiseNot* 1
Examples *BitwiseOr* 1
Examples *BitwiseXor* 1
Examples *BlackmanWindow* 1
Examples *Cast* 1
Examples *CastLike* 1
Examples *Ceil* 1
Examples *Celu* 1
Examples *CenterCropPad* 1
Examples *Clip* 1
Examples *Col2Im* 1
Examples *Compress* 1
Examples *Concat* 1
Examples *ConcatFromSequence* 1
Examples *ConstantOfShape* 1
Examples *Conv* 1
Examples *ConvInteger* 1
Examples *ConvTranspose* 1
Examples *Cos* 1
Examples *Cosh* 1
Examples *CumSum* 1
Examples *DFT* 1
Examples *DeformConv* 1
Examples *DepthToSpace* 1
Examples *DequantizeLinear* 1
Examples *Det* 1
Examples *Div* 1
Examples *Dropout* 1
Examples *DynamicQuantizeLinear* 1
Examples *Einsum* 1
Examples *Elu* 1
Examples *Equal* 1
Examples *Erf* 1
Examples *Exp* 1
Examples *Expand* 1
Examples *EyeLike* 1
Examples *Flatten* 1
Examples *Floor* 1
Examples *GRU* 1
Examples *Gather* 1
Examples *GatherElements* 1
Examples *GatherND* 1
Examples *Gelu* 1
Examples *Gemm* 1
Examples *GlobalAveragePool* 1
Examples *GlobalLpPool* 1
Examples *Greater* 1
Examples *GreaterOrEqual* 1
Examples *GroupNormalization* 1
Examples *HammingWindow* 1
Examples *HannWindow* 1
Examples *HardSigmoid* 1
Examples *HardSwish* 1
Examples *Hardmax* 1
Examples *Identity* 1
Examples *If* 1
Examples *ImageDecoder* 1
Examples *InstanceNormalization* 1
Examples *IsInf* 1
Examples *IsNaN* 1
Examples *LRN* 1
Examples *LSTM* 1
Examples *LayerNormalization* 1
Examples *LeakyRelu* 1
Examples *Less* 1
Examples *LessOrEqual* 1
Examples *LogSoftmax* 1
Examples *Loop* 1
Examples *LpNormalization* 1
Examples *MatMul* 1
Examples *MatMulInteger* 1
Examples *Max* 1
Examples *MaxPool* 1
Examples *MaxRoiPool* 1
Examples *Mean* 1
Examples *MeanVarianceNormalization* 1
Examples *MelWeightMatrix* 1
Examples *Min* 1
Examples *Mish* 1
Examples *Mod* 1
Examples *Mul* 1
Examples *Multinomial* 1
Examples *NegativeLogLikelihoodLoss* 1
Examples *NonMaxSuppression* 1
Examples *NonZero* 1
Examples *Not* 1
Examples *OneHot* 1
Examples *Optional* 1
Examples *Or* 1
Examples *PRelu* 1
Examples *Pad* 1
Examples *Pow* 1
Examples *QLinearConv* 1
Examples *QLinearMatMul* 1
Examples *QuantizeLinear* 1
Examples *RNN* 1
Examples *RandomNormal* 1
Examples *Reciprocal* 1
Examples *ReduceL1* 1
Examples *ReduceL2* 1
Examples *ReduceLogSum* 1
Examples *ReduceLogSumExp* 1
Examples *ReduceMax* 1
Examples *ReduceMean* 1
Examples *ReduceMin* 1
Examples *ReduceProd* 1
Examples *ReduceSum* 1
Examples *ReduceSumSquare* 1
Examples *RegexFullMatch* 1
Examples *Relu* 1
Examples *Reshape* 1
Examples *Resize* 1
Examples *ReverseSequence* 1
Examples *RoiAlign* 1
Examples *Round* 1
Examples *STFT* 1
Examples *Scan* 1
Examples *Scatter*_(deprecated) 1
Examples *ScatterElements* 1
Examples *ScatterND* 1
Examples *Selu* 1
Examples *SequenceAt* 1
Examples *SequenceLength* 1
Examples *Shape* 1
Examples *Shrink* 1
Examples *Sigmoid* 1
Examples *Sign* 1
Examples *Sin* 1
Examples *Sinh* 1
Examples *Size* 1
Examples *Slice* 1
Examples *Softmax* 1
Examples *SoftmaxCrossEntropyLoss* 1
Examples *Softplus* 1
Examples *Softsign* 1
Examples *SpaceToDepth* 1
Examples *Split* 1
Examples *SplitToSequence* 1
Examples *Sqrt* 1
Examples *Squeeze* 1
Examples *StringConcat* 1
Examples *StringNormalizer* 1
Examples *StringSplit* 1
Examples *Sub* 1
Examples *Sum* 1
Examples *Tan* 1
Examples *Tanh* 1
Examples *TfIdfVectorizer* 1
Examples *ThresholdedRelu* 1
Examples *Tile* 1
Examples *TopK* 1
Examples *Transpose* 1
Examples *Trilu* 1
Examples *Unique* 1
Examples *Unsqueeze* 1
Examples *Upsample*_(deprecated) 1
Examples *Where* 1
Examples *Xor* 1
Examples ai.onnx.preview.training 1
Examples *ai.onnx.preview.training.Adam* 1
Examples *ai.onnx.preview.training.Gradient* 1
Examples *ai.onnx.preview.training.Momentum* 1
To_help_you_get_started_with_the_API,_you_can_use_the Backends 1
Runners_may_reuse_their_output_buffers._Thus,_if_you_need Writing_A_Custom_Runner 1
Writing_A_Custom_Runner Comparator 1
The_Comparator_is_designed_for_scenarios_where_you_need_to Data_Loaders 1
Polygraphy_provides_a_default_=DataLoader=_class_that_uses_numpy Logger 1
Building_Python_API_Documentation_Locally Deprecation_Policy 1
Modifying_Input_Shapes_In_An_ONNX_Model Advanced_Topics 1
Reducing_Failing_ONNX_Models Examples 1
For_CLI_run,_please_go_to_the_cloned_repository's_root_directory 2._Data_preparation 1
B._Conversion_to_tfrecord Workflow 1
2.2._TensorRT_Inference Additional_resources 1
Aware_Training*  1
Step_4__TensorRT_Deployment Results 1
Step_3__TensorRT_Deployment Results 3
no_residual_connections_exist_in_MobileNet-v1. MobileNet-v2 1
MobileNet-v2 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/efficientnet][EfficientNet]] 1
residual_connections_exist_in_MobileNet-v2. Notes 1
QAT Only_accuracy 1
Layer_Class NVIDIA(R)_vs_TensorFlow_Toolkit 1
Perform_custom_quantization_on_a_ResNet-like_model._More *Default_Quantization* 1
*Custom_Quantization_with_'Custom_Q/DQ_Insertion_Case'_(optimal)* *Library_provided_custom_Q/DQ_insertion_cases* 1
Layers* Layers*_Other_layers_are_inherited_from_=BaseQuantizeWrapper= 1
Layers*_Other_layers_are_inherited_from_=BaseQuantizeWrapper= *How_to_add_a_new_wrapper?* 1
ResNet101-v2 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/mobilenet][MobileNet]] 1
EfficientNet-B3 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/inception][Inception]] 1
>=_2.8\\ >=_1.10.1\\ 1
(optional)_>=_8.4_GA Installation 1
Local Documentation 1
Documentation License 1
You_still_need_to_set_=Graph=_inputs_and_outputs_yourself! Running_the_example 1
be_folded_-_=((x_+_c0)_+_c1)_+_c2=_will_*not*_be_folded,_even Prerequisites 1
Tensor example_constant_tensor_from_ResNet50_* 1
Node example_ReLU_node_from_ResNet50_* 1
Graph Exporters 1
Exporters Advanced 1
Of_Contents* Description 2
Setup_the_algorithm_selectors Preparing_sample_data 1
Sample_=--help=_options Additional_resources 5
Sample_=--help=_options Models_other_than_ResNet-50_with_custom_configuration 1
- License 18
- per-tensor_dynamic_range_*_- 1
- - 1
2019*_-_This_=README.md=_file_was_recreated,_updated_and Known_issues 1
Of_Contents*_-_[[#description][Description]]_- Description 13
TensorRT_API_layers_and_ops Preparing_sample_data 4
TensorRT_API_layers_and_ops Prerequisites 1
TensorRT_API_layers_and_ops Running_the_sample 1
2022*_-_Migrated_code_from_parsing_a_=caffe=_model_to_an_=onnx= 2021*_-_Change_names_and_topic_from_"reformat-free"_to_"I/O 1
2019*_-_This_is_the_first_release_of_the_=README.md=_file_and Known_issues 1
Running_the_sample Additional_resources 3
Benchmark_Engine Inference 3
Inference Plot_the_final_results 1
Sample_Images Evaluate_mAP_Metric 1
This_sample_is_not_supported_on_Ubuntu_14.04_and_older. Prerequisites 1
2._EfficientNet_V2 Create_ONNX_Graph 1
INT8_Precision Benchmark_TensorRT_Engine 1
Benchmark_TensorRT_Engine Inference 1
Depending_on_the_saved_model_exporter,_some_EfficientNet_V1 Inference_in_Python 1
Please_make_sure_that_the_=onnx-graphsurgeon=_module_installed Model_Conversion 2
TFOD_EfficientDet_models_will_have_a_slightly_reduced_throughput 3._TFHub_Models 1
3._TFHub_Models Create_ONNX_Graph 1
Sample_--help_options Additional_resources 5
In_order_to_proceed,_you_need_to_re-export_the_saved_model._If Create_ONNX_Graph 1
If_you_receive_any_error_messages_about_non_sufficient_workspace INT8_Precision 1
Mask_R-CNN Evaluate_mAP_Metric 1
R-CNN*,_default_is_0.5. TF_vs_TRT_Comparison 1
onnx_resnet50 Prerequisites 1
-_[[https_//arxiv.org/pdf/1512.03385.pdf][Deep_Residual - 1
3._Application_Samples Known_Limitations 1
Of_Contents*_- Description 2
Additional_preprocessing_needs_to_be_applied_to_the_data_before TensorRT_API_layers_and_ops 1
Layer*_-_[[https_//arxiv.org/abs/1807.03247][Arxiv_paper_by -_[[https_//github.com/onnx/onnx][GitHub__ONNX]]_- 1
If_you_wanted_to_train_your_own_model_and_then_perform_inference TensorRT_API_layers_and_ops 1
Of_Contents*_-_[[#tensorrt-command-line-wrapper-trtexec][TensorRT Description 1
network*_-_If_you_have_a_model_saved_as_a_UFF_file,_ONNX engine_generation*_-_If_you_generate_a_saved_serialized 1
engine_generation*_-_If_you_generate_a_saved_serialized Building_=trtexec= 1
Example_6__Tune_throughput_with_multi-streaming Tool_command_line_arguments 1
Specifying_the_=--safe=_parameter_turns_the_safety_mode_switch Additional_resources 1
It's_important_to_preprocess_the_data_and_convert_it_to_the TensorRT_API_layers_and_ops 1
Enabling_proto2_features Generated_code 1
Extensions APIs 1
Serialization_performance The_cpp_performance_can_be_improved_by_using 1
To_iterate_over_all_oneofs Updating_Reflection 1
Programming_Languages C#__https_//silentorbit.com/protobuf/_*_C#/.NET/WCF/VB_ 1
Presence_in_proto3_APIs Semantic_differences 1
Considerations_for_change-compatibility How_to_enable_/explicit_presence/_in_proto3 1
Coding_Style Contributing_Process 1
Installation_from_PECL PHP_Package 1
Installation_from_composer Protoc 1
Protoc Usage 1
Example_build_invocation Options 1
Options displayInput___default=true_|_false=hide_input._*_displayPrevious__ 1
Windows_build To_push_artifacts_to_Maven_Central 1
Use_Java_Protocol_Buffers_with_Bazel Build_from_Source 1
Build_from_Source_-_Without_Maven Compatibility_Notice 1
dependent_packages* for_Mac_users* 1
for_AIX_users* C++_Installation_-_Windows 1
(no_default) Objective_C_Generator_=protoc=_Options 1
C Run_instructions 1
C Benchmark_datasets 1
CPP_generated_code_ Go 1
CPP_generated_code_ Go_ 1
PHP_with_c_extension Node.js 2
Unit_Tests Compiling 1
Of_Contents*_-_[[#description][Description]]_* Description 30
input*_The_scores_input_are_of_shape Parameters 1
Parameters Limitations 1
Parameters License 1
Parameters Additional_Resources 1
Structure Parameters 28
Structure Additional_resources 1
Structure SIG_-_Special_Interest_Groups 1
-_[[https_//arxiv.org/pdf/1812.05784][PointPillars]] License 3
The_above_settings_are_slightly_different_to_the_original Additional_resources 1
Of_Contents*_-_[[#changelog][Changelog]]_- Changelog 1
Transformation*__This_flag_primarily_defines_various_offsets Malformed_Boxes_by_+1*__Some_legacy_implementations_of_ROI 1
Malformed_Boxes_by_+1*__Some_legacy_implementations_of_ROI Additional_Resources 1
Additional_Resources  1
-_[[https_//arxiv.org/abs/1506.04579][ParseNet_Paper]]\\ License 1
Anchors_Input_(Optional) Dynamic_Shape_Support 1
Using_the_Fused_Box_Decoder Additional_Resources 1
-_[[https_//arxiv.org/abs/1512.02325][SSD__Single_Shot License 2
=t_w=_and_=t_h=_from_the_input_remain_unchanged. Parameters 1
-_[[https_//arxiv.org/abs/1612.08242][YOLOv2_paper]] License 1
-_[[https_//arxiv.org/pdf/2010.04159.pdf][Deformable_DETR]] License 1
-_[[https_//arxiv.org/abs/1504.08083][Original_ROI License 1
-_[[https_//arxiv.org/abs/1504.08083][ROI_Pooling License 1
-_[[https_//arxiv.org/abs/1810.04805][BERT]] License 1
-_[[https_//arxiv.org/abs/1706.03762][Transformer]] License 1
-_[[https_//arxiv.org/abs/1506.01497][Faster_R-CNN]] License 1
This_code_is_almost_the_same_to_=CodeTypeSSD__CENTER_SIZE=_using =inputOrder= 1
=inputOrder= Additional_resources 1
Of_Contents*_-_[[#coordconvacplugin][coordConvACPlugin]]_- Description 1
What_if_the_limit_is_zero? 7._Verify_download 1
Run_Hello_World_MLCube_example Setup_Docker 1
Workspace MNIST_MLCube_directory_structure_summary 1
docs-site_Action_Development_documentation python-publish_action 1
On_Windows Installation 1
NEW__The_KiTS23_Challenge_is_Underway! KiTS19 1
Labeling_Errors Challenge_Results_and_References 1
[[https_//schema.org/Text][sc_Text]] column 1
[[https_//schema.org/Text][sc_Text]] jsonPath 1
[[https_//schema.org/Text][sc_Text]] Reference 1
[[https_//schema.org/Text][sc_Text]] BoundingBox 1
BoundingBox Properties 1
[[#fileobject][FileObject]],_[[#fileset][FileSet]] includes 1
[[#fileset][FileSet]] excludes 1
[[#fileset][FileSet]] source 1
[[#recordset][RecordSet]],_[[#field][Field]] key 1
[[#recordset][RecordSet]] field 1
[[#recordset][RecordSet]] subField 1
[[#recordset][RecordSet]] transform 1
[[#field][Field]] parentField 1
[[#field][Field]] dataType 1
[[#field][Field]] references 1
[[#field][Field]] data 1
[[#datasource][DataSource]] format 1
[[#datasource][DataSource]] Open_issues/questions 1
Loading_a_=distribution=_via_HTTP_with_Basic_Auth Programmatically_build_JSON-LD_files 1
note/*__It's_worth_pointing_out_that_we_divide_the_loss_by Gradient_computation_&_optimization 3
Gradient_computation_&_optimization Hands-on_--_Let's_train_an_NMT_model 3
Inference_--_How_to_generate_translations Intermediate 3
matters_in_the_attention_mechanism?/* Attention_Wrapper_API 3
Hands-on_--_building_an_attention-based_NMT_model Tips_&_Tricks 3
Three_models_in_a_single_graph_and_sharing_a_single_Session* Three_models_in_three_graphs,_with_three_Sessions_sharing_the 3
Three_models_in_three_graphs,_with_three_Sessions_sharing_the Data_Input_Pipeline 3
module._Data_iterators_are_flexible,_easy_to_reason_about_and Other_details_for_better_NMT_models 1
Bahdanau-style_attention_often_requires_bidirectionality Multi-GPU_training 3
Multi-GPU_training Benchmarks 3
Multi-GPU_training Abstractions 2
Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s WMT_German-English 3
Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s WMT_English-German_---_Full_Comparison 3
Standard_HParams Other_resources 3
Reproduced_papers List_of_all_sorted_CM_scripts 2
Third_level_files Examples 2
Differentiating_ML_artifacts Environment_variables 2
rename CM_internal_automations 2
default,_CM_will_pull_Git_repositories_and_cache_installations_and Ubuntu,_Debian 2
that_you_must_set_up_virtual_env_on_Ubuntu_23+_before_using_any Red_Hat 2
Show/clean_CM_cache_with_all_installations Windows 2
2022 Resources 2
2021-2023_[[https_//mlcommons.org][MLCommons]] [[../LICENSE.md][Apache_2.0]] 2
[[../LICENSE.md][Apache_2.0]] Collective_Mind_automation_language_(CM) 2
Power_Measurement_Setup Reproducing_the_Nvidia_Jetson_AGX_Orin_Submission 6
Full_run Resnet50 4
Full_run Retinanet 4
Full_run RNNT 4
Full_run 3d-unet 4
Other_backends Run_benchmarks_and_submit_results 4
Measure_power Debug_benchmarks 4
Debug_benchmarks  4
Add_new_data_set Participate_in_reproducibility_and_optimization_challenges 4
BERT-99.9%__MobileBERT_Offline_-_DeepSparse ResNet50 6
System_requirements_to_run_MLPerf_on_Nvidia_GPU MLCommons_CM_automation_meta-framework 2
Compile_MLPerf_loadgen CM_automation_for_the_MLPerf_benchmark 6
Prepare_MLPerf_submission Trying_deepsparse_backend 4
Run_Command Run_ResNet50_TFLite_via_CM 2
What_is_the_difference_between_Repeatability,_Reproducibility_and Discussions 2
Running_the_power_server_inside_a_docker_container Running_a_dummy_workload_with_power_(on_host_machine) 2
Run_a_dummy_workload_with_power_inside_a_docker_container Running_MLPerf_Image_Classification_with_power 2
Running_MLPerf_Image_Classification_with_power_inside_a_docker Further_questions? 2
in_the_same_repository_(specified_by_/./) Viewing_CM_meta_description 2
Creating_other_types_of_artifacts Reusing_others'_artifacts_in_the_CM_format 2
From_zip_file Adding_reusable_automations_for_related_artifacts 2
and_a_/module.py*_with_the_automation_actions_implemented_as Extending_meta_descriptions_of_artifacts 2
STMicroelectronics_NUCLEO-L4R5ZI Download_and_run_EEMBC_Energy_Runner 2
With_one_CM_command_that_will_install_all_dependencies Use_Python_virtual_environment_with_CM_and_MLPerf 2
With_one_CM_command_that_will_install_all_dependencies The_next_steps 2
Use_Python_virtual_environment_with_CM_and_MLPerf The_next_steps 2
Extra_system_requirements_for_Nvidia_GPU MLCommons_CM_automation_language 2
Install_ONNX_runtime_for_CPU Download_Bert-large_model_(FP32,_ONNX_format) 2
fp32 Acknowledgments 2
Install_virtual_environment CM_automation_for_the_MLPerf_benchmark 2
Stage/*_##_Run_Commands_###_Quick_submission_run_(short_run) Customizations 2
Run_experiments Second_approach__adding_CM_interface_to_your_research_project 2
Run_experiments Notes 3
Run_experiments Setup_for_RPi4_CPU 1
Git_project Adding_CM_script_to_prepare_and_run_your_experiment 2
CUDA Backend_(ML_framework) 2
TVM_ONNX_(Python) Datasets 2
Power_measurements Prepare_submission 2
Prepare_submission The_next_steps 2
2023 Resources 2
Artifacts_reusable_(pilot_project_with_MLCommons) Distinguished_artifact_award 2
can_skip_this_step_if_you_want_to_share_your_artifacts_without_the Making_artifacts_available_to_evaluators 2
if*_they_have_been_placed_on_any_publicly_accessible_archival Submitting_artifacts 2
Models Installation 2
Please_check_the How_to_deal_with_numerical_accuracy_and_instability? 2
V1.0.0 Prototyping_phase 2
Reproduce_results_from_ACM/IEEE/NeurIPS_papers Project_coordinators 4
doc Maintainers 2
any Maintainers 2
uid Maintainers 2
reindex Maintainers 2
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__speech_recognition 4
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__recommendation 4
[[../README.md][TOC]]_]* Customize_MLPerf™_inference_benchmark 2
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__object_detection 4
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__image_classification 4
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__NLP 4
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__medical_imaging 2
[[../README.md][TOC]]_]* Ideas_to_improve_CK 2
[[../README.md][TOC]]_]* Ideas_to_improve_automation 2
[[../README.md][TOC]]_]* Standardization 2
[[../README.md][TOC]]_]* Preparing_models 2
[[../README.md][TOC]]_]* Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Object_Detection_- 2
[[../README.md][TOC]]_]* Reproducibility_reports__MLPerf™_inference_benchmark_v1.1 2
[[../README.md][TOC]]_]* MLPerf™_Inference_v0.7_-_Image_Classification_-_Nvidia_Jetson_Xavier 2
[[../README.md][TOC]]_]* Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Image 2
[[../README.md][TOC]]_]* Common_setup_for_the_MLPerf_inference_benchmark 2
[[../README.md][TOC]]_]* Common_workflow_for_MLPerf_inference 2
[[../README.md][TOC]]_]* Misc_MLPerf™_inference_notes 2
[[../README.md][TOC]]_]* Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit 2
[[../README.md][TOC]]_]* Nvidia-based_generic_platforms_with_Ubuntu 2
[[../README.md][TOC]]_]* Nvidia_Jetson_Nano_board 2
[[../README.md][TOC]]_]* Rapsberry_Pi_4_with_a_standard_port_of_Debian 2
[[../README.md][TOC]]_]* x8664-based_generic_platforms_with_Yocto 2
[[../README.md][TOC]]_]* Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit_with_Coral_Edge 2
[[../README.md][TOC]]_]* x8664-based_generic_platforms_with_Ubuntu 2
[[../README.md][TOC]]_]* Example_of_CK_dashboards_for_ML_Systems_DSE 2
[[../README.md][TOC]]_]* Analyse_MLPerf™_inference_results 2
[[../README.md][TOC]]_]* Automated_design_space_exploration_of_ML/SW/HW_stacks 2
[[../README.md][TOC]]_]* CK_workflows_for_speech_recognition_with_PyTorch 2
[[../README.md][TOC]]_]* CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_PyTorch 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_TensorFlow 2
[[../README.md][TOC]]_]* CK_workflows_for_object_detection_with_TFLite 2
[[../README.md][TOC]]_]* CK_workflows_for_object_detection_with_ONNX 2
[[../README.md][TOC]]_]* CK_workflows_for_object_detection_with_TensorRT 2
[[../README.md][TOC]]_]* CK_workflows_for_the_MLPerf_inference_benchmark 2
[[../README.md][TOC]]_]* CK_workflows_for_language_(NLP)_with_ONNX 2
[[../README.md][TOC]]_]* CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_ONNX 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_TVM 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_OpenVino 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_PyTorch 2
[[../README.md][TOC]]_]* CK_workflows_for_object_detection_with_TVM 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_ONNX 2
[[../README.md][TOC]]_]* CK_workflows_for_image_classification_with_TFLite 2
[[../README.md][TOC]]_]* MLPerf™ 2
[[../README.md][TOC]]_]* Upgrade_the_CK_framework 2
[[../README.md][TOC]]_]* Logging_infrastructure 2
[[../README.md][TOC]]_]* MLCube™_project 2
[[../README.md][TOC]]_]* Continuous_integration_for_CK_workflows 2
[[../README.md][TOC]]_]* CK_components_for_ML_Systems_(automation_recipes) 2
MLPerf_inference_v1.1__Image_Classification__DSE_(Pareto Install_system_dependencies 6
Development_(live)_components_for_MLPerf Activate_virtual_environment 16
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.5.0_RUY_(x86) 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v0.5_-_Image_Classification_-_OpenVino_2019_R3 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_2.4.1_with_RUY 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1_(x86) 2
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on System_packages 2
Install_Collective_Knowledge_(CK) Pull_[[https_//github.com/mlcommons/ck-mlops][CK_MLOps_repository]] 4
Install_COCO_2017_val_dataset_(5000_images)_and Setup_for_EdgeTPU_(Host__RPi_4) 2
Install_COCO_2017_val_dataset_(5000_images)_and Setup_for_RPi4_CPU 2
MLPerf_inference_v1.1__Image_Classification__Resnet50__ONNX_(out Install_system_dependencies 4
MLPerf_inference_v1.1__Image_Classification__Resnet50_ Install_system_dependencies 4
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM__AWS Install_system_dependencies 6
by_the Reproducing_MLPerf™_inference_benchmarks_(v0.7_and_v1.0) 2
Using_CK_adaptive_containers_(to_be_tested!) Other_reproducibility_studies 2
Preprocess_using_OpenCV_(better_accuracy_but_may_fail_on_some Optional__install_reduced_ImageNet_2012_val_dataset_with_the_first 2
Performance__Single_Stream_(500_samples) note_from_the_community_*_A_valid_SingleStream_performance_run 6
Performance__Offline_(500_samples) note_from_the_community_*_A_valid_Offline_performance_run 6
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM__GCP Install_system_dependencies 2
Preprocess_using_pillow_(slightly_worse_accuracy_but_works_most_of Install_reduced_ImageNet_2012_val_dataset_with_the_first_500_images 4
Preprocess_using_pillow_(slightly_worse_accuracy_but_works_most_of Install_framework_TFLite_2.4.1_with_RUY 4
ResNet-50_(no-argmax) Run_MLPerf™_benchmark 2
System_packages Install_Collective_Knowledge_(CK)_and_Virtual_Environment 2
Linux Run_a_container_and_record_experiments_locally 2
Linux Load_and_run_a_model_in_C++ 2
Run_a_container_with_external_ImageNet  2
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM_ Install_system_dependencies 2
20210723 PyTorch_1.5.0_*_TorchVision_0.6.0_(works_with_PyTorch_1.5.0)_*_ONNX 2
Install_any_available_version Install_CK_packages_with_ONNX_(GPU) 2
Install_any_available_version Notes 4
Install_any_available_version Install_CK_packages_with_TensorFlow_(GPU) 2
Install_any_available_version Tested_configurations 2
Export_all_MLPerf_inference_results Coordinator 2
that_this_CK-MLPerf_documentation_is_discontinued_after_the MLPerf™_inference_benchmark_automation 2
Customizable_dashboards Table_of_contents 2
TensorRT Test_CK_automation_(platform_detection) 2
TensorRT Building_for_JetPack_4.x 1
View_CK_dashboard_in_your_browser Demo_of_a_Docker_with_MLPerf™_dashboards_for_ML_Systems_DSE_(Linux 2
Download_and_install_MLPerf™_inference_results_via_CK Available_results 2
v1.0  2
[[../README.md][Back_to_TOC]]_]* Shortcuts 6
TF_SSD_Mobilenet-v1_non-quantized Convert_COCO_to_1200x1200 2
Preprocess_using_Pillow_(slightly_worse_accuracy_but_works_most_of Plug_in_full_ImageNet_2012_val_dataset_with_50000_images 2
MLPerf_tasks TBD 2
TBD Notes 2
Use_ONNX Scenario__Accuracy__Single_Stream 2
Use_ONNX Scenario__Performance__Single_Stream 2
model,image-classification,mlperf,onnx,resnet50,v1.5-opset-11 Scenario__Performance__Single_Stream 2
Install_SSD-ResNet34_1200x1200_non-quantized_fp32_for_ONNX_opset-8 Benchmark 2
Benchmark Analyze_experimental_results 2
Record_benchmarking_results_to_the_CK_repository Analyze_experimental_results 2
Start_Docker_while_mounting_CK_repository_with_experiments_ Integration_with_web_services_and_CI_platforms 2
Integration_with_web_services_and_CI_platforms Questions_and_feedback 4
Record_results_to_the_CK_repository PyTorch-based_models_for_CPU 2
Run_benchmark CK_automation 2
[[../reproduce/README.md#][Back_to_MLPerf_v1.1_reproducibility MLPerf_inference_v1.1_reproducibility_report_for_the_OctoML 2
and_simplifying_MLPerf Authors 2
Use_reduced_ImageNet_to_test_the_MLPerf_workflow Install_PyTorch_model_(Resnet50__int8__quantized) 2
Automated_workflows Coordinator 2
Update_program_sources Update_software_dependencies 2
Add_new_CK_packages /PACKAGE_DIR/_-_the_path_to_the_CK_package_entry._This_is_useful_if 2
Using_CK_modules Generate_reproducible_and_interactive_articles 2
Add_CK_entries_from_a_zip_file_to_an_existing_CK_repository CLI_to_manage_CK_entries 2
Copy_a_given_CK_entry CLI_to_manage_CK_actions 2
Android_(Linux_host) CK_installation 2
that_on_Windows_you_also_need_to_install_/ctuning@ck-win* Docker 2
Docker Further_info 2
actions/*_are_implemented_using modules/*_are_always_stored_in_*/module_/_<_CK_module_name_>/* 2
platform/*_to_help_the_community_share_CK_components,_create_live How_CK_supports_collaborative_and_reproducible_ML&systems_research 2
Push_data_to_a_dashboard Notes 2
that_the_1st_generation_of_the_CK_framework_was_discontinued_in Collective_Knowledge_framework_(CK) 2
Tutorials Releases 2
Stable_versions Current_projects 2
Other_use_cases CK_portal 2
Organizers Initial_discussion_and_materials 4
Generate_and_upload_MLPerf_submission Questions?_Suggestions? 2
Generate_MLPerf_submission Use_=--submitter=<Your_name>=_if_your_organization_is_an_official 2
Challenge  2
Test_CUDA_installation Install_Python_virtual_environment 4
Push_the_results_to_GitHub_repo Try_PyTorch_backend 4
Push_the_results_to_GitHub_repo Using_ARMNN_with_NEON 4
Push_the_results_to_GitHub_repo Tensorflow_backend 4
Try_PyTorch_backend Test_composable_ML_benchmark_with_other_models,_data_sets,_frameworks 4
Test_composable_ML_benchmark_with_other_models,_data_sets,_frameworks The_next_steps 4
Generate_actual_submission_tree Pytorch_backend 4
Generate_actual_submission_tree Tensorflow_backend 6
Generate_actual_submission_tree Tensorflow_backend_(Reference_implementation) 2
test Maintainers 8
Platform_information List_of_all_sorted_CM_scripts 2
show Maintainers 2
list_files_recursively Maintainers 2
add Maintainers 2
replay Maintainers 2
CM_script_execution_flow If_a_script_is_already_cached,_then_the_=preprocess=,_=run_file=_and 2
Dynamic_variations ENV_flow_during_CM_script_execution 2
Special_env_keys Script_Meta 2
Special_keys_in_script_meta How_cache_works? 2
prepare Maintainers 2
Caching_output_of_CM_scripts Assembling_pipeline_to_compile_and_run_image_corner_detection 2
Customizing_sub-dependencies_in_a_pipeline Using_Python_virtual_environments 2
CM_script_automation_help CM_CLI 406
CM_modular_Docker_container Customization 406
CLI_flags_can_be_used_in_the_Python_CM_API_as_follows_* Default_environment 162
CLI_flags_can_be_used_in_the_Python_CM_API_as_follows_* Script_flags_mapped_to_environment 14
Default_environment Script_workflow,_dependencies_and_native_scripts 271
How_to_use =[DOCKER_OS_VERSION]=_is_one_of_=18.04=,_=20.04=,_=22.04=_for_=ubuntu= 2
How_to_use =[--docker_os,_--docker_os_version,_--cm_repo_and_--script_tags]=_are 2
Versions Script_workflow,_dependencies_and_native_scripts 17
Versions Script_output 72
New_environment_keys_(filter) Maintainers 66
New_environment_keys_auto-detected_from_customize Maintainers 136
Default_variations Script_workflow,_dependencies_and_native_scripts 44
Valid_variation_combinations_checked_by_the_community Script_workflow,_dependencies_and_native_scripts 2
When_custom_config_files_are_generated_they_override_the Information 2
Supported_and_Tested_OS Examples 2
Supported_and_Tested_OS CLI 4
Detect_CUDA_on_Windows System_dependencies 2
ONNX,_CPU Run_command 2
Other_Input_Options_ Use_modular_Docker_container_with_the_CM_API 2
Choices_(flags) Example__MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_- 2
Detect_llvm_with_non-standard_name Force_new_detection_even_if_llvm_is_already_found_and_cached 2
Preprocess_the_dataset_with_=Channel=_component_at_beginning Input_Variables_coming_from_Dependencies 2
Docker_Setup Run_Commands 4
Further_analysis_of_results Contact_us 2
New_state CLI 2
Detect_python_with_non-standard_name Force_new_detection_even_if_python_is_already_found_and_cached 2
Using_Docker Future_work 2
Private_challenges Copyright 2
CK_components_can_be_found_at Author 1
CK_components_can_be_found_at Status 1
CK_components_can_be_found_at Minimal_CK_installation 1
Option_2_-_Execute_the_whole_ML_pipeline_from_a_Python_script_ _dart__Dashboard 1
🗺_Overview 🖥_Run_the_example 2
▶️_Run_the_Code CLI_Commands_for_the_Label_Studio_Integration 2
🧽_Clean_up 📜_Learn_more 2
SOON_*_We_also_recommend_you_check_out_our 🧰_How_the_example_is_implemented 1
🧰_How_the_example_is_implemented 🖥_Run_it_locally 1
ZenML_Test_Environments The_ZenML_Test_CLI 1
2.3_Copyright_license_back_to_You 3._Patents 1
3.2_Revocation_of_patent_license 4._License_obligations_by_Us 1
8.3_In_the_event_of_a_termination_of_this_Agreement_Sections_5., 9._Miscellaneous 1
Building_the_API_Docs_locally Contributors 1
the_server* up_a_local_ZenML_Server* 1
to_a_pre-existing_server* your_deployed_server_details* 1
your_deployed_server_details* The_ZenML_Dashboard_is_now_available 1
👣_How_to_migrate_your_Profiles Decoupling_Stack_Component_configuration_from_implementation 1
to_migrate*__Rename_all_references_to_=Repository=_in_your_code_to The_=BaseStepConfig=_class_is_now_called_=BaseParameters= 1
to_migrate*__Rename_all_references_to_=BaseStepConfig=_in_your_code Configuration_Rework 1
the_=enable_xxx=_decorators* to_migrate*__Simply_remove_the_decorator_and_pass_something_like 1
=pipeline.with_config(...)=* to_migrate*__Replaced_with_the_new_=pipeline.run(config_path=...)=. 1
=step.with_return_materializer(...)=* to_migrate*__Simply_remove_the_=with_return_materializer=_method 1
is_now_renamed_to_=DockerSettings=* to_migrate*__Rename_=DockerConfiguration=_to_=DockerSettings=_and 1
is_now_renamed_to_=ResourceSettings=* to_migrate*__Rename_=ResourceConfiguration=_to_=ResourceSettings= 1
the_=requirements=_and_=required_integrations=_parameters* to_migrate*__Simply_remove_the_parameters_and_use_the 1
to_migrate*__Simply_remove_the_parameters_and_use_the new_pipeline_intermediate_representation* 1
to_migrate*__If_you_have_written_a =PipelineSpec=_now_uniquely_defines_pipelines 1
to_migrate*__No_code_changes,_but_rather_keep_in_mind_the_behavior New_post-execution_workflow 1
to_migrate*__Replace_all_post-execution_workflows_from_the_paradigm 📡Future_Changes 1
GCR_container_registry Authentication_Methods 1
Authentication_Methods Caveats 1
Authentication_Methods How_do_you_use_it? 5
GCP_OAuth_2.0_token Auto-configuration 1
Local_and_remote_availability Register_Service_Connectors 1
Service_Connector_Verification Configure_local_clients 1
ACR_container_registry Authentication_Methods 1
Azure_Access_Token Auto-configuration 1
ECR_container_registry Authentication_Methods 1
AWS_Federation_Token Auto-configuration 1
Base_Abstraction_3__=Flavor= Implementing_a_Custom_Stack_Component_Flavor 2
Interactive_stack_deployment Displaying_Terraform_outputs_for_stacks_deployed_with_mlstacks 1
Container_Registry 7)_Create_Stack 2
7)_Create_Stack And_you're_already_done! 2
Trackers* Stores* 1
Registries* Other_configuration 1
Model_Registry_Flavors How_to_use_it 2
List_of_available_parameters Register_models_via_the_CLI 1
allow_you_to_send_messages_to_chat_services_(like_Slack, Alerter_Flavors 2
DISCORD_TOKEN How_to_Use_the_Discord_Alerter 1
Configuring_a_Custom_Seldon_Core_Secret* How_do_you_use_it? 1
with_various_tools_for_each_category._Once_code_is Available_integrations 1
In_a_ZenML_Step Secret_Schemas 2
Configuration_use-case__GCP_Service_Connector_with_different Configuring_the_stack 1
to_delete_a_scheduled_pipeline* Additional_configuration 1
Infrastructure_Deployment How_to_use_it 7
Infrastructure_Deployment How_to_find_the_registry_URI 1
job_->_S3* Enabling_CUDA_for_GPU-backed_hardware 1
Enabling_CUDA_for_GPU-backed_hardware Important_Note_for_Multi-Tenancy_Deployments 1
Build_your_own_custom_orchestrator Implementation_guide 1
repository_instead,_you'll_have_to How_to_find_the_registry_URI 1
container_registry_or_when_using_a_remote_container_registry Local_registry_URI_format 1
Advanced_Configuration How_do_you_use_it? 2
Artifact_Store_Flavors How_to_use_it 2
effect_on_the_=zenml.io.fileio=* Build_your_own_custom_artifact_store 1
Warning Stack_Component__=KubernetesSparkStepOperator= 1
Configuring_RBAC How_to_use_it 1
Call_Evidently_directly Visualizing_Evidently_Reports 1
Data_Validator_Flavors How_to_use_it 2
Call_whylogs_directly Visualizing_whylogs_Profiles 1
Experiment_Tracker_Flavors How_to_use_it 2
over_*pipeline-level*_defined_hooks._{%_endhint_%} Accessing_step_information_inside_a_hook 1
Supported_orchestrators Stopping/pausing_a_scheduled_run 1
Step_output_names Configure_steps/pipelines 1
and_caching* and_caching* 1
and_caching* Pass_any_kind_of_data_to_your_steps 1
artifacts*_can_be_used_to_pass_values_to_steps_that_are Using_a_custom_step_invocation_ID 1
Enable_or_disable_logs_storing Settings_in_ZenML 1
objects_or_dicts* Utilizing_the_settings 1
Storing_and_retrieving_the_artifact (Optional)_How_to_Visualize_the_Artifact 1
(Optional)_Which_Metadata_to_Extract_for_the_Artifact Usage 1
Configuring_materializers_at_runtime Basic_example 1
Example_ Visualization_via_Materializers 1
Example__Facets_Data_Skew_Visualization Custom_Class*_The 1
Step*_There_are_three_different_steps_in_the_=facets=_integration Disabling_Visualizations 1
Additional_logs* Client_and_server_logs 1
Updated*__October_17,_2023 Suggestions_for_Resolving_Dependency_Conflicts 1
Stacks,_Infrastructure,_Authentication Client_Methods 1
Methods* Methods* 1
Update,_and_Delete_Methods* Active_User_and_Active_Stack 1
Active_User_and_Active_Stack Resource_Models 1
Speeding_up_Docker_builds_for_containerized_components Registering_a_code_repository 1
Tracking_code_version_for_pipeline_runs Available_implementations 1
GitLab Developing_a_custom_code_repository 1
for_the_GPU_hardware_to_be_properly_utilized._If_you_don't 1._*Specify_a_CUDA-enabled_parent_image_in_your_=DockerSettings=* 1
If_I_share_my_email,_will_you_spam_me? Version_mismatch_(downgrading) 1
Automate_build_reuse_by_connecting_a_code_repository Customize_the_Docker_building 1
files_get_included* Installing_additional_pip_dependencies_or_apt_packages 1
What_is_already_built_in? How_do_I_use_it? 1
that_allows_you_to_fetch_or_reference_them_in_your_pipelines_and Centralized_secrets_store 2
register_missing_secrets_for_your_stack* Set_scope_for_secrets 1
Deploying_a_ZenML_Server Using_the_ZenML_CLI_to_connect_to_a_deployed_ZenML_Server 1
This_simply_means_that_any_pipeline_you_run_will_be_using_the stack*_as_its_environment._{%_endhint_%}_{%_endtab_%}_{%_endtabs 1
stack*_as_its_environment._{%_endhint_%}_{%_endtab_%}_{%_endtabs Components_of_a_stack 1
store*. Orchestrator 1
store*_and_then_loaded_from_there_when_the_next_step_needs Registering_a_stack 1
List_Pipelines_via_CLI Runs 1
Component-Specific_Metadata Steps 1
Step_Information Artifacts 1
Artifact_Visualizations Code_Example 1
set_caching_to_=False=_on_steps_that_depend_on_*external Configuring_caching_behavior_of_your_pipelines 1
is_a_Python_package_that_can_be_installed_directly_via_=pip=_ Install_with_the_dashboard 1
is_an_extensible,_open-source_MLOps_framework_for_creating 1._Development 1
Parameters_&_Settings 2._Execution 1
tailored_to_specific_use_cases/tools._With_ZenML_installed, Stack_Switching 1
Stack_Switching 3._Management 1
it_should_use,_the_*default_user_details,*_and_more._The Secret_store_environment_variables 1
Advanced_server_configuration_options Run_the_ZenML_server_with_Docker 1
ZenML_server_with_=docker-compose= Troubleshooting 1
Troubleshooting Apply_Perf_Optmization_(AGX_and_NX_applicable) 6
Troubleshooting Setup_the_Jetson_Orin_NX_System 2
Troubleshooting Apply_Perf_Optmization_for_AGX/NX 1
Troubleshooting Apply_Perf_Optmization 9
Optional_cluster_services ZenML_Helm_Installation 1
Connect_to_the_deployed_ZenML_server ZenML_Helm_Deployment_Scenarios 1
Use_a_DNS_service_to_map_a_different_hostname_to_the_Ingress Secret_Backends 1
Having_an_existing_NGINX_Ingress_Controller Existing_hosted_SQL_database 1
Existing_hosted_SQL_database Configuration_file_templates 1
Cloud-specific_settings Connecting_to_deployed_ZenML 1
🚨_Reporting_a_Vulnerability Coding_Conventions 1
A_private,_written_warning_from_community_leaders, 2._Warning 1
A_warning_with_consequences_for_continued_behavior._No 3._Temporary_Ban 1
A_temporary_ban_from_any_sort_of_interaction_or_public 4._Permanent_Ban 1
A_permanent_ban_from_any_sort_of_public_interaction Attribution 1
document._-_[_]_If_my_change_requires_a_change_to Types_of_changes 1
Changelog*_ 0.45.4 1
Changelog*_ 0.45.3 1
Changelog*_ 0.45.2 1
Changelog*_ 0.44.3 1
Changelog*_ 0.44.1 1
Changelog*_ 0.43.0 1
Changelog*_ 0.42.1 1
Changelog*_ 0.42.0 1
Changelog*_ 0.41.0 1
Changelog*_ 0.40.3 1
Changelog*_ 0.40.2 1
Changelog*_ 0.40.1 1
Changelog*_ 0.40.0 1
Changelog*_ 0.39.1 1
Changelog*_ 0.39.0 1
Changelog*_ 0.38.0 1
Changelog*_ 0.37.0 1
Changelog*_ 0.36.1 1
Changelog*_ 0.36.0 1
Changelog*_ 0.35.1 1
Changelog*_ 0.35.0_(YANKED) 1
Changelog*_ 0.34.0 1
Changelog*_ 0.33.0 1
Changelog*_ 0.32.1 1
Changelog*_ 0.32.0 1
Changelog*_ 0.31.1 1
Changelog*_ 0.31.0 1
Changelog*_ 0.30.0 1
Changelog*_ 0.23.0 1
Changelog*_ 0.22.0 1
Changelog*_ 0.21.1 1
Changelog*_ 0.21.0 1
Changelog*_ 0.20.5 1
Changelog*_ 0.20.4 1
Changelog*_ 0.20.3 1
Changelog*_ 0.20.2 1
Changelog*_ 0.20.0_/_0.20.1 1
Changelog*_ 0.13.2 1
Changelog*_ 0.13.1 1
Changelog*_ 0.13.0 1
Changelog*_ 0.12.0 1
Changelog*_ 0.11.0 1
Changelog*_ 0.10.0 1
Changelog*_ 0.9.0 1
Changelog*_ 0.8.1 1
Changelog*_ 0.8.0 1
Changelog*_ 0.7.2 1
Changelog*_ 0.7.1 1
Changelog*_ 0.6.3 1
Changelog*_ New_Features 1
Changelog*_ 0.5.5 1
Changelog*_ 0.5.4 1
Changelog*_ 0.5.3 1
Changelog*_ 0.5.2 1
Changelog*_ 0.5.1 1
If_you_upgraded_to_ZenML_v0.45.2_or_v0.45.3_and_are What's_Changed 1
What's_Changed 0.44.0 1
What's_Changed 0.7.0 1
What's_Changed 0.6.1 1
If_you_upgraded_to_ZenML_v0.45.2_and_are_experiencing What's_Changed 1
This_change_disrupts_existing_pipeline_schedules._After Performance_enhancements_(#3207) 1
Changelog*__https_//github.com/zenml-io/zenml/compare/0.44.2...tes 0.44.2 1
/0.44.0_was_removed_from_pypi_due_to_an_issue_with_the_alembic What's_Changed 1
Disable_Implicit_Auth_Methods_for_Service_Connectors_by_Default What's_Changed 1
Dependency_and_Integration_Version_Updates What's_Changed 1
it_is_not_recommended_to_continue_using_MLflow_older_than Breaking_Changes 1
Breaking_Changes Changes_in_D3_5.0 1
/This_release_replaces_the_previous_0.35.0_release_that_was Breaking_Changes 1
🙌_Community_Contributions 0.7.3 1
New_Contributors 0.6.2 1
What's_changed 0.6.0 1
➕_Other_updates,_additions_and_fixes 0.5.7 1
Overview 0.5.0 1
What_to_expect_in_the_next_weeks_and_the_new_ZenML 0.5.0rc2 1
What_to_expect_in_the_next_weeks_and_the_new_ZenML 0.3.7.1 1
Bug_Fixes_+_Refactor 0.3.7 1
Bug_Fixes_+_Refactor 0.3.6 1
Bug_Fixes_+_Refactor 0.3.5 1
Bug_Fixes_+_Refactor 0.3.4 1
👭_4._Start_the_Dashboard 🗺_Roadmap 1
Install_dependencies CLI 1
Install_dependencies Installation 2
Import_in_all_the_right_places Step_4__Create_a_PR_and_celebrate__tada_ 1
Install_the_Chart Configuration 1
Advanced_Options Telemetry 1
Authentication_for_Google_Cloud_Container_Registry Installation 1
Trigger_build_and_push_of_images_on_other_branch GCP_Data_and_Experiment_Integration 1
Saving_Experiments_to_GCP Getting_Information_from_a_Container 1
Mounting_Local_Repository Submitting_PRs 1
Other_Info ToDo 1
for_NVIDIA_GPU_set_up*__You_may_have_to_install_the Building_Docker_Image 1
Using_Singularity/Apptainer_instead_of_Docker Getting_Started 1
Shared_data_pipelines_between_JAX_and_PyTorch FAQS 1
How_do_I_run_this_on_my_SLURM_cluster? Submissions 1
Can_submission_be_structured_using_multiple_files? Citing_AlgoPerf_Benchmark 1
Start_tmux_session_(Recommended) Datasets 1
WMT FastMRI 1
Coding_your_submission Run_your_submission 1
to_score_your_submission_on_a_workload,_from_the Pytorch_DDP 1
Pytorch_DDP Run_your_submission_in_a_Docker_container 1
Docker_Tips Score_your_submission 1
0.0.16_/(Last_updated_28_April_2023)/ Introduction 1
Data_selection Evaluation_during_training 1
Software_dependencies Tuning 1
To_estimate_the_variance_of_the_results,_this_tuning_will_be Self-tuning_ruleset 1
Self-tuning_ruleset Workloads 1
Qualification_set Scoring 1
Alternative_scores Benchmark_Procedure 1
Requesting_Additional_Baselines Licensing 1
Awards_and_prize_money Model_Track 1
Expected_output Demonstration_case_2__Dynamic_batching 1
Inference_APIs Java_bindings_for_In-Process_Triton_Server_API 1
CPU-only_container_composition Build_it_yourself 1
CPU-Only_Build Building_Without_Docker 1
Extract_Build_Artifacts Building_on_Unsupported_Platforms 1
Development_Build_of_Backend_or_Repository_Agent Building_with_Debug_Symbols 1
The_repository_agent_API_is_beta_quality_and_is_subject_to Using_a_Repository_Agent 1
to_Triton_Inference_Server?*_Make_use_of *Installation* 1
to_Triton_Inference_Server?*_Make_use_of Serve_a_Model_in_3_Easy_Steps 1
Inference_Request/Response_Cache Model_Pipeline 1
Model_Pipeline *Resources* 1
Example_Request Generate_Response_JSON_Object 1
Example_Response Generate_Response_JSON_Error_Object 1
Example_Usage GRPC 1
Statistics_Response_JSON_Error_Object GRPC 1
Unregister CUDA_Shared_Memory 2
Unregister GRPC 1
Trace_Setting_Request_JSON_Object GRPC 1
Unload GRPC 1
Pending_Request_Count_(Queue_Size)_Per-Model Latencies 1
Summaries GPU_Metrics 1
Triton-reported_Response_Cache_Metrics Custom_Metrics 1
this_your_first_time_setting_up_a_model_repository?*_Check_out Repository_Layout 1
sure,_that_=TRITON_GCS_MOUNT_DIRECTORY=_exists_on_your_local S3 1
sure,_that_=TRITON_AWS_MOUNT_DIRECTORY=_exists_on_your_local Azure_Storage 1
sure,_that_=TRITON_AZURE_MOUNT_DIRECTORY=_exists_on_your_local Cloud_Storage_with_Credential_file_(Beta) 1
Caching_of_Cloud_Storage Model_Versions 1
Python_model_using_Python_Backend Deploying_Decoupled_Models 1
this_your_first_time_writing_a_config_file?*_Check_out Minimal_Model_Configuration 1
Decoupled Maximum_Batch_Size 1
of_Tensors_as_Input_/* Auto-Generated_Model_Configuration 1
Default_Max_Batch_Size_and_Dynamic_Batcher Datatypes 1
Priority Ensemble_Model_Instance_Groups 1
Ensemble_Model_Instance_Groups CUDA_Compute_Capability 1
Custom_Batching Sequence_Batcher 1
Ensemble_Scheduler Optimization_Policy 1
When_building_Triton_on_Jetson,_you_will_require_a_recent Runtime_Dependencies_for_Triton 1
Model_Instances Framework-Specific_Optimization 1
TensorFlow_Automatic_FP16_Optimization NUMA_Optimization 1
Other_Areas_of_Interest End-to-end_Example 1
gRPC_Endpoint Handling_in_Triton_Core 1
Currently,_Triton_core_does_not_detect_cancellation_status_of_a Handling_in_Backend 1
Initializing_State_from_File Scheduling_Strategies 1
Oldest Ensemble_Models 1
the_following_flags_are_*deprecated*_ Supported_Trace_Level_Option 1
3._Build_with_Debug_Flags* Specific_Issues 1
Symbols* Server_Issues 1
Deadlock Client_Issues 1
Performance_Profiling Submitting_an_Issue 1
Custom_Cache Deprecation_Notes 1
There_is_no_synchronization_between_when_Triton_polls_the Modifying_the_Model_Repository 1
to_Triton_Inference_Server_and_want_do_just_deploy_your_model Create_A_Model_Repository 1
Verify_Triton_Is_Running_Correctly Send_an_Inference_Request 1
A_clear_and_concise_description_of_what_the_bug_is. Information*_What_version_of_Triton_are_you_using? 1
Information*_What_version_of_Triton_are_you_using? Reproduce*_Steps_to_reproduce_the_behavior. 1
RELEASE__You_are_currently_on_the_main_branch_which_tracks to_Triton_Inference_Server?*_Make_use_of 1
Client_Support_and_Examples Extend_Triton 1
Additional_Documentation Contributing 1
A_demo_to_query_inception_model Additional_Resources 1
Helm_v3 Model_Repository 1
Helm_v2 Model_Repository 2
GCS_Permissions Deploy_Prometheus_and_Grafana 1
AWS_Model_Repository Deploy_Prometheus_and_Grafana 1
AWS_Model_Repository Deploy_the_Triton_Inference_Server 1
Supported_flavors Requirements 1
Triton_flavor Deploy_models_tracked_in_MLflow_to_Triton 1
Perform_inference MLflow_Deployments 1
Prometheus_ServiceMonitor_Support Using_Triton_Inference_Server 1
Of_Contents*_-_[[#models][Models]]_- Models 1
Only_original_source_code_from_you_and_other_people_that_have Contributing_code 6
Client_side bert-99.9 4
the_MLPerf_Inference_container*,_launch_a_Python_console_and_run NVIDIA_DGX_Stations,_this_method_will_fail*,_since_the_Mellanox_NICs 25
stopping*__under_the_new_rules,_/min_query_count/_is_no_longer_a Fixing_INVALID_results 25
refer_to_/closed/NVIDIA_for_detailed_instructions_for_NVIDIA_GPU H3C_Submission_Systems 1
refer_to_/closed/NVIDIA_for_detailed_instructions_for_NVIDIA_GPU Fujitsu_Submission_Systems 1
contains_RetinaNetNMS_PVA_kernel NMSPVAPlugin___Sample_application_to_demonstrate_how_to_use_this 14
Aarch64-Linux_or_Tegra-Linux_Specific_Paths Steps_to_build_the_standalone_plugin 14
Steps_to_build_the_standalone_plugin MACROS_in_the_NMSPVAPlugin 14
for_DLRMv2*,_the_dataset_is_quite_large._We_recommend that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and 6
the_above_steps_(/Download_the_datasets,_Downloading_the_model Setting_up_the_DLRMv2_Scratch_Space 6
measurements,_and_systems_directories_in_your_submission*_for later,_you_wish_to_remove_a_system*,_simply_edit_this_file_and 22
this_webpage_has_not_yet_been_finalized,_so_the Instructions_for_Auditors 22
you_proceed_to_try_to_build_and_run_from_this_directory,_it_is Running 2
Running Loading_and_processing_traces 2
Power_Regulator_Settings__OS_Control_Mode Fans 1
Thermal_Configuration__Optimal_Cooling Maximum_Frequency 1
Setup_with_docker_image Run_Benchmarks 3
option_2__pull_docker convert_dataset_and_model 23
2._End-to-end_run_inference Option_2__Build_docker_container 32
Run_Benchmarks_with_Int8 Docker_Instructions 16
Build Setup_Instructions_-_Docker 25
Quantize_Torchscript_Model_and_Check_Accuracy Run_Benchmark_(Common_for_Docker_&_Baremetal) 25
3.b_Option_3__pull_docker 4._Run_command_for_accuracy_and_performance 13
Preprocess_Data Run_the_Benchmark 7
Run_the_Benchmark Get_Started_with_ResNet50 4
Get_the_Results Get_started_with_BERT 7
Get_the_Results Get_started_with_DLRM2 4
Get_the_Results Get_Started_with_Retinanet 7
Get_the_Results Complinace_Test 1
Get_the_Results Get_started_with_DLRM 3
Get_the_Results Get_Started_with_ResNet50 3
Convert_Dataset_and_Model Run_the_Benchmark 7
Login_to_Docker_Container Preprocess_model_and_dataset 7
Login_to_Docker_Container Run_the_Benchmark 7
Calibrate_and_dump_int8_model Run_the_Benchmark 4
Get_the_results Get_Started_with_RNNT 7
9._run Docker 2
power_measurement*_with_VF_configuration,_you_need_to_allow Launching_the_environment_on_a_MIG_(Multi-Instance_GPU)_instance 14
Run_performance Results 4
Download_dataset Reproduce_results 1
generate_results_for_accuracy_and_performance_separately_add FP8_flow 1
refer_to_/closed/NVIDIA/README.md_for_detailed_instructions_for Dell_Technologies_Submission_Systems 1
Alternative_cross_compile_option Troubleshooting 18
USB-C_Power_Adapters Apply_Perf/W_Optmization_(only_AGX_applicable) 6
USB-C_Power_Adapters Download_Data,_Model_and_Preprocess_the_data 5
USB-C_Power_Adapters Running_a_Benchmark 3
USB-C_Power_Adapters Apply_Perf/W_Optmization_for_AGX 1
USB-C_Power_Adapters Apply_Perf/W_Optmization_for_NX 1
the_datasets_for_inferences*_described_in Running_a_Benchmark 6
DF_Cstates__Auto DF_Common_Options 54
NUMA_nodes_per_socket__NPS1 CPU_Common_Options 1
SMT_Control__Disable Prefetcher_Settings 1
SMT_Control__Disable Management_Firmware_Settings 2
SMT_Control__Disable Global_C-state_Control__Enabled 16
L2_Up/Down_Prefetcher__Auto Core_Performance_Boost__Disable 1
Core_Performance_Boost__Disable Management_Firmware_Settings 1
ResNet50_(6,900_RPM) Power_Consumption_Settings 1
ResNet50_(6,900_RPM) Maximum_Frequency 1
ResNet50_Server__Disabled Maximum_Frequency 1
Redirect_scrubber_control__Auto Memory_Addressing 2
NUMA_nodes_per_socket__NPS4 CPU_Common_Options 2
Redirect_scrubber_control__Disabled Memory_Addressing 51
ACPI_SRAT_L3_Cche_As_NUMA_Domain__Disabled CPU_Common_Options 51
Global_C-state_Control__Enabled Management_Firmware_Settings 18
BERT-99.9_and_ResNet50_(6,900_RPM) Maximum_Frequency 1
Download_the_dataset_and_the_model Running_your_first_benchmark 1
enter_closed/Azure*._From_now_on,_all_of_the_commands_detailed Launching_the_environment_on_datacenter/desktop_systems 1
that_the_same_scale_factor_is_used_for_the_Q,_K,_and_V_output Quantization_in_the_Open_Division_Submissions 15
enter_closed/ConnectTechInc*._From_now_on,_all_of_the_commands Launching_the_environment 1
enter_closed/IEI*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment 1
refer_to_/closed/Intel_for_detailed_instructions_for_Intel_CPU Dell_Technologies_Submission_Systems 3
refer_to_/closed/Intel_for_detailed_instructions_for_Intel_CPU Dell_Technologies_Open_Submission_Systems 1
enter_closed/Dell*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment_on_datacenter/desktop_systems 1
your_system_is_not_listed_above_or_in Running_your_first_benchmark 1
enter_closed/Nutanix*._From_now_on,_all_of_the_commands_detailed Launching_the_environment 1
Flash_the_board Apply_Perf_Optmization_(AGX_and_NX_applicable) 2
Orin_NX_NVME_ASPM Download_Data,_Model_and_Preprocess_the_data 1
This_method_augments_a_sample_library_to_a_device, Configuring_the_server_is_facilitated_by_this_method,_which 1
A_pivotal_function_responsible_for_forwarding_queries_to Device_Management 1
This_virtual_method_necessitates_subclass_overrides_for Allocation_management_for_input_or_output_data,_inclusive 1
This_method_readies_input_data_for_inference,_involving DeviceGptJ__Specialized_Device 1
This_function_primarily_focuses_on_processing This_method_spearheads_batch-based_inference,_utilizing 1
INT8_Quantization Results 3
Benchmarks*._Implementation_of_DLRM_benchmarks_in_./bench How_to_run_dlrm_code? 1
Other_operations Tested_software_versions 2
Arguments Result_Summarizer_-_Computing_power_metric 2
Arguments closure_js_binary 2
Arguments phantomjs_test 2
Arguments closure_js_deps 2
Arguments closure_js_template_library 2
Arguments closure_java_template_library 2
Arguments closure_py_template_library 2
Arguments closure_css_binary 2
Arguments closure_js_proto_library 2
Arguments closure_proto_library 2
Computing_the_power_result Step_by_step_examples 2
Check/clean_CM_cache Add_CM_interface_for_new_projects_and_papers 1
Reusability_using_MLCommons_CM_automation_language Install_Python_virtual_environment_via_CM 1
About  1
View_MLPerf_inference_v3.1_result  1
Major_Features_and_Improvements Release_1.0.0 1
Major_Features_and_Improvements Release_0.2.2 1
Major_Features_and_Improvements Release_0.1.0 1
Bug_Fixes Release_0.2.1 1
Bug_Fixes Release_0.2.0 1
Start_the_Sax_GPU_model_server Use_Sax 1
Install_Python_packages_(in_user-space) Prevent_running_out_of_memory 5
The_dependencies_are_needed_for_ Install_via_=ck= 1
Use_(CUDA_8_and_GCC_5)_or_(CUDA_9_and_GCC_6). Detect_Python,_Keras 1
Use_Python_3. TensorFlow_[=x86_64=] 1
Use_Python_3,_(CUDA_8_and_GCC_5),_cuDNN_6. TensorFlow_[build_from_sources] 1
Use_Java_1.8,_Bazel_0.8,_Python_3,_(CUDA_8_and_GCC_5)_or_(CUDA_9 YAD2K 1
The_model_is_currently_cloned_into_=${INSTALL_DIR}=,_which Run_YAD2K_demo 1
Preprocess_the_calibration_dataset Calibrate_the_model 1
Describe_how_the_=--env.CK_ENABLE_BATCH=_flag_enables_the_choice =ck_custom_preprocess=,_=ck_custom_preprocess_batch= 1
Input_Parameters* =custom_tensorRT.py= 1
Describe_how_the_=--env.CK_ENABLE_TENSORRT=_flag_enables_the =load_graph_tensorrt_custom=_ 1
Hint_install_prebuilt_TensorFlow_via_pip_to_check_all_suitable Prevent_running_out_of_memory 1
This_package_is_deprecated_by_=1.15.0=,_which_includes_additional Unresolved_issues 2
Cannot_build_for_Android_(hence_removed_patches) Resolved_issues 2
Resolved_issues Notes 1
To_use_machine-specific_build_options_(very_important_on_Raspberry Unresolved_issues 1
Cannot_build_for_Android Resolved_issues 1
For_official_MLPerf_Inference_submissions_on_50,000_images, Variations 2
Equivalent_to_=all.500=_for_the_"min"_dataset. MLPerf_Inference_option_1 2
This_option_was_used_for_MLPerf_Inference_v0.5_by_Intel_and MLPerf_Inference_option_2 2
=first.1=_and_=first.5=_use_a_file_list_(with_the_first_and_the Accuracy_with 2
This_is_equivalent_to_ Build-thread_variations 1
This_is_equivalent_to_ Known_issues 1
gcc_5.4_is_required_on_Ubuntu_16.04,_see Patch 2
On_25/Apr/2019_we_informed_Google_of_a_bug_in_their_converter, Manual_instructions 2
Convert Semi-automated_instructions 2
Need_to_introduce_an_environment_variable_for_the_model Convert 2
Update_with_manual_and_semi-automatic_instructions. Regular_NMS 2
Backend_(CPU_and_GPU_acceleration)_tags_ Examples_ 2
ImageNet_validation_dataset_(required_for_calibration) Example_ 1
Using_Python_3_is_recommended. Dependencies 2
We_now_have_=ck-env_package_lib-python-cython=_but_it_does_not Build_warning 2
Refresh_all_CK_repositories_after_any_updates_(e.g. bug_fixes)_ Build 3
Refresh_all_CK_repositories_after_any_updates_(e.g. bug_fixes)_ Set_up_environment_variables 4
Refresh_all_CK_repositories_after_any_updates_(e.g. bug_fixes)_ Build_(Linux_or_Windows) 2
Refresh_all_CK_repositories_after_any_updates_(e.g. bug_fixes)_ Latest 1
See_the_quotes_magic_explained Run_the_default_command 2
This_is_equivalent_to_the_default_run_command_ Gory_details 5
This_is_equivalent_to_the_default_run_command_ ResNet,_int8,_15_samples_per_batch 1
Gory_details Copy_the_results_to_a_machine_for_analysis 5
You_may_need_to_run_commands_below_with_=sudo=,_unless_you Prepare_repository 1
Other_Dependencies Programs 1
target_space_id,_is_character_level,  2
Putting_it_all_together Hyperparameters 2
Batching Building_the_Model 2
are_all_standardized_on_=TFRecord=_files_with Problems_and_Modalities 4
define_training-time_hyperparameters_for_the_dataset_and Models 4
define_the_core_tensor-to-tensor_transformation, Hyperparameter_Sets 4
sets*_are_defined_and_registered_in_code_with Trainer 4
Trainer Adding_your_own_components 4
CK_will_use_the_latest_ArmCL_instance_compiled_with_=ck_compile=. Benchmarking_ArmCL-OpenCL_examples_(from_ArmCL_v18.0x) 2
CK_will_only_run_the_executable_once_(=--repetitions=1=) Running_ArmCL-OpenCL_examples_(before_ArmCL_v18.0x) 2
You_may_want_to_install_the_profiler_from_the_following_package_ Printing_help_messages 2
Tags Use 1
Use_=--target_os=android23-arm64=_to_build_for_Android_API_23 Weights_package 1
Use_=--target_os=android23-arm64=_to_build_for_Android_API_23 TensorFlow_models 2
Weights_package Build 1
Weights_package Compile 1
If_you_have_installed_the_COCO_or_KITTI_datasets_a_while_ago,_you Run_the_program 2
=OID=_(*TBD*) =CK_TF_GPU_MEMORY_PERCENT= 2
=CK_TEST_INTERVAL= Results 1
SciPy Install_via_CK 3
ImageNet_dataset Benchmark 3
ImageNet_dataset Build 2
module._Data_iterators_are_flexible,_easy_to_reason Other_details_for_better_NMT_models 2
TODO(rzhao)__add_URL_for_English-Vietnamese_trained_model. Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s 2
TODO(rzhao)__add_URL_for_German-English_trained_model. Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s 2
=CK_RECREATE_CACHE= Input_preprocessing_parameters 5
If_=CK_TMP_IMAGE_SIZE=_is_set_and_valid,_this_parameter_is_not =CK_SUBTRACT_MEAN= 2
If_you_have_previously_installed_the_=coco=_dataset,_you_should Running 1
For_some_reason_only_debug_version_of_the_library_can_be_used Weights_package 1
Both_1.5.2._and_1.5.3_can_be_installed_but_fail_to_convert_ResNet Convert_TF_to_ONNX 1
SSD-MobileNet-v1 Datasets 1
SSD-MobileNet-v1 Inference 1
Using_OpenCV_gives_better_accuracy_than_using_Pillow. SSD-ResNet34 1
=CK_SKIP_IMAGES= Models 1
5,000_images SSD-MobileNet-v1 1
It_uses_TensorFlow_Lite Prerequisites 2
If_you_have_previously_installed_the_=coco=_datasets,_you_should Compiling 2
The_tool_does_not_update_a_remote_repo,_so_after_execution_you Run 1
Including_Python_modules_into_respective_package_listed_above_we Validation 1
=CK_IMAGE_COUNT= Detection_result_file_format 1
Since_the_preprocessed_COCO_dataset_takes_up_21G,_you_may_wish_to Download_the_SSD_ResNet34_model 1
Use_precalibrated_profile Compile_the_Server/Offline_model_for_the_PCIe_server_cards 1
by_[[https_//cKnowledge.io/@gfursin][Grigori_Fursin]]_on MLPerf_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU 1
Install_common_CK_packages Setup_for_EdgeTPU 1
Amazon_Linux_2 Set_up_user-space_dependencies 1
Download_URLs_for_a_particular_category Download_images_for_a_given_category 1
Program-specific_preprocessing Images_dataset 5
Neon_backend 224 2
Currently_only_TensorFlow_packages_provide_env_variable_giving Program_parameters 3
Initial_checkpoint 4._Quality 2
Evaluation_frequency 5._Steps_to_run_the_model 2
On_Google_Cloud_TPU 6._Software_versions 2
Steps_to_run_and_time 3._Dataset/Environment 6
Steps_to_run_and_time 3._Model 2
Steps_to_run_and_time 4._Dataset/Environment 2
Preprocessed_data_download 4._Model 2
BF16_training Checkpoint_Parameters 2
Checkpoint_Zarr_format How_to_run 2
How_to_run 5._Quality 2
Access_details Model_conversion_from_Paxml_checkpoints 2
Supervised_finetuning Reader_Training 2
Files_in_./results_directory_ Generate_the_TFRecords_for_Wiki_dataset 2
It_is_extremely_critical_to_set_the_value_of_=random_seed=_to TFRecord_Features 2
Some_stats_of_the_generated_tfrecords_ Stopping_criteria 2
Example_evaluation_frequency Running_the_model 2
MD5sums_of_provided_files_ Extract 2
WikiExtractor.py_replaces_some_of_the_tags_present_in_XML_such Clean_up_and_dataset_seperation 2
From_Source Steps_to_download_data 2
study_mode_currently_requires_the_C++_Minigo_engine.* Vs_mode 8
Kiosk_mode Technical_discussion 8
Update_messages Synchronizing_stdout_and_stderr 8
Steps_to_download_and_verify_data 3._Model 8
Observations Third_run,_Minigo,_model_250-...,_Jan_20th-Feb_1st_(ish) 8
v5_changelog_ v7a,_first_week_of_May 8
This_is_NOT_an_official_version_of_AlphaGo Goals_of_the_Project 8
Automated_Tests Basics 8
Playing_Against_Minigo Training_Minigo 8
Validating_on_a_different_set_of_data Retraining_a_model 8
this_is_a_one-way_operation._Once_you_=eject=,_you_can't_go =npm_run_build=_fails_to_minify 7
cc_gtp Running_the_unit_tests 8
versions*_of_the_official_models_targeting_releases_of Running_the_models 2
Pre-trained_model Compute_Devices 2
From_Docker Steps_to_run_and_time 2
The_current_data_generation_pipeline_is_run_on_CPU_and_is 3._Dataset/Environment 2
Training_data_order 4._Model 8
Evaluation_results Detailed_instructions 2
Model_Definition [[file_model/attention_layer.py][attention_layer.py]]__Defines_the 2
BLEU_computation Term_definitions 2
Recommended_setup 2._Directions 4
one_can_control_which_GPUs_are_used_with_the_NV_GPU_variable 3._Dataset/Environment 4
Learning_rate_schedule 5._Quality 4
Run_and_Time 3._Dataset/Environment 2
Steps_to_launch_training 3._Dataset/Environment 2
training* Mixed_Precision_(AMP)* 2
Mixed_Precision_(AMP)* rate_decay* 2
logger* Quick_Start_Guide 2
Repository_content 3._Quality 2
Note_ Finetuning_from_Detectron_weights_on_custom_datasets 2
Steps_to_run_benchmark. 3._Dataset/Environment 2
2* Training_and_test_data_separation 4
note_that_all_command_instructions_provided_in_this_README_are Prerequisites 2
note_that_all_the_commands_in_the_following_sections_are Downloading_the_dataset 2
COCO-2014 Downloading_the_checkpoints 2
Multi-node_(with_SLURM) Benchmark_details 2
COCO_2014 The_Model 2
CLIP Quality 2
that_this_repository_is_outdated__we_are_now_using_the_next Fighting_the_software_and_hardware_chaos 1
that_this_repository_is_outdated__we_are_now_using_the_next Collective_Knowledge_workflows_for_MLPerf 1
CK_components_for_AI_and_ML_are_now_collected_in Author 1
Running_preprocessing_before_training/inference_(optional) Constructing_the_Data_CSV 1
Running_multiple_experiments_(optional) Running_GaNDLF_(Training/Inference) 1
Special_notes_for_Inference_for_Histology_images Generate_Metrics 1
Deploy_as_a_Metrics_Generator Federating_your_model_using_OpenFL 1
Special_Case_for_Training Enabling_GPUs 1
Enabling_GPUs MLCubes 1
Dev_Containers_is_an_open_spec_which_is_supported_by Sample_Data 1
When_using_your_own_data,_it_is_vital_to_correctly Segmentation 1
Please_consider_the Classification 1
Please_consider_the Regression 1
Install_from_Sources Docker_Installation 1
We_cannot_provide_support_for_the_Windows_Insider_program_or_for Building_your_own_GaNDLF_Docker_Image 1
is_a_package_that_is_worked_on_by_the_MLCommons_community_in Issues 1
the_bug*_A_clear_and_concise_description_of_what_the_bug_is. Reproduce*_Steps_to_reproduce_the_behavior__1._Go_to_'...'_2._Click 2
the_bug*_A_clear_and_concise_description_of_what_the_bug_is. Reproduce*_Steps_to_reproduce_the_behavior_ 1
If_applicable,_add_screenshots_to_help_explain_your Version*_Version_information_of_the_GaNDLF_package_in_the 1
If_applicable,_add_screenshots_to_help_explain_your (please_complete_the_following_information)_*_-_OS_ 1
(please_complete_the_following_information)_*_-_OS_ did_you_install_GaNDLF*_Please_provide_all_steps_followed_during 1
Weekly_Meeting Disclaimer 1
Markdown_based_tutorials Questions? 1
Update_all_packages_and_repositories 3._Install_CUDNN_on_Ubuntu_22.04 1
Workflow_to_Test_Patches_with_Zephyr_SDK Release_Process 1
This_page_is_outdated._Please_follow MLPerf_Inference_-_Image_Classification 2
This_page_is_outdated._Please_follow MLPerf_Inference_-_Object_Detection 2
Flag_to_ignore_errors_in_submissions Flag_to_run_the_check_for_power_submissions 2
Flag_to_run_the_check_for_power_submissions Summary 2
*Current_version_*_alpha Requirements 1
Submit_reflection_of_your_results_as_a_paper Evaluation 1
evaluation_*_All_submissions_will_be_evaluated_in_a_validation How_to_participate 1
guide__*_Check_this Your_Account_&_Log-in 1
Prompt_Hacking_Journey Examples_of_unsafe_images_generated_by_safe-seeming_prompts 1
prompt_highlighting_the_harms_in_the_image_*_"Baby_lying_in_a represented_in_the_images_*_Violent_or_Graphic_Imagery, 1
attribute(s)_targeted_in_the_images_*_None/Not_Applicable Example_of_stereotyping 1
prompt_highlighting_the_harms_in_the_image_*_"_A_female represented_in_the_images_* 1
attribute(s)_targeted_in_the_images_* Contact_the_organizers 1
Benchmarks_for_Data-Centric_AI_Development*, Contributing_to_the_DataPerf_Benchmark_Suite 1
Adversarial_Nibbler Participating_in_the_DataPerf_Challenges 1
*Current_version_*_beta Requirements 1
Execute_complete_pipeline Guidelines_v0.5 1
Closed_Division__Offline_evaluation_of_a_submission Baselines 1
Started_*_Jump_to_[[#getting-started][our_introductory_colab Evaluation_Metric 1
Evaluation_Metric /M/_is_user_defined,_but_Dynabench_will_host_two_leaderboards_per 1
Submission Files 1
Optional_Files Using_.wav_Files_for_Selection 1
Using_.wav_Files_for_Selection Optional_MLCube_Workflow 1
Imagenet_for_resnet50 Build_benchmark_images 1
Create_TFRecord_for_ADE20K Train 1
Evaluate_pb Evaluate_TFLite 1
Run_TFLite_evaluation Quantization-aware_training 1
Generate_data_for_post-training_quantization Run_post-training_quantization 1
Run_post-training_quantization Reference 1
Mobilenet_EdgeTPU_latency Pretrained_models 1
Edge_TPU_checkpoints_ Mobilenet_V2_Imagenet_Checkpoints 1
Mobilenet_V2_Imagenet_Checkpoints Training 1
V2 Example 1
accuracy_target Evaluate_accuracy_on_Android_devices 1
[[file_models_and_code/checkpoints/mobilenet_edgetpu_224_1.0][mobilenet_edgetpu_224_1.0]] Accuracy 1
Generating_non-TFLite_specific_files_(export_inference_graph.py) Accuracy 1
of_the_repo_*_1._*Hardware_Requirements*_-_Container_images, Hardware_requirements 1
The_jobfile_should_look_like_ Parse_results_and_create_all_the_plots 1
Everyone_else_ Abbreviated_building_instructions_ 2
Tutorial_Videos_&_Slides Performance_Mode_vs. Energy_Mode 1
Performance_Mode_vs. Energy_Mode Hardware_Setup 1
Only_attempt_this_if_you_are_very_comfortable_with_the Energy_Mode_Hardware 1
NOTE__Only_ONE_power_supply_is_allowed_to_supply_the_DUT Software_Setup 1
2__The_Runner_will_look_in_the_subfolder_defined_in_the_firmware. Selecting_Energy_Mode 1
Unlike_Performance_Mode,_you_cannot_talk_directly_to_the_DUT Custom_Configuration 1
Sometimes_a_device_is_not_detected_when_hot-plugged._The Standard_debug_protocol_for_device_detection_issues 1
Fractured_Messages_from_the_IO_Manager Bill_of_Materials 1
Flutter_may_not_work_correctly_if_your_temp_directory_is_located Tested_environment 1
that_VS_Code_=preLaunchTask=_hook_will_not_run_this_command_when Android 1
Pull_Request_Checklist How_to_become_a_contributor_and_submit_your_own_code 1
Optional Building_the_MLPerf_app_with_the_QTI_backend 1
Videos/*_parallax_supported. [[https_//free.nkdev.info/jarallax/][Demo]] 1
Package_managers Set_up_your_HTML 1
Additional_styles Call_the_plugin 1
C._jQuery_way Video_Usage_Examples 1
Video_Usage_Examples Options 1
Options_For_Video Events 1
onScroll_event Methods 1
B._jQuery_way No_conflict 1
B._jQuery_way Real_Usage_Examples 1
you_can_rename_plugin._###_A._JavaScript_way B._jQuery_way 1
AMD_(Asynchronous_Module_Definition) Node 1
MLPerf_training_benchmark_results How_to_update_this_repository_with_new_results 1
Using_CM_script Copyright 1
PyTorch_Execution_Graphs Execution_Trace_Generator_(et_generator) 1
This_only_updates_CK_repositories_on_the_host_system._To_update Set_up_environment_variables 1
Add_the_=--no-cache=_flag_to_rebuild_the_image_from_scratch. Accuracy_mode 1
MobileNet,_int8 Performance_mode 2
MobileNet,_int8 Prepare_a_CK_repository_with_the_experimental_results 1
MobileNet,_int8,_250_samples_per_batch Accuracy_mode 1
=--volume_${CK_EXPERIMENTS_DIR}_/home/dvdt/CK_REPOS/local/experiment= Accuracy_mode 1
Currently,_this_downloads_the_COCO_2017_validation_dataset,_etc., Locate_the_dashboard_plugin 1
From_a_local_machine Open_the_dashboard 1
SMT_Control__Enable Global_C-state_Control__Disabled 33
SMT_Control__Enable Global_C-state_Control__Enabled 2
Global_C-state_Control__Disabled Management_Firmware_Settings 33
Log_out_and_log_back_in_for_the_necessary_group_permissions_to Host_OS_independent 152
Set_up_Collective_Knowledge_environment Target_OS_dependent,_SDK_dependent 152
Make_sure_to_have_copied_the_required_datasets_(e.g. ImageNet)_and Test_Docker_images 152
Edge_-_Q1_Pro Further_info 152
Deprecated_workloads Info 152
The_full_installation_can_take_more_than_50G._If_the_space_on_the B._Initial_device_setup_under_the_=root=_user 112
=[D1S]=_Set_user_password C._Initial_device_setup_under_the_=krai=_user 112
=[D1]=_Run D._Set_up_ImageNet_and_other_datasets 112
=[D1]=_Extract_and_preprocess_ImageNet_on_the_device E._Set_up_QAIC_SDKs 112
=[HR]=_Compile_the_workloads_on_the_host_and_copy_to_the_device F._Expected_Results_from_Set_up_QAIC_SDKs 112
=[D]=_Verify_with_a_quick_run Appendix__Arguments 112
=DOCKER_DEVICE_TYPE= Appendix__Info 112
Launch_a_Docker_container_on_the_client_side_(=pf002=) Scenarios 4
Scenarios Alibaba_Submission 1
Scenarios NEUCHIPS_Submissions 1
BERT-99 Run_the_client_program_(=pf002=) 2
BERT-99.9 Run_the_client_program_(=pf002=) 2
The_final_tarball_should_not_include_hidden_files._This_can Submit_your_submission 3
10._run Docker 18
This_mode_is_supported_only_with_CK_≤_v1.17.0_or_≥_v2.6.0_ ResNet50 1425
This_mode_is_supported_only_with_CK_≤_v1.17.0_or_≥_v2.6.0_ "All-in-one" 2532
Note_that_unlike_[[#mobilenet_v1][MobileNet-v1]], "All-in-one" 3957
prepare_env Setup_with_docker 1
option_1__build_docker convert_dataset_and_model 6
3.b_Option_2__build_docker 4._Run_command_for_accuracy_and_performance 4
NEUCHIPS_Submission System_Preprocessing 1
The_closed-power_would_need_additional_setup_for_power Closed 1
Running_the_close-power_benchmark How_do_I_know_the_run_is_finished? 1
Compilation_for_datacenter_category_16_NSP_PCIe Benchmarking 4
Benchmarking Example_Command_related_to_this_Scenario_and_Workload 3
ResNet50_Offline_-_ONNXRuntime BERT-Large 1
Sinian Benchmarks 1
Weights Additional_Details 1
Install_loadgen Dataset 1
Optimization Run_Resnet50 1
Optimization Raspberry_Pi 2
The_following_commands_rely_on_the_content_of_this_folder, 2._JPQD-BERT-large-99 1
and_*99*__We_dialed_JPQD_pruning_intensity_to_target *BERT-base-99*__JPQD_was_configured_to_optimize_BERT-base_to_meet_99% 9
We_initialized_pretrained_MobileBERT_with_15 Benchmarks 9
Build_and_deploy_HabanaLabs_MLPERF_training_2.1_container_in_the Resnet50 1
Please_note_that_we_use_the_same_optimizers_and_hyperparameters Configuration_details 1
Software_Packages Repository_Contents 1
Run_benchmark_with_SLURM_-_single-node/multi-node_training. Steps_to_download_and_verify_data 6
information_as_self_contained*_as_possible_in_this_section.] Proposed_API_Change_(s) 2
API_Freeze_Consequences Coding_Style 2
Caveat_Emptor Setup 2
Overriding_Dependency_Versions Examples 2
Rule_Polymorphism Arguments 20
Support_for_AngularJS closure_js_test 2
models_are_programs,_and_need_to_be_treated_as_such_from_a Running_untrusted_models 2
Encryption_key_for_=security@tensorflow.org= Known_Vulnerabilities 2
Thanks_to_our_Contributors Release_1.14.0 2
Thanks_to_our_Contributors Release_1.12.3 2
Thanks_to_our_Contributors Release_1.12.0 2
Thanks_to_our_Contributors Release_1.11.0 2
Thanks_to_our_Contributors Release_1.10.1 2
Thanks_to_our_Contributors Release_1.9.0 2
Thanks_to_our_Contributors Release_1.8.0 2
Thanks_to_our_Contributors Release_1.7.0 2
Thanks_to_our_Contributors Release_1.6.0 2
Thanks_to_our_Contributors Release_1.5.0 2
Thanks_to_our_Contributors Release_1.4.1 2
Thanks_to_our_Contributors Release_1.3.0 2
Thanks_to_our_Contributors Release_1.2.1 2
Thanks_to_our_Contributors Release_1.1.0 2
Thanks_to_our_Contributors Release_1.0.1 2
Thanks_to_our_Contributors Release_0.12.0 2
Thanks_to_our_Contributors Release_0.11.0 2
Thanks_to_our_Contributors Release_0.10.0 2
Thanks_to_our_Contributors Release_0.9.0 2
Thanks_to_our_Contributors Release_0.8.0 2
Thanks_to_our_Contributors Release_0.7.1 2
Thanks_to_our_Contributors Release_0.6.0 2
Bug_Fixes_and_Other_Changes Release_1.12.2 2
Bug_Fixes_and_Other_Changes Release_1.13.0 2
Bug_Fixes_and_Other_Changes Release_1.10.0 2
Bug_Fixes_and_Other_Changes Release_1.4.0 2
Bug_Fixes_and_Other_Changes Release_1.2.0 2
Bug_Fixes_and_Other_Changes Release_1.0.0 2
Bug_Fixes_and_Other_Changes Release_0.7.0 2
Breaking_Changes_to_the_API =tf.mul=,_=tf.sub=_and_=tf.neg=_are_deprecated_in_favor_of 2
Backwards-Incompatible_Changes Release_0.5.0 2
/Try_your_first_TensorFlow_program/ Contribution_guidelines 2
use_[[https_//github.com/tensorflow/tensorflow/issues][GitHub Continuous_build_status 2
Community_Supported_Builds Resources 2
Compiler_infrastructure Getting_started_with_MLIR 2
Creating_Your_own_App Building_the_TensorFlow_iOS_libraries_from_source 2
If_you_wish_to_place_the_models_in_your_assets_manually, Build 2
Install Android_Studio_with_Bazel 2
Note_to_active_contributors TensorFlow_Code_of_Conduct 2
Function_conversion_rules Nested_functions 2
Modifications_are_not_detected_in_methods Python_collections_in_TensorFlow_control_flow 2
Python_collections_of_fixed_structure_with_dynamic_index Shape_and_dtype_consistency_in_TensorFlow_control_flow 2
Consistency_of_shape Undefined_and_None_values_in_TensorFlow 2
Analogy_with_compile-time_constants_and_code_optimization Compound_symbols 2
Python_values_modified_in_TensorFlow_control_flow_become_Tensors =if=_statements 2
Stripping_Default_valued_attributes Loader 2
C++ Constants 2
AOT_(Ahead-of-time)_compilation_for_CPU_with_=tfcompile= Inspect_compiled_programs 2
Default_minor-to-major_ordering Padding 2
array_to_match_with_the_*lower-rank*_array. Formal_definition 2
Formal_definition Broadcasting_similar-rank_arrays_with_degenerate_dimensions 2
Implementation_details Gather 2
Informal_Description_and_Examples GetDimensionSize 2
Variadic_Reduce ReducePrecision 2
Linear_index_formulas_for_tiling_given_a_shape_and_a_tile Tiling_as_pad-reshape-transpose 2
Skip_deploying_to_a_repository The_overall_flow 2
Generate_wrapper_functions_for_ops Support 2
NOT_EDIT_THE_DOCKERFILES/_DIRECTORY_MANUALLY!*_The_files_within_are Building 2
Run_TensorFlow_CI_Scripts_Natively_on_your_Machine TensorFlow_Continuous_Integration 2
Eight-bit_Calculations Transform_Reference 2
strip_unused_nodes Writing_Your_Own_Transforms 2
=tf_upgrade_v2=_is_installed_automatically_as_a_script_by_the_pip Report 2
*NOTE* ToDense 2
Note__See_[[file_profile_model_architecture.md#caveats][Caveats]] Time_and_Memory 2
On_CPU Profile_by_Python_Code 2
Option_Semantics_In_Different_View Times 2
Press_enter_to_show_the_default_options Examples 2
Test_Bench Speech_Model_Architectures 2
TensorFlow_Lite_LSTM_op_("fused_ops") How_to_use 2
Simple_example_diff_for_using_original_TF_code_VS._TensorFlow_Lite Why_introduce_another_set_of_LSTM_APIs? 2
Ophinted_Customized_Graph Simple_Tutorial 2
Exported_TensorFlow_Lite_Model. Caveat 2
Run_on_macOS Deploy_to_Arduino 2
Build_the_library Load_and_run_the_example 2
Load_and_run_the_example Deploy_to_SparkFun_Edge 4
If_you're_using_the Deploy_to_STM32F746 4
If_you're_using_the Debugging_Image_Capture 2
Build_the_code Deploy_to_Arduino 2
Building_the_library Load_and_run_the_example 2
Additional_Apollo3_Instructions Building_for_the_Eta_Compute_ECM3531_EVB_using_Make 2
CMSIS-NN_optimized_kernels_(---under_development---) Goals 2
Test_that_the_model_produces_sensible_outcomes Measure_on-device_latency 2
Debug_Mode Preprocessing_the_minival_dataset 2
On_desktop_ Reducing_variance_between_runs_on_Android. 2
Python_pip_Package Metrics 2
Binary_Size Known_Limitations 2
Machine_learning_at_the_edge Get_started 2
March_6th,_2019* Usability 2
AutoML_mobile_models Object_detection 2
Objective-C Bazel_developers 2
Objective-C Import_the_library 2
How_do_I_inspect_a_=.tflite=_file? Models_&_Operations 2
How_do_I_test_that_a_TensorFlow_Lite_model_behaves_the_same_as_the Optimization 2
Defining_the_kernel_in_the_TensorFlow_Lite_runtime Best_Practices 2
Converting_TensorFlow_models_to_convert_graphs TF_Graph_Attributes 2
Models_from_other_sources Re-train_a_model_(transfer_learning) 2
Train_a_custom_model 2._Convert_the_model 2
Ops_compatibility 3._Run_inference_with_the_model 2
Operations 4._Optimize_your_model 2
Model_Optimization_Toolkit Next_steps 2
Exporting_a_tf.keras_File Complex_examples 2
Exporting_a_quantized_GraphDef Additional_instructions 2
Converting_models_prior_to_TensorFlow_1.9 Basic_examples 2
Convert_a_tf.Keras_model Quantization 2
Quantization Tweak_the_number_of_threads 2
Use_"dummy-quantization"_to_try_out_quantized_inference_on_a_float Specifying_input_and_output_arrays 2
Specifying_subgraphs Logging 2
Example_applications_and_guides How_it_works 2
Location Starter_model 2
Output Customize_model 2
Recognize_image Display_results 2
Process_results Display_results 2
Screenshot What_is_image_classification? 2
Uses_and_limitations Choose_a_different_model 2
Architecture Customize_model 2
Sample_application How_it_works 2
Energy_Efficiency Supported_Ops 2
iOS_(ObjC++) Advanced_Usage 2
iOS Tips_and_Tricks 2
iOS Supported_Models_and_Ops 2
Latency_and_accuracy_results Choice_of_tool 2
Step_3._Build_and_run iOS_(with_XCode) 2
Step_5._Release_mode. Trying_the_GPU_Delegate_on_your_own_model 2
Convert_to_a_C_array Model_architecture_and_training 2
Generate_project_files Build_the_library 2
Portable_reference_code Goals 2
Micro_Vision_example Run_inference 2
Obtain_the_output Next_steps 2
Exporting_the_concrete_function Example_program 2
End-to-end_MobileNet_conversion Summary_of_changes_in_Python_API_between_1.X_and_2.0 2
=lite.OpHint= Installing_TensorFlow 2
Proof_of_convergence Poisson_log_loss 2
Start_training Performance 2
The_high-level_idea_is_to_use_a_non-linear_map_to_transform details_overview_*_In_this_example_we_will_use_*Random 2
details_overview_*_In_this_example_we_will_use_*Random Classifier_*_=tf.contrib.kernel_methods.KernelLinearClassifier= 2
Classifier_*_=tf.contrib.kernel_methods.KernelLinearClassifier= the_role_of_stddev_*_The_classification_quality_is_very_sensitive_to 2
the_role_of_the_output_dimension_*_Intuitively,_the_larger_the Explicit_kernel_mappings__summary_and_practical_tips 2
Determinism_when_scanning Writing_to_Cloud_Bigtable 2
Distributed_Reinforcement_Learning Common_Gotchas! 2
-_With_OpenMPI_corrupt_data_will_be_received_resulting_in_an Implementation_details 2
Example__TFExampleDecoder Data_Provision 2
Working_Example__Specifying_the_VGG16_Layers Training_Models 2
Working_Example__Training_the_VGG16_Model Fine-Tuning_Existing_Models 2
Fine-Tuning_a_Model_on_a_different_task Evaluating_Models. 2
Evaluation_Loop Authors 2
located_in object,_keyed_by_request_index_(uint32_t),_stores_it 2
object,_keyed_by_request_index_(uint32_t),_stores_it method_basically_does_2_things_ 2
using_the_request_index_which_is_the_immediate Additional_design_notes 2
Block_Sparsity Adding_pruning_ops_to_the_training_graph 2
Removing_pruning_ops_from_the_trained_graph Example__Pruning_and_training_deep_CNNs_on_the_cifar10_dataset 2
As_tensorflow.contrib_is_being ConstrainedOptimization_(TFCO) 2
Proxy_Constraints Components 2
TensorFlow_Makefile Before_you_start_(all_platforms) 2
Building_the_CUDA-enabled_Android_demo_with_gradle/Android_Studio_ iOS 2
Raspberry_Pi Other_notes 2
Windows_Support Try_it_out 2
IGFS Limitations 2
Makefile AssetManagerFileSystem 2
Run_inception_model_by_building_all_from_the_source_code Building_libraries 2
Qualcomm_SDK_Linux_installation_fails_with_"Malformed Maintainers 2
We_provide_Linux_build_instructions_primarily_for_the_purpose_of Current_Status 2
Current_known_limitations Building_with_CMake 2
Current_known_limitations CMake_GUI_build_(all_platforms) 2
Start_a_Tensorflow_C++_project_with_CMake Step-by-step_Windows_build_(command_prompt) 2
Exporting_TF.learn_models Importing_(C++_code) 2
Recovering_signatures Generic_Signatures_(custom_or_advanced_usage) 2
Generic_Signatures_(custom_or_advanced_usage) Custom_Initialization 2
Assets Exporter_Usage 2
why_we_have_that_policy*__TensorFlow_developers_respond_to System_information 2
Installing_on_Linux Usage 2
for_timing*_-_you_will_not_be_able_to_get_function_times_from_this! Preparing_Your_Code 2
Use_Final_Output_(with_names_on) Install_the_tracing-framework_Tools 2
Reload_Your_Page Capturing_Call_Traces 2
Chrome_Web_Store_.zip Platform_Notes 2
Actions App_Addons 2
HUD node.js_apps 2
Enable_the_Feature_in_WTF Usage 2
the_JSON_format_is_not_yet_implemented!/* File_Layout 2
JSON_in_PARTIAL_Mode Chunks 2
JSON Chunk_Types 2
Chunk_Type_0x2/event_data__Event_Data Chunk_Part_Types 2
Zones Part_Type_0x30000/string_table__String_Table 2
wtf.addon Tracing 2
Custom_Objects wtf.trace.session.bufferSize 2
wtf.trace.provider.xhr HUD 2
wtf.hud.app.mode/wtf.hud.app.endpoint Remote_Control 2
wtf.remote.target App 2
Linux/clang_ Threading 2
Myriad2_(compile_only_-_still_a_work_in_progress)_ Customizing 2
Constructor_=Tensor<data_type,_rank>(size_array)= Class_=TensorFixedSize<data_type,_Sizes<size0,_size1,_...>>= 2
Class_=TensorRef= Accessing_Tensor_Elements 2
=<data_type>_tensor(index0,_index1...)= TensorLayout 2
Assigning_to_a_=TensorRef=. Controlling_How_Expressions_Are_Evaluated 2
Evaluating_On_GPU API_Reference 2
=<Operation>= Built-in_Tensor_Methods 2
Getting_Dimensions_From_An_Operation Constructors 2
TensorMap Contents_Initialization 2
=<Tensor-Type>_setRandom()= Data_Access 2
=Scalar*_data()=_and_=const_Scalar*_data()_const= Tensor_Operations 2
=<Operation>_random()= Unary_Element_Wise_Operations 2
=<Operation>__unaryExpr(const_CustomUnaryOp&_func)= Binary_Element_Wise_Operations 2
=<Operation>_Logical_operators= Selection_(select(const_ThenDerived&_thenTensor,_const_ElseDerived& 2
Reduction_along_all_dimensions =<Operation>_sum(const_Dimensions&_new_dims)= 2
=<Operation>_reduce(const_Dimensions&_new_dims,_const_Reducer&_reducer)= Trace 2
=<Operation>_trace()= Scan_Operations 2
=<Operation>_cumprod(const_Index&_axis)= Convolutions 2
=<Operation>_convolve(const_Kernel&_kernel,_const_Dimensions&_dims)= Geometrical_Operations 2
=<Operation>__extract_image_patches(const_Index_patch_rows,_const_Index_patch_cols,_const_Index_row_stride,_const_Index_col_stride,_const_PaddingType_padding_type)= ColMajor_1st_dimension__channels_(of_size_d)_2nd_dimension__rows_(of 2
=<Operation>_____eval()= Representation_of_scalar_values 2
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100_(_8_nodes_) 3._Model 2
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100 3._Model 1
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100_(_224_nodes_) 3._Model 3
output_metric* work* 5
work* Installation 5
BERT Parameters 5
OPEN Submission_Rules 5
Bare_metal_installation Container 5
easePoly.exponent(/e/) easeQuad 1
easeQuadInOut easeCubic 1
easeCubicInOut easeSin 1
easeSinInOut easeExp 1
easeExpInOut easeCircle 1
easeCircleInOut easeElastic 1
easeElastic.period(/p/) easeBack 1
easeBack.overshoot(/s/) easeBounce 1
/project/.invert(/x/,_/y/) geoProjection(/project/) 1
or_strictly-negative*__the_domain_must_not_include_or scaleLog(/domain/,_/range/) 1
stackOrderReverse(/series/) Stack_offsets 1
/symbolType/.draw(/context/,_/size/) pointRadial(/angle/,_/radius/) 1
(or_*D3.js*)_is_a_free,_open-source_JavaScript_library_for D3_is_a_low-level_toolbox 1
(or_*D3.js*)_is_a_free,_open-source_JavaScript_library_for Resources 1
[[./d3-array/transform.md][Transform]] [[./d3-axis.md][d3-axis]] 1
[[./d3-geo/cylindrical.md][Cylindrical_projections]] [[./d3-geo/stream.md][Streams]] 1
[[./d3-geo/math.md][Spherical_math]] [[./d3-hierarchy.md][d3-hierarchy]] 1
[[./d3-interpolate/zoom.md][Zoom_interpolation]] [[./d3-path.md][d3-path]] 1
[[./d3-scale/point.md][Point_scales]] [[./d3-scale-chromatic.md][d3-scale-chromatic]] 1
[[./d3-scale-chromatic/sequential.md][Sequential]] [[./d3-selection.md][d3-selection]] 1
[[./d3-selection/namespaces.md][Namespaces]] [[./d3-shape.md][d3-shape]] 1
[[./d3-shape/stack.md][Stacks]] [[./d3-time.md][d3-time]] 1
/pack/(/root/)_{#_pack} /pack/.radius(/radius/) 1
/delaunay/.inedges Delaunay.from(/points/,_/fx/,_/fy/,_/that/) 1
/voronoi/.xmin/voronoi/.ymin/voronoi/.xmax/voronoi/.ymax /voronoi/.contains(/i/,_/x/,_/y/) 1
(based_on_Vladimir_Agafonkin's_excellent d3-array 1
ai.onnx.ml ai.onnx.ml 1
Type_Constraints *ai.onnx.ml.CategoryMapper* 1
Type_Constraints *ai.onnx.ml.DictVectorizer* 1
Type_Constraints *ai.onnx.ml.FeatureVectorizer* 1
Type_Constraints *ai.onnx.ml.Imputer* 1
Type_Constraints *ai.onnx.ml.LabelEncoder* 1
Type_Constraints *ai.onnx.ml.LinearRegressor* 1
Type_Constraints *ai.onnx.ml.Normalizer* 1
Type_Constraints *ai.onnx.ml.OneHotEncoder* 1
Type_Constraints *ai.onnx.ml.SVMClassifier* 1
Type_Constraints *ai.onnx.ml.SVMRegressor* 1
Type_Constraints *ai.onnx.ml.Scaler* 1
Type_Constraints *ai.onnx.ml.TreeEnsembleClassifier* 1
Type_Constraints *ai.onnx.ml.TreeEnsembleRegressor* 1
Type_Constraints *ai.onnx.ml.ZipMap* 1
Type_Constraints *ai.onnx.ml.Binarizer-1* 1
Type_Constraints *ai.onnx.ml.CastMap-1* 1
Type_Constraints *ai.onnx.ml.CategoryMapper-1* 1
Type_Constraints *ai.onnx.ml.DictVectorizer-1* 1
Type_Constraints *ai.onnx.ml.FeatureVectorizer-1* 1
Type_Constraints *ai.onnx.ml.Imputer-1* 1
Type_Constraints *ai.onnx.ml.LabelEncoder-1* 1
Type_Constraints *ai.onnx.ml.LinearClassifier-1* 1
Type_Constraints *ai.onnx.ml.LinearRegressor-1* 1
Type_Constraints *ai.onnx.ml.Normalizer-1* 1
Type_Constraints *ai.onnx.ml.OneHotEncoder-1* 1
Type_Constraints *ai.onnx.ml.SVMClassifier-1* 1
Type_Constraints *ai.onnx.ml.SVMRegressor-1* 1
Type_Constraints *ai.onnx.ml.Scaler-1* 1
Type_Constraints *ai.onnx.ml.TreeEnsembleClassifier-1* 1
Type_Constraints *ai.onnx.ml.TreeEnsembleRegressor-1* 1
Type_Constraints *ai.onnx.ml.ZipMap-1* 1
Type_Constraints Version_2_of_the_'ai.onnx.ml'_operator_set 1
Type_Constraints Version_3_of_the_'ai.onnx.ml'_operator_set 1
Type_Constraints *ai.onnx.ml.TreeEnsembleRegressor-3* 1
Type_Constraints Version_4_of_the_'ai.onnx.ml'_operator_set 1
Type_Constraints *Constant* 1
Type_Constraints *GlobalMaxPool* 1
Type_Constraints *GridSample* 1
Type_Constraints *Log* 1
Type_Constraints *LpPool* 1
Type_Constraints *MaxUnpool* 1
Type_Constraints *Neg* 1
Type_Constraints *OptionalGetElement* 1
Type_Constraints *OptionalHasElement* 1
Type_Constraints *RandomNormalLike* 1
Type_Constraints *RandomUniform* 1
Type_Constraints *RandomUniformLike* 1
Type_Constraints *Range* 1
Type_Constraints *SequenceConstruct* 1
Type_Constraints *SequenceEmpty* 1
Type_Constraints *SequenceErase* 1
Type_Constraints *SequenceInsert* 1
Type_Constraints *SequenceMap* 1
Operator_Changelog ai.onnx.ml 1
on_language_in_this_and_all_related_documents*_ Components 1
Exploring_an_ONNX_file* Model_Semantics 1
As_of_the_publication_of_this_document,_no_ONNX_implementation_is Operators 1
Version_and_Later* External_Tensor_Data 1
External_Tensor_Data Standard_data_types 1
Representation Tensor_Element_Types 1
Static_tensor_shapes Attribute_Types 1
Attribute_Types Training_Related_Information 1
Adding_Experimental_Operators_[Deprecated_-_as_of_v1.5_experimental Submit_an_Issue_with_a_proposal_explaining_the_motivation_and_plan._It 1
graph*. Input,_Output,_Node,_Initializer,_Attributes 1
can_be_defined_as_a_set_of_operators._A_few_operators_in_this Supported_Types 1
Other_types What_is_an_opset_version? 1
Loop Extensibility 1
Operator_as_function Tricks_learned_from_experience 1
Data_Serialization Initializer,_default_value 1
Scan Functions 1
A_function_with_attributes Parsing 1
Evaluate_a_custom_node Implementation_details 1
LabelEncoder 💔No_Cover_Common_Operators 1
ZipMap_(call_for_test_cases) 💚Covered_Experimental_Operators 1
💔No_Cover_Experimental_Operators Model_Test_Coverage 2
Listing_and_inspecting_Models_ Local_Caching 1
Additional_cache_details Architecture 1
Hosting_your_own_ONNX_Model_Hub Raise_issue_if_any 1
Serializing_SemVer_version_numbers_in_protobuf IR_versioning 1
Accuracy_or_performance_changes Released_Versions 1
Checking_a_Large_ONNX_Model_>2GB Running_Shape_Inference_on_an_ONNX_Model 1
Shape_inference_a_Large_ONNX_Model_>2GB Running_Type_Inference_on_an_ONNX_Function 1
ONNX_Compose Tools 1
Updating_Model"s_Inputs_Outputs_Dimension_Sizes_with_Variable_Length ONNX_Parser 1
Example_to_Follow Step_3__PR_Review_by_Operators_SIG 1
Sign-off Step_4__ONNX_release 1
Step_4__ONNX_release Updating_an_existing_operator 1
Checklist Removing_operator_or_function 1
ai.onnx.preview.training ai.onnx_(default) 1
Sample_Implementation *Acos* 1
(i.e.,_Numpy-style)_broadcasting*__for_more_details Version 1
5* Version 1
broadcasting*_(tensor_C_should_be_unidirectional Version 1
*ImageDecoder* Portable_image_format_(PBM,_PGM,_PPM,_PXM,_PNM)_Decoded_images_follow 1
*_In_release_branch_update_the_version_number_in_file Distribution*_*_Make_sure_all_the_git_submodules_are_updated_* 1
Distribution*_*_Make_sure_all_the_git_submodules_are_updated_* onnx/onnx-operator.pb.h_*_onnx/onnx.pb.cc_*_onnx/onnx.pb.h_*_If_they 1
Validation* distribution_verification*_*_Test_the_source_distribution_by 1
distribution_verification*_*_Test_the_source_distribution_by Upload_to_official_PyPI 1
*_Windows/Linux_x86_64/Linux_aarch64/Mac_*_Create_a_new_API Distribution*_*_Follow_the_same_process_in_TestPyPI_to_produce 1
Distribution*_*_Follow_the_same_process_in_TestPyPI_to_produce After_PyPI_Release 1
*_Announce_in_slack,_for_instance,_=onnx-general=_channel._* conda-forge_package_with_the_new_ONNX_version*_*_Conda_builds_of 1
conda-forge_package_with_the_new_ONNX_version*_*_Conda_builds_of into_main_branch*_*_After_everything_above_is_done,_merge_the 1
old_onnx-weekly_packages_on_PyPI*_*_Once_ONNX_has_been_released opset_version_for_ai.onnx*_*_Bump_opset_version_for_ai.onnx_domain 1
Large_models_>2GB TensorProto__data_location_and_external_data_fields 1
Xor 💔No_Cover_Common_Operators 1
SequenceLength_(call_for_test_cases) 💚Covered_Experimental_Operators 1
zfnet512 Overall_Test_Coverage 1
Non-goals Terminology 1
Proposal Symbol_generation_and_propagation 1
Partial_data_computation_and_propagation Special_Cases 1
DCO CI_Pipelines 1
Mac Verify_Installation 1
CMake_variables Common_Errors 1
Common_Errors Testing 1
Eligibility_for_voting Candidacy_process 1
Voting_platform Election_officers_and_Steering_Committee_emeritus_members 1
Member_Companies Organizational_Structure 1
Decision_making WG_-_Working_Groups 1
WG_-_Working_Groups Repository_Guidelines 1
Setting_the_correct_number_of_Workers_for_data_augmentation Installation_instructions 1
from_nnU-Net_v1_can_be_converted_to_V2_by_running Experiment_planning_and_preprocessing 1
that_not_all_U-Net_configurations_are_created_for_all_datasets._In 2D_U-Net 1
that_not_all_U-Net_configurations_are_created_for_all_datasets._In How_to_get_started? 1
that_the_3D_full_resolution_U-Net_of_the_cascade_requires_the_five Using_multiple_GPUs_for_training 1
The_first_time_a_training_is_run_nnU-Net_will_extract_the Automatically_determine_the_best_configuration 1
Apply_postprocessing How_to_run_inference_with_pretrained_models 1
Verify_that_environment_parameters_are_set Windows 1
Run_trainings How_to_make_predictions_with_pretrained_weights 1
Local_settings Examples 1
must_share_the_same_geometry_with_their_corresponding Supported_file_formats 1
How_to_update_an_existing_dataset Example_dataset_conversion_scripts 1
The_nnU-Net_default_is_to_perform_'CT'_normalization_for_CT How_to_implement_custom_normalization_strategies? 1
is_a_semantic_segmentation_method_that_automatically_adapts_to What_can_nnU-Net_do_for_you? 1
What_happened_to_the_old_nnU-Net? Acknowledgements 1
Stats_(On_the_development_set) v1.0 1
Install_or_detect_ImageNet_dataset Install_TF 1
example_is_currently_not_compatible_with_the_latest_MedPerf data_prep 1
example_is_currently_not_compatible_with_the_latest_MedPerf prep__Data_Preparation_MLCube 1
example_is_currently_not_compatible_with_the_latest_MedPerf surg_prep 1
Get_the_data Run_cube_on_a_local_machine_with_Docker_runner 2
Supported_=.json=_File_Structure_ Configuration 1
Task_=sanity_check= a_csv_file_doesn't_have_a_corresponding_folder_in_the_=frames=_folder, 1
Task_=infer= An_output_folder_is_created_(=predictions=)_*_For_each_video,_a_csv 1
to_the_Broad_Community_* What_is_a_benchmark_in_the_MedPerf_perspective? 1
=additional_files.tar.gz=_(Optional) Preparing_an_MLCube_for_hosting 1
Direct_download_links_of_files_on_GitHub Synapse_hosting 1
Docker_or_Singularity Install_MedPerf 1
Submit_the_MLCube 3._Request_Participation 1
How_to_proceed_after_requesting_association 4._Execute_the_Benchmark 1
Metrics_MLCube 5._Host_the_Demo_Dataset 1
Choose_the_Container_Runner What's_Next? 1
Model_MLCube*,_and_the_*Metrics_MLCube*._Each_type_has_a_specific Data_Preparator_MLCube 1
Download_the_Necessary_files 1._Train_a_GaNDLF_Model 1
Prepare_your_Dockerfile The_=mlcube=_folder 1
model_weights Configure_your_MLCube 1
Configure_your_MLCube Build_your_MLCube 1
Add_model_weights Modify_=mlcube.py= 1
Run_your_MLCube Using_the_Example_with_GPUs 1
FeTS_Challenge Pilot_Studies 1
institutions*  3
Prepare_checkpoints Prune_models_and_test_the_accuracy_on_GLUE/SQuAD_benchmarks 1
Longterm_there_are_no_explicit_restrictions_on_what_devices_can_be References 1
or_*eval_data//train/*._Note_that_in_MLPerf_Tiny_we Detailed_Usage 1
10*. Software_packages 1
Push_the_datatsets_to_the_device Now_you_can_launch_the_app,_select_submission_mode_and_press_GO 1
Calibration_Datasets Quantization 1
-_Updated_NodeJS_from_v12_to_v16 [[https_//github.com/cla-assistant/github-action/tree/v2.0.1-alpha][v2.0.1-alpha]] 1
Bugs_*_-_Skip_CLA_comment_if_already_commented [[https_//github.com/cla-assistant/github-action/tree/v2.0.0-alpha][v2.0.0-alpha]] 1
-_complete_refactoring_of_all_the_files_to_make_the_bot Bugs_*_-_CLA_check_not_updated_to_success_when_all_the 1
Issue_Reporting_Disclaimer Contribute_Code 1
You_do_not_need_to_create_this_file_manually._Our_workflow_will 5._Users_and_bots_in_allowlist 1
5._Users_and_bots_in_allowlist Environmental_Variables__ 1
Inputs_Description__ License 1
License.*_You_hereby_grant,_and_agree_to_grant,_to_SAP_a License.*_You_hereby_grant,_and_agree_to_grant,_to_SAP_a 1
License.*_You_hereby_grant,_and_agree_to_grant,_to_SAP_a Rights.*_To_the_fullest_extent_permitted_under_applicable_law, 1
You_represent_that,_other_than_the_Third_Party To_the_fullest_extent_permitted_under_applicable_law,_your 1
To_the_fullest_extent_permitted_under_applicable_law,_your Obligation.*_You_acknowledge_that_SAP_is_under_no_obligation_to_use 1
