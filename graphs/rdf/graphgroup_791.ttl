```less
@prefix : <http://ctuning.org/ml-benchmark-ontology#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
<http://ctuning.org/ml-benchmark-ontology> a owl:Ontology .

:AutomatedDesignSpaceExploration a owl:Class ;
    rdfs:subClassOf :Exploration .

:Standardization a owl:Class ;
    rdfs:subClassOf :Process .

:Workflow a owl:Class ;
    rdfs:subClassOf :Process .

:hasBenchmark a owl:ObjectProperty ;
    rdfs:domain :Model ;
    rdfs:range :Benchmark .

:mlperfInferencev1.0 a :MLPerfInference,
        owl:NamedIndividual .

:reproducibilityReportMLPerfInferencev1.1 a :ReproducibilityReport,
        owl:NamedIndividual .

:Exploration a owl:Class ;
    rdfs:subClassOf :Analysis .

:MLPerfInference a owl:Class ;
    rdfs:subClassOf :Benchmark .

:Report a owl:Class ;
    rdfs:subClassOf :Documentation .

:ReproducibilityReport a owl:Class ;
    rdfs:subClassOf :Report .

:Benchmark a owl:Class ;
    rdfs:subClassOf :Evaluation .

<https://github.com/NVIDIA/TensorRT/releases/tag/20.10>-_20.10 a :Release ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

<https://docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-7.html#rel_7-2-1> a :Release ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v7.2.1.0/model-benchmarks/mlperf_inference_v1.0/results> .

:Version "20.10" a :Version ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

:GPU "GeForce RTX 3090" a :GPU ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

:Driver_Version "465.99" a :DriverVersion ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

:Relevant_Files "mlperf_inference_v1.0" a :RelevantFile ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

:link "<https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results>" a :Link ;
    hasBenchmark <https://github.com/NVIDIA/TensorRT/releases/download/v20.10.0/model-benchmarks/mlperf_inference_v1.0/results> .

:Steps_To_Reproduce "1. Copy the model checkpoint to the TensorRT data directory.<br><br>2. Run the TensorRT inference process using the following command: tensorrt infer --model-path <path