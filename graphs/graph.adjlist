#./parse_structure_ollama.py
# GMT Wed Nov  1 21:35:17 2023
# test
we_have_moved_the_main_AE_pages Description
Description Managing_the_configuration_files Setup_for_Google_Cloud_Instances System_dependencies Set_up Download_the_needed_files
Packed_data Running_the_model
Running_the_model
Example_2 Description_of_how_the_=results_text.tar.gz=_file_was_prepared
Description_of_how_the_=results_text.tar.gz=_file_was_prepared
Requirements 2._Directions Quick_Start_Guide Steps_to_download_data
2._Directions
Steps_to_download_data =dev-clean-wav/=_*_=dev-other-wav/=_*_=test-clean-wav/=_* Steps_to_launch_training
=dev-clean-wav/=_*_=dev-other-wav/=_*_=test-clean-wav/=_*
NVIDIA_DGX_A100_(single_node) Alternative_launch_with_nvidia-docker
Alternative_launch_with_nvidia-docker Steps_to_launch_training_on_multiple_nodes 3._Dataset/Environment
Hyperparameter_settings 3._Dataset/Environment 3._Quality Dataset/Environment
3._Dataset/Environment
Test_data_order 4._Model 3._Model
4._Model
Loss_function 5._Quality Submission_functions
5._Quality
Publication/Attribution 2._Directions Quality 5._Quality
Steps_to_launch_training_on_multiple_nodes
3._Quality
Dataset/Environment
The_MLPerf_Subset Model
Model
Quality
=--opt-level=_=O1=_and_=O2=_both_use_dynamic_loss_scaling_by Summary
Summary =generate_final_report.py= =pack_submission.sh=_(Deprecated) =repository_checks.sh= MLPerf_inference_-_Python_-_ResNet50_FP32_-_ImageNet_-_TVM_-_CPU_- The_next_steps MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_ONNX_- MLPerf_inference_-_C++_-_RetinaNet_FP32_-_Open_Images_-_ONNX_-_GPU_- MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_PyTorch_-
training*_below_for_more_detail) =--opt-level_O2=_("Almost_FP16"_mixed_precision._More_dangerous
=--opt-level_O2=_("Almost_FP16"_mixed_precision._More_dangerous Distributed_training
Distributed_training Expected_Output(s)
 Currently,_the_non-=-devel=_images_on_Pytorch_Dockerhub_do  Fixing_INVALID_results Tuning_parameters_for_better_performance you_run_into_issues,_invalid_results,_or_would_like_to_improve_your Model Steps_to_do_calibration_for_RNNT Steps_to_run_RNNT (optional)_>=_8.4_GA License FileSet RecordSet Field DataSource extract fileProperty JSON_Text_that_matches_the_fields_of_the_=RecordSet=. Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s CK_based_object_detection_DSE Notes Recap Rules Known_Issues stopping*__under_the_new_rules,_/min_query_count/_is_no_longer_a Steps_to_run_RNN-T_with_three_options Steps_to_run_GPT-J Steps_to_calibrate_GPT-J Download_the_COCO_training_dataset Unit-tests ImageNet_validation_dataset_(required_for_calibration) Data_ logger* Customize_the_Training Running_multiple_experiments_(optional) Pose_estimation Image_segmentation Smart_reply is_an Known_problems on_model_validation* Build_the_markdown_documentation POC_2_-_Pancreas_Segmentation POC_3_-_Surgical_Workflow_Phase_Recognition POC_4_-_Cloud_Experiments How_to_Use_MedPerf Dependency
Currently,_the_non-=-devel=_images_on_Pytorch_Dockerhub_do Running_your_Apex_container
Running_your_Apex_container Option_2__Install_Apex_in_a_running_container
Option_2__Install_Apex_in_a_running_container
and_*run.sh*_show_an_example_using_Amp is_intended_purely_as_an_instructional_example,_not_a_performance
is_intended_purely_as_an_instructional_example,_not_a_performance
[[https_//github.com/mcarilli/mixed_precision_references/tree/master/GTC_2019][GTC Contents
Contents Requirements Walkthrough
Use_[[https_//pytorch.org/docs/stable/amp.html][PyTorch 2._Distributed_Training
2._Distributed_Training
is_deprecated._Use Synchronized_Batch_Normalization
Synchronized_Batch_Normalization
Use Checkpointing
Checkpointing Installation
Installation Part_1._Concurrent_inference_and_dynamic_batching Guidelines_(alpha_version) MLCube_execution
[Experimental]_Windows Custom_C++/CUDA_Extensions_and_Install_Options
Custom_C++/CUDA_Extensions_and_Install_Options
[[https_//github.com/NVIDIA/apex/tree/master/examples/FP16_Optimizer_simple/distributed_apex][Simple Synchronized_Batch_Normalization
CPU_path Important_arguments
Important_arguments
Transform_unstructured_sparsity_to_structured_sparsity_(as_in_Figure References
References Appendix
Test_your_own_range! Performance_Comparisons
Performance_Comparisons
Build_and_deploy_HabanaLabs_MLPERF_training_3.0_container_in_the Resnet50
Resnet50
Run_and_time_PyTorch_Resnet50 Bert_TF
Bert_TF
to_download_Dataset_and_Checkpoint_* Preparation_*_In_order_to_use_dataset_one_needs_to_preprocess Training_data_packing
Preparation_*_In_order_to_use_dataset_one_needs_to_preprocess Run_and_time
Run_and_time Bert_PT
Bert_PT
Scaling_out_the_training_to_64_Gaudi2 GPT3-175B_PT
GPT3-175B_PT
Installing_requirements Prepare_checkpoint
Prepare_checkpoint
Run_GPT3_on_HLS-Gaudi2-N48-PT_system UNet3D
UNet3D
do_not_report_security_vulnerabilities_through_public_GitHub Preferred_Languages
Preferred_Languages
Model_Tests Contributor_License_Agreement
Contributor_License_Agreement
DeepSpeed-Compression DeepSpeed_Software_Suite
DeepSpeed_Software_Suite
DeepSpeed_on_Azure DeepSpeed_Adoption
DeepSpeed_Adoption
Code_of_Conduct Publications
Publications
this_step_frequently_hangs_when_connected_to_a_VPN_(including Update_the_Readthedocs.io_API_documentation
Update_the_Readthedocs.io_API_documentation
all_processes_must_call_this_method_and_not_just_the DeepSpeed_Configuration
DeepSpeed_Configuration Launching_DeepSpeed_Training
Launching_DeepSpeed_Training
MPI_and_AzureML_Compatibility Resource_Configuration_(single-node)
Resource_Configuration_(single-node)
Running_BingBertSquad DeepSpeed_Integration
DeepSpeed_Integration
Weight_updates Evaluation
Evaluation Recipe
Fine-tuning_Results Enabling_DeepSpeed's_Transformer_Kernel_for_better_Throughput
Enabling_DeepSpeed's_Transformer_Kernel_for_better_Throughput
out!*_1)_The_NCCL-based_implementation_requires_PyTorch_>=_1.8 1._Overview
1._Overview
out!*_This_NCCL-based_implementation_requires_PyTorch_>=_1.8._It 1.2.2_MPI-based_implementation
1.2.2_MPI-based_implementation 1.3_0/1_Adam_Algorithm 1.3_1-bit_LAMB_Algorithm 1.3_1-bit_Algorithm
1.3_0/1_Adam_Algorithm
out!*_0/1_Adam_relies_on_an_compression_error_compensation 2._BERT_Pre-training_with_0/1_Adam
2._BERT_Pre-training_with_0/1_Adam
is_DeepSpeed_Compression_*_DeepSpeed_Compression_is_a_library use_DeepSpeed_Compression_*_DeepSpeed_Compression_offers_novel
use_DeepSpeed_Compression_*_DeepSpeed_Compression_offers_novel
to_use_DeepSpeed_Compression_*_The_first_section_General_Tutorial 1._General_Tutorial
1._General_Tutorial
to_use_layer_reduction* to_use_layer_reduction* 1.2_Weight_Quantization
1.2_Weight_Quantization
to_use_weight_quantization* to_use_weight_quantization* 1.3_Activation_Quantization
1.3_Activation_Quantization
to_use_activation_quantization* to_use_activation_quantization* 1.4_Pruning
1.4_Pruning
is_pruning* 1.4.1_Sparse_Pruning
1.4.1_Sparse_Pruning
to_use_sparse_pruning* to_use_sparse_pruning*
to_use_row_pruning* to_use_row_pruning*
to_use_head_pruning* to_use_head_pruning*
to_use_channel_pruning* to_use_channel_pruning* 2._Tutorial_for_ZeroQuant__efficient_and_affordable_post-training
2._Tutorial_for_ZeroQuant__efficient_and_affordable_post-training
to_use_ZeroQuant* to_use_ZeroQuant* 3._Tutorial_for_XTC__simple_yet_effective_compression_pipeline_for
3._Tutorial_for_XTC__simple_yet_effective_compression_pipeline_for
to_use_XTC* to_use_XTC*
of_XTC_methods_*_To_accommodate_users_who_do_not_have_a 3.1_One-bit_or_Two-bit_BERT-base_(12-layer)_with_8-bit_activation
3.1_One-bit_or_Two-bit_BERT-base_(12-layer)_with_8-bit_activation
Currently_DeepSpeed_Transformer_Kernels_do_not_support_Sparse *Integrate_Transformer_Kernel* How_to_use_sparse_attention_with_DeepSpeed_launcher
*Integrate_Transformer_Kernel*
DeepSpeed_MoE_requires_Pytorch_1.8_or_above._{__.notice--info} Expert_groups_initialization
Expert_groups_initialization
Combining_ZeRO-Offload_and_DeepSpeed_MoE_for_very_large_models Random_Token_Selection
Random_Token_Selection
Currently,_DeepSpeed_Sparse_Attention_can_be_used_only_on_NVIDIA Sparse_attention_modules
Sparse_attention_modules
How_to_use_sparse_attention_with_DeepSpeed_launcher
For_large_model_training,_see AlexNet
AlexNet
the_=lambda=_in_the_middle_of_=layers=_above_is_not_a Inputs_and_Outputs
Inputs_and_Outputs
The_pipeline_engine_expects_data_loaders_to_return_a_=tuple=_of out!*_The_pipeline_engine_/pulls/_data_from_an_iterator_instead
out!*_The_pipeline_engine_/pulls/_data_from_an_iterator_instead Advanced_Topics
Advanced_Topics
DeepSpeed_now_supports_PreLayerNorm_as_the_default_way_for Fine-tuning_with_DeepSpeed_on_GLUE_Tasks
Fine-tuning_with_DeepSpeed_on_GLUE_Tasks
On_08/15/2022_we_have_added_another_BERT Pre-training_Bing_BERT_without_DeepSpeed
Pre-training_Bing_BERT_without_DeepSpeed
/Downloading_and_pre-processing_instructions_are_coming_soon./ Running_the_Bing_BERT_model
Running_the_Bing_BERT_model Enabling_DeepSpeed
Enabling_DeepSpeed
Training Checkpoints_Saving_&_Loading
Checkpoints_Saving_&_Loading
Start_Training Reproducing_Fastest_BERT_Training_Results_with_DeepSpeed
Reproducing_Fastest_BERT_Training_Results_with_DeepSpeed
Custom_Monitoring Note_-_Some_Monitor_backends_don't_support_mixed_sample_values._Be
Note_-_Some_Monitor_backends_don't_support_mixed_sample_values._Be
[[https_//pytorch.org/][PyTorch]]_must_be_installed_/before/ Install_DeepSpeed_from_source
Install_DeepSpeed_from_source
PyTorch Example__Tuning_for_Large_Batch_Sizes
Example__Tuning_for_Large_Batch_Sizes
In_the_case_where_we_use_gradient_accumulation,_backward_on_the Configuration
Configuration
Run_DCGAN_Model_with_DeepSpeed_Enabled Performance_Comparison
Performance_Comparison
key_to_the_DeepSpeed_JSON_configuration._A_full Training_a_1.5B_Parameter_GPT-2_model
Training_a_1.5B_Parameter_GPT-2_model
vs_ZeRO-Offload_*_DeepSpeed_first_included_offloading Allocating_Massive_Megatron-LM_Models
Allocating_Massive_Megatron-LM_Models
DeepSpeed_version_=0.3.15=_introduced_automatic_external Extracting_weights
Extracting_weights
gains/*,_and_*/memory_footprint_reduction/*_from_using Training_GPT-2_with_the_Original_Megatron-LM
Training_GPT-2_with_the_Original_Megatron-LM
Running_Unmodified_Megatron-LM_GPT2_model Enabling_DeepSpeed
Loss_Scaling Checkpoint_Saving_&_Loading
Checkpoint_Saving_&_Loading
Train_scripts DeepSpeed_Evaluation_using_GPT-2
DeepSpeed_Evaluation_using_GPT-2
1.3_1-bit_LAMB_Algorithm
out!*_1-bit_LAMB_relies_on_an_compression_error_compensation 2._BERT_Pre-training_with_1-bit_LAMB
2._BERT_Pre-training_with_1-bit_LAMB
1._=cycle_min_mom=__minimum_momentum_in_cycle_phase_2. Required_Model_Configuration_Changes
Required_Model_Configuration_Changes
*PyTorch_model* Batch_Scaling_Example
Batch_Scaling_Example
This_tutorial_is_updated_on_03/04/2021_to_reflect_the_1-bit_Adam out!*_1)_The_NCCL-based_implementation_requires_PyTorch_>=_1.8
1.3_1-bit_Algorithm
out!*_1-bit_Adam_relies_on_an_compression_error_compensation 2._BingBertSQuAD_Fine-tuning_with_1-bit_Adam
2._BingBertSQuAD_Fine-tuning_with_1-bit_Adam
For_details_about_loading_checkpoint,_argument_parsing, 2.1_Running_BingBertSQuAD_with_DeepSpeed_and_1-bit_Adam
2.1_Running_BingBertSQuAD_with_DeepSpeed_and_1-bit_Adam
The_results_are_summarized_in_the_table_below._The_total Speed_and_Scalability_/*
Speed_and_Scalability_/* 3._BERT_Pre-training_with_1-bit_Adam
3._BERT_Pre-training_with_1-bit_Adam
based_technologies*__In_simple_terms,_ZeRO_is_a_memory_efficient Parallelism_based_technologies*__3D_Parallelism_refers_to_a
Parallelism_based_technologies*__3D_Parallelism_refers_to_a Deciding_which_technology_to_use
Deciding_which_technology_to_use
based_technologies*__For_most_training_scenarios,_ZeRO_offer Understanding_performance_tradeoff_between_ZeRO_and_3D_Parallelism
Understanding_performance_tradeoff_between_ZeRO_and_3D_Parallelism
Eigenvalue_Parameters How_to_Use_MoQ_for_GLUE_Training_Tasks
How_to_Use_MoQ_for_GLUE_Training_Tasks
Example__Megatron-LM Usage_Outside_the_DeepSpeed_Runtime
Usage_Outside_the_DeepSpeed_Runtime
Example__Bert In_Model_Training_Workflow
In_Model_Training_Workflow
This_tutorial_was_updated_on_10/29/2021._Changes_include__1)_A 1._Configurations_and_tuning_strategy
1._Configurations_and_tuning_strategy
1.3_fixed_discrete_schedule 2._Curriculum_learning_for_Megatron-LM_GPT-2_pre-training
2._Curriculum_learning_for_Megatron-LM_GPT-2_pre-training
out!*_After_the_update_on_10/29/2021,_now_there_are_two 2.1_Training_data_truncation
2.1_Training_data_truncation
that_CUDA_profiling_incurs_non-negligible_overhead. Profile_memory_consumption
Profile_memory_consumption
1.2_Challenges_in_applying_error-compensation_to_Adam 2._Compressing_communication_with_1-bit_Adam
2._Compressing_communication_with_1-bit_Adam
2.2_Addressing_system_challenges_for_1-bit_Adam 3._Benefits_of_1-bit_Adam_on_communication-constrained_systems
3._Benefits_of_1-bit_Adam_on_communication-constrained_systems
in_model_size*_as_well_as_*increase_in_number_of_GPUs*._As Experimental_Setup
Experimental_Setup
Training_setup_using_Azure_VMSS Performance_Evaluation_on_Various_Model_Configurations
Performance_Evaluation_on_Various_Model_Configurations
TFLOPs/GPU*_on_128_NDm_A100_v4-series_A100_systems_(i.e.,_1024 Scaling_the_1T_and_2T_models
Scaling_the_1T_and_2T_models How_to_run_training_experiments_on_Azure?
How_to_run_training_experiments_on_Azure?
Customized_Inference_Kernels_for_Boosted_Compute_Efficiency_of Kernel-Fusion
Kernel-Fusion
for_Transformers_*_For_transformer-based_models_such_as Inference_with_Tensor-Slicing_*_For_massive_models_such_as
Inference_with_Tensor-Slicing_*_For_massive_models_such_as Inference_with_ZeroQuant_*_For_massive_models_with_tens_or
Inference_with_ZeroQuant_*_For_massive_models_with_tens_or
for_Resource_Constrained_Systems_*_Models_such_as_Bloom Optimizations_*_When_applicable,_MII_automatically_applies
Optimizations_*_When_applicable,_MII_automatically_applies MII-Public_and_MII-Azure
MII-Public_and_MII-Azure
Cost_Sensitive_Scenarios Deployment_Options
Deployment_Options
MII-Azure_Deployment Concluding_Remarks
Concluding_Remarks
rematerialization.*_When_fusing_kernels_of_the_different (b)_Invertible_operators_to_save_memory_and_run_large_batches
(b)_Invertible_operators_to_save_memory_and_run_large_batches Overlapping_I/O_with_Computation_through_Asynchronous_Prefetching
Overlapping_I/O_with_Computation_through_Asynchronous_Prefetching
Alternative_approach__Host_some_model_weights_in_GPU_memory Model_Scaling_on_1_GPU
Model_Scaling_on_1_GPU
Impact_of_generation_output_length Using_ZeRO-Inference
Using_ZeRO-Inference
and_allow_*large_batch_sizes*._Alternative How_to_use_ZeRO-Inference
How_to_use_ZeRO-Inference Conclusion
Conclusion
*_*gradient_accumulation*_*_number_of [integer]
[integer] [integer] Optimizer_Parameters BFLOAT16_training_options [boolean] Optimizer_offloading [string] Flops_Profiler [list_of_integer]
Optimizer_Parameters
[dictionary] Scheduler_Parameters Communication_options [integer] Curriculum_Learning [dictionary] Elastic_Training_Config_(V0.1_and_V0.2) Compression Weight_Quantization Activation_Quantization Sparse_Pruning Row_Pruning Head_Pruning Channel_Pruning Checkpoint_options
Scheduler_Parameters
Communication_options
[boolean] [boolean] FP16_training_options Automatic_mixed_precision_(AMP)_training_options params/*__[various] [dictionary] *cpu_offload*_is_deprecated_and_will_be_removed_in_future, Asynchronous_I/O Logging Autotuning [string] [integer] Sparse_Attention Data_Type_options
[float] [boolean] ZeRO_Optimizations_for_FP16_Training
FP16_training_options
BFLOAT16_training_options
Automatic_mixed_precision_(AMP)_training_options
this_mode_cannot_be_combined_with_the_=fp16=_mode_described [dictionary]
params/*__[various] Gradient_Clipping
Gradient_Clipping
ZeRO_Optimizations_for_FP16_Training
*cpu_offload*_is_deprecated_and_will_be_removed_in_future, Parameter_offloading
Parameter_offloading
Optimizer_offloading
Asynchronous_I/O
Logging
Autotuning
[string] [string] Activation_Checkpointing [integer]
[int] [int]
Flops_Profiler
Activation_Checkpointing
Sparse_Attention
Curriculum_Learning
[list_of_integer] [list_of_integer] Monitoring_Module_(TensorBoard,_WandB,_CSV)
Monitoring_Module_(TensorBoard,_WandB,_CSV)
Elastic_Training_Config_(V0.1_and_V0.2)
Compression GRPC_Options
*Compression*_has_seven_different_components,_including_layer Layer_Reduction
Layer_Reduction
Weight_Quantization
Activation_Quantization
Sparse_Pruning
Row_Pruning
Head_Pruning
Channel_Pruning
Checkpoint_options
Data_Type_options
Single-GPU,_Multi-GPU,_and_Multi-Node_Training Pipeline_Parallelism
Pipeline_Parallelism
Integration_with_Megatron-LM The_Zero_Redundancy_Optimizer
The_Zero_Redundancy_Optimizer
Contiguous_Memory_Optimization_(CMO) ZeRO-Offload
ZeRO-Offload
Communication_Overlapping Training_Features
Training_Features
Automatic_loss_scaling_with_mixed_precision Training_Optimizers
Training_Optimizers
Memory-Efficient_Training_with_ZeRO_Optimizer Training_Agnostic_Checkpointing
Training_Agnostic_Checkpointing
1Cycle_Learning_Rate_Schedule Simplified_Data_Loader
Simplified_Data_Loader
Communication_Logging Sparse_Attention
Latest_News Extreme_Speed_and_Scale_for_DL_Training_and_Inference
Extreme_Speed_and_Scale_for_DL_Training_and_Inference
Windows Features CM_CLI_testing Run_a_container_and_record_experiments_locally DCO
Features Dependencies Configure_Contributor_License_Agreement_within_two_minutes
Learning_rate_scaling_when_the_effective_batch_size_changes Configuring_ZeRO_configurations
Configuring_ZeRO_configurations Autotuning_Output
Autotuning_Output
Autotuning_Metric "throughput"__training_samples_per_second_(calculated_as
"throughput"__training_samples_per_second_(calculated_as
Max_Train_Batch_Size Model_Parallelism_Size
Model_Parallelism_Size
Megatron-DeepSpeed_on_AzureML Workspace_Setup
Workspace_Setup
End-to-end_Faster_and_Mask_R-CNN_baselines Comparison_with_Detectron_and_mmdetection
Comparison_with_Detectron_and_mmdetection
PASCAL_VOC_Annotations_in_COCO_Format Creating_Symlinks_for_Cityscapes_
Creating_Symlinks_for_Cityscapes_
Training_and_test_data_separation 4._Model
Optimizer 5._Quality 4._Quality
If_the_repository_is_not_in_the_PYTHONPATH,_make_sure_to_update Build_and_Deploy_HabanaLabs_MLPerf_Training_2.1_Container
Build_and_Deploy_HabanaLabs_MLPerf_Training_2.1_Container
Training_Data_Packing Training_Data_for_ResNet50
Training_Data_for_ResNet50
TTT_(Time_to_Train)_Calculation_for_BERT Training_ResNet50
Training_ResNet50
TTT_(Time_to_Train)_Calculation_for_ResNet50 Supported_Configurations
Supported_Configurations
Convert_NumPy_dataset_to_raw_format. Specify_the_preprocessed_data_paths_in_the_training_script.
Specify_the_preprocessed_data_paths_in_the_training_script.
the_Bug* Steps/Code_to_Reproduce_the_Bug*
Steps/Code_to_Reproduce_the_Bug*
Model_checkpoint 5._Quality
Evaluation_thoroughness 6._Additional_notes 6._Other MLCommons_Inference 5._Steps_to_run_the_model Reference_runs
6._Additional_notes
NF5**8_(single_node) Alternative_launch_with_nvidia-docker
Checkpoint Prepare_enviroment Running_the_model
Prepare_enviroment
Dataset Prepare_environment
Prepare_environment
Setup_Conda_Environment_and_Build_Dependencies Run_Benchmark
Run_Benchmark Setup_with_Docker
Pretrained_backbone Running_the_model
NVIDIA_DGX_H100_(single_node) Alternative_launch_with_nvidia-docker
Build_the_container_and_push_to_a_docker_registry. Running_training
Running_training
Alternative_launch_with_docker Steps_to_launch_training_on_multiple_nodes
Clean_up Running_the_model Librispeech
Decide_benchmark_name*_|_name_|_framework_|_acc._|_AUC_|_dataset Disclaimer
Disclaimer Prerequisites_and_Installation 2._Directions
Prerequisites_and_Installation
Calibration_set Running_the_benchmark
Running_the_benchmark
GPU Examples_for_testing
Examples_for_testing
Usage License Contact_us
License Credits
Take_into_account_that_we_only_update_the_published_wheels_after Testing_your_Installation
Testing_your_Installation
Installation_-_C++ Quick_start__Loadgen_Over_the_Network
Quick_start__Loadgen_Over_the_Network
The_MLPerf_spec_is_/always/_right._Please_file_a_LoadGen_bug_so_it Q__How_can_I_file_a_bug?
Q__How_can_I_file_a_bug?
On_GitHub__https_//github.com/mlcommons/inference/issues/new Q__Can_I_make_local_modifications_to_the_LoadGen_for_submission?
Q__Can_I_make_local_modifications_to_the_LoadGen_for_submission?
No. To_keep_the_playing_field_level,_please_upstream_any_local Q__Where_can_I_find_the_results_of_a_test?
Q__Where_can_I_find_the_results_of_a_test?
By_default,_the_loadgen_will_output_an_/mlperf_log_summary.txt/ Q__The_reference_implementation_for_</some_model/>_prints_out_results
Q__The_reference_implementation_for_</some_model/>_prints_out_results
They_are_not._The_LoadGen_results_are_the_ground_truth_for Q__I'm_getting_linker_errors_for_LoadgenVersion_definitions._Where_is
Q__I'm_getting_linker_errors_for_LoadgenVersion_definitions._Where_is
If_you_have_a_custom_build_setup,_make_sure_you_run_the Q__What_is_this_/version_generator.py/_script?
Q__What_is_this_/version_generator.py/_script?
The_LoadGen_records_git_stats_(if_available)_and_the_SHA1_of_all Q__How_do_I_view_the_/mlperf_log_trace.json/_file?
Q__How_do_I_view_the_/mlperf_log_trace.json/_file?
This_file_uses_the_[Trace_Event_Format] Q__Why_is_the_code_littered_with_so_many_lambdas?_My_eyes_hurt. Q__What_is_the_difference_between_the_MultiStream_and_MultiStreamFree
Q__Why_is_the_code_littered_with_so_many_lambdas?_My_eyes_hurt.
Lambdas_are_a_convenient_and_efficient_way_to_ship_arbitrary_data_+ Q__What_C++_version_does_the_LoadGen_target?
Q__What_C++_version_does_the_LoadGen_target?
It_currently_targets_and_requires_C++14._It_should_compile_with Q__What_dependencies_does_the_LoadGen_code_have?
Q__What_dependencies_does_the_LoadGen_code_have?
aware_of_how_to_score_the_accuracy_of_a_model's_outputs._*_*NOT* Submission_Considerations
Submission_Considerations
Choose_your_TestSettings_carefully! Responsibilities_of_a_LoadGen_User
Responsibilities_of_a_LoadGen_User
Assess_Accuracy LoadGen_over_the_Network
LoadGen_over_the_Network
QDL_Additional_Methods Example
Example META_is_config_valid() META_search_callback() Reusable_automation_actions Interaction_with_custom_artifact_stores In-Process_Triton_Server_API Extract Model_versioning
Setup RNNT 3d-unet Resnet50 Retinanet Bert GPT-J GCS_for_simple_task_signaling
RNNT
One_liner_to_do_an_end-to-end_submission_using_the_reference Please_adjust_the_=target_qps=_value_as_per_your_system_performance Please_modify_the_=--adr.gptj-model.checkpoint=_value_to_the_path
Please_adjust_the_=target_qps=_value_as_per_your_system_performance
Below_we_give_an_/essential/_sequence_of_steps_that_should_result Table_of_Contents
Table_of_Contents Description Getting_Started [[https_//github.com/d3/d3-array/blob/master/README.md][Arrays
CK_can_normally_detect_available_Python_interpreters Install_implicit_dependencies_via_pip
Install_implicit_dependencies_via_pip
These_dependencies_are_/implicit/,_i.e. CK_will_not_try_to_satisfy Install_explicit_dependencies_via_CK_(also_via_=pip=,_but_register
Install_explicit_dependencies_via_CK_(also_via_=pip=,_but_register
3d-unet
Retinanet
Validate_accuracy_for_ssd-mobilenet_and_ssd-resnet34_benchmarks Datasets
Datasets Running
This_part_is_only_necessary_if_the_accuracy_check_in_Part_II each_target_accuracy_metric,_the_delta_between_the_two_accuracy delta_between_the_two_accuracy_metrics_should_be_within_1%_for_the
each_target_accuracy_metric,_the_delta_between_the_two_accuracy
=generate_final_report.py=
Path_to_.csv_output_file_of_the Outputs
Outputs =log_parser.py= =submission_checker.py= =truncate_accuracy_log.py= =preprocess_submission.py= Parameters Calibration Load_and_run_a_model_in_Python
=log_parser.py=
=pack_submission.sh=_(Deprecated)
=repository_checks.sh=
=submission_checker.py=
Flag_to_avoid_checking_if_mandatory Summary
=truncate_accuracy_log.py=
Path_to_directory_containing_your_submission_*output*__Path_to Outputs
=preprocess_submission.py=
Running_other_datasets_ 3._Dataset
3._Dataset
Bert
GPT-J
Please_modify_the_=--adr.gptj-model.checkpoint=_value_to_the_path
Expected_time_to_do_benchmark_runs Validity_of_the_submission
Validity_of_the_submission
Reviewing_other_submissions Changes_from_MLCommons_Inference_3.0
Changes_from_MLCommons_Inference_3.0
This_document_is_autogenerated_from_internal_documentation._If Make_Targets HPE-NVIDIA_MLPerf_Quantization What_if_I_have_permission_issues_when_I_attempt_to_write_to_the Before_you_continue MLPerf_Inference_Policies_and_Terminology Heterogeneous_MIG_Workloads_for_Multi-MIG_Systems NVIDIA_MLPerf_Quantization NVIDIA_Submissions MLPerf_Quantization
Make_Targets
HPE-NVIDIA_MLPerf_Quantization
Make_sure_your_performance_tuning_changes_(i.e. any_change Difference_system_configurations_that_use_the_same_GPU_configuration
Difference_system_configurations_that_use_the_same_GPU_configuration
that_this_flag_is_only_supported_/_allowed_on_the_following you_wish_to_use_both_start_from_device_and_end_on_device,_you_must
you_wish_to_use_both_start_from_device_and_end_on_device,_you_must
in_order_to_use_start_from_device_or_end_on_device_in_a Using_NUMA_configurations
Using_NUMA_configurations
Fixing_INVALID_results
Tuning_parameters_for_better_performance
What_if_I_have_permission_issues_when_I_attempt_to_write_to_the
Before_you_continue
an_eye_out_for_this_announcement,_as_it_will_also_include_a submission_that_does_not_use_one_of_these_commit_hashes_will_not_be
submission_that_does_not_use_one_of_these_commit_hashes_will_not_be Minimal_Query_Count
Minimal_Query_Count
The_way_audit_tests_function_is_by_placing_an_=audit.conf= Truncating_the_Accuracy_Logs
Truncating_the_Accuracy_Logs
Make_sure_that_no_files_and_directories_exist_in_the_project The Encrypting_your_project_for_submission
The Packaging_your_project_for_submission
Packaging_your_project_for_submission
MLPerf_Inference_Policies_and_Terminology
that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and Download_the_Datasets Download_the_datasets Download_the_dataset_and_the_model
Download_the_Datasets
that_you_do_not_need_to_download_the_datasets_or_models_for Downloading_the_Model_files Downloading_the_model_files
Downloading_the_Model_files
proceeding,_double_check_that_you_have_downloaded_both_the Preprocessing_the_datasets_for_inference
Preprocessing_the_datasets_for_inference Running_NEUCHIPS_DLRM_benchmark
your_system_is_not_listed_above,_you_must_add_your_system_to_our Running_your_first_benchmark
Running_your_first_benchmark
enter_closed/HPE*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment
Launching_the_environment
notes_/* Building_the_binaries Launching_the_environment_on_a_MIG_(Multi-Instance_GPU)_instance Launching_the_environment_on_Jetson_Orin_systems Launching_the_environment_on_Jetson_Orin_AGX/NX Further_reading Adding_a_New_or_Custom_System
Building_the_binaries
This_command_does_not_need_to_be_run_every_time_you_enter_the Running_the_actual_benchmark
Running_the_actual_benchmark
you_run_into_issues,_invalid_results,_or_would_like_to_improve_your
engines_is_only_required_if* Building_and_running_engines_for_the_"High_Accuracy_Target"
Building_and_running_engines_for_the_"High_Accuracy_Target"
META_is_config_valid()
META_search_callback()
Preprocessing_the_dataset_for_use Model
Downloading_/_obtaining_the_model Optimizations Dataset
Optimizations
Embedding_Table_Sorting_and_Splitting Instructions_for_Auditors
Instructions_for_Auditors
Preprocessing_the_dataset_for_usage Model Optimizations
Soft_Dropping Instructions_for_Auditors
Goal_of_this_Benchmark Dataset
Preprocessing_the_dataset Model
Generating_model_binaries_and_running_INT8_calibration Instructions_for_Auditors Instructions_for_Audits
Sequence_Splitting Instructions_for_Audits
Instructions_for_Audits
Model_Source Optimizations
Lower_Precision Instructions_for_Audits Calibration
Preprocessing_data Model
Replace_ReLU6_with_ReLU Instructions_for_Audits
Removal_of_Softmax Calibration
Calibration Instructions_for_Audits
TransposedConvolution_->_Convolution_+_PixelShuffle_Conversion Instructions_for_Auditors
Training_(MobileNetV1-SSD)** Quantization_(ResNet50)**
Quantization_(ResNet50)**
enter_closed/NVIDIA*._From_now_on,_all_of_the_commands_detailed Launching_the_environment Launching_the_environment_on_datacenter/desktop_systems
Launching_the_environment_on_a_MIG_(Multi-Instance_GPU)_instance
=g292_z43_q16= Performance Power_(full)
Performance Benchmark_via_the_"neoclassical"_CK_interface SingleStream_scenario Prepare_your_submission Run_experiments_(via_cmdgen)
=g292_z43_q16=_[optional] Power
Power
=r282_z93_q5= Performance
=r282_z93_q5=_[optional] Power
precision_fp16 =g292_z43_q16= Performance =g292_z43_q16=_[optional] Power =r282_z93_q5= =r282_z93_q8= =r282_z93_q5=_[optional] =r282_z93_q8=_[optional]
=r282_z93_q8=
=r282_z93_q8=_[optional]
Fixed_SOC_Pstate_=_P0 DF_Common_Options
DF_Common_Options
ACPI_SRAT_L3_Cche_As_NUMA_Domain_=_Disabled CPU_Common_Options
CPU_Common_Options
L2_Up/Down_Prefetcher_=_Auto Management_Firmware_Settings
Management_Firmware_Settings
Power_(full)
Run_the_below_commands_with_=sudo=_or_as_superuser. Generic
Generic
=g++= =r282_z93_q5=__use_QAIC_settings_(ECC_on)
=r282_z93_q5=__use_QAIC_settings_(ECC_on)
Please_detect_only_one_Python_interpreter._We_recommend_Python Python_v3.8
Python_v3.8
CK_can_normally_detect_compilers_automatically,_but_we_are_playing Install_implicit_dependencies_via_pip
These_dependencies_are_/explicit/,_i.e. CK_will_try_to_satisfy Compile_the_Server/Offline_model_for_the_PCIe_server_cards Hint
Compile_the_Server/Offline_model_for_the_PCIe_server_cards
SingleStream Compile_and_install_the_models_to_the_16_NSP_AEDK Info Compile_and_install_the_models_to_the_20W_AEDK
Compile_and_install_the_models_to_the_16_NSP_AEDK
Info
Please_detect_only_one_Python_interpreter._Python_3.6,_the_default Python_v3.6_(default)
Python_v3.6_(default)
Hint Select_the_calibration_dataset Detect_a_pregenerated_profile
Since_the_preprocessed_=1200x1200=_COCO_dataset_takes_up_21G,_you Calibrate_on_your_own Use_precalibrated_profiles
Calibrate_on_your_own
For_more_information,_please_see_the Use_precalibrated_profiles Compilation_for_15w_AEDKs_(edge_category)
Use_precalibrated_profiles
Compile_and_install_the_models_to_the_20W_AEDK
Offline SingleStream
Since_the_preprocessed_ImageNet_dataset_takes_up_7.1G,_you_may Download_the_MLPerf_TensorFlow_model
Download_the_MLPerf_TensorFlow_model
The_input_tensor's_shape_gets_updated_("fixed")_from_=?x224x224x3= Obtain_a_profile_using
Obtain_a_profile_using
1_sample_per_batch_(for_the_Single_Stream_scenario) Calibrate_on_your_own
1_sample_per_batch_(for_the_SingleStream_scenario) Compile_the_Server/Offline_model_for_the_PCIe_server_cards Prerequisites
Accuracy_benchmark Quantization_and_calibration
Quantization_and_calibration
Q__What_is_the_difference_between_the_MultiStream_and_MultiStreamFree
MultiStream_corresponds_to_the_official_MLPerf_scenario_for Q__Why_is_the_code_littered_with_so_many_lambdas?_My_eyes_hurt.
This_excludes_"uber"_packages_which_can_be_used_to_install_all Run_the_TensorFlow_(Python)_Image_Classification_client
Run_the_TensorFlow_(Python)_Image_Classification_client
When_using_the_batch_count_of_*N*,_the_program_classifies_*N* Benchmark_the_accuracy ResNet
Benchmark_the_accuracy
For_the_=imagenet-2012-val-min=_dataset,_change Using_Collective_Knowledge ResNet
Using_Collective_Knowledge
Please_[[file_info@dividiti.com][let_us_know]]_if_you_would_like Install_the_models_for_TFLite
Install_the_models_for_TFLite
MobileNet_quantized Bonus__other_MobileNets_models Benchmark_the_accuracy Example__OpenCV_preprocessing_(default),_MobileNet_non-quantized Example__universal_OpenCV_preprocessing_(default),_MobileNet
Bonus__other_MobileNets_models Compile_the_TFLite_Image_Classification_client Compile_the_TensorFlow_(C++)_Image_Classification_client
Compile_the_TFLite_Image_Classification_client
OpenCV_preprocessing MobileNet_non-quantized MobileNet_quantized
MobileNet_non-quantized
The_prediction_from_=tflite=_differs_from_that_from_=tf-cpp=. Benchmark_the_performance
Benchmark_the_performance
ResNet
Example__OpenCV_preprocessing_(default),_MobileNet_non-quantized
If_you_would_like_to_get_a_feel_of_CK_workflows,_you_can_skip Install_common_tools_and_libraries
Install_common_tools_and_libraries
Care_must_be_taken_not_to_mix_Python_3_and_Python_2_packages._If Install_required_Python_3_packages
Install_required_Python_3_packages
Option_3__User-space_installation_via_CK_(under_=$HOME=_and [Optional]_Install_Android_SDK_and_NDK
[Optional]_Install_Android_SDK_and_NDK
On_Ubuntu_18.04,_NDK_r13b_gets_installed._On_Ubuntu_16.04, Pull_CK_repositories
Pull_CK_repositories
Transitive_dependencies_include Install_a_small_dataset_(500_images) Install_the_COCO_2017_validation_dataset_(5,000_images)
Install_a_small_dataset_(500_images)
ImageNet_dataset_descriptions_are_in Install_the_full_dataset_(50,000_images)
Install_the_full_dataset_(50,000_images)
If_you_already_have_the_ImageNet_validation_dataset_downloaded_in Preprocess_datasets
Preprocess_datasets
The_TFLite_weights_are_in_the_=mobilenet_v1_1.0_224*.tflite=_file. Inspecting_recorded_experimental_results
Inspecting_recorded_experimental_results
Image_cropping Visualizing_experimental_results
Visualizing_experimental_results
The_ResNet_model_has_a Install_models_for_TensorFlow_(C++)
Install_models_for_TensorFlow_(C++)
Compile_the_TensorFlow_(C++)_Image_Classification_client
TensorFlow_preprocessing MobileNet_non-quantized
TensorFlow_preprocessing_(*NOT_APPLICABLE!*) MobileNet_quantized Benchmark_the_performance
Example__universal_OpenCV_preprocessing_(default),_MobileNet
Install_the_ResNet_model Run_the_ONNX_Image_Classification_client
Run_the_ONNX_Image_Classification_client
MobileNet,_NCHW Benchmark_the_performance
Install_the_quantized_finetuned_model_(courtesy_of Run_the_TensorFlow_(Python)_Object_Detection_client_on_50_images
Run_the_TensorFlow_(Python)_Object_Detection_client_on_50_images
When_using_the_batch_count_of_*N*,_the_program_runs_object Benchmark_the_accuracy
Currently_we_have_no_TFLite_1.13.1_prebuilt_packages._Please Install_the_SSD-MobileNet_models_for_TFLite
Install_the_SSD-MobileNet_models_for_TFLite
This_TFLite_model_has_been Compile_the_TFLite_Object_Detection_client
Compile_the_TFLite_Object_Detection_client
We_are_working_on_resolving_the_difference_in_mAP_between_the_TF Benchmark_the_performance Using_Collective_Knowledge
Option_3__user-space_installation_via_CK_(under_=$HOME=_and Pull_CK_repositories
Install_the_COCO_2017_validation_dataset_(5,000_images)
If_you_have_previously_installed_the_COCO_2017_validation_dataset Preprocess_the_COCO_2017_validation_dataset_(first_50_images)
Preprocess_the_COCO_2017_validation_dataset_(first_50_images)
COCO_2017_validation_dataset Prerequisites_and_Installation
delta_between_the_two_accuracy_metrics_should_be_within_1%_for_the
Part_III___Compare_performance_of_TEST04-A_with_TEST04-B Help
Help
SSD_ResNet34_int8 ONNXRuntime_PTQ
ONNXRuntime_PTQ
[[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate Accuracy OpenCL "All-in-one" Note_that_unlike_[[#mobilenet_v1][MobileNet-v1]],
Accuracy Known_issues =llvm_-mcpu=cortex-a72_-mfloat-abi=hard= Setup_with_docker_image Get_the_Results CPU MobileNet-v2 MobileNet-v3 EfficientNet Direct_usage
OpenCL Performance Compliance Accuracy Benchmark_via_the_"neoclassical"_CK_interface MobileNet-v1 "All-in-one"
Compliance Notes
Use_a_uniform_target_latency [[https_//github.com/krai/ck-mlperf/tree/master/program/generate-target-latency][Estimate
Benchmark_via_the_"neoclassical"_CK_interface
=model-tflite-mlperf-efficientnet-lite4= [[https_//github.com/arm-software/armnn-mlperf#preprocess-on-an-x86-machine-and-detect-on-an-arm-dev-board][Detect
[[https_//github.com/arm-software/armnn-mlperf#preprocess-on-an-x86-machine-and-detect-on-an-arm-dev-board][Detect Benchmark_performance_via_the_"classical"_CK_interface Run_once_(classical_CK_interface)
Benchmark_performance_via_the_"classical"_CK_interface
AutoSinian Benchmarks
Benchmarks
Inside_the_Docker_container,_[[file_closed/Alibaba]]_will_be Prerequisites
Prerequisites
Run_harness_on_engines Notes_on_runtime_and_performance
Notes_on_runtime_and_performance
Run_Calibration Instructions_for_Auditors
Steps_to_do_calibration_for_RNNT
Install_Python_and_IPex Download_Model
Download_Model
2._SW_requirements Steps_to_run_DLRM Run_DLRM
Steps_to_run_DLRM
Run_command Setup_with_docker
Setup_with_docker
Setup_with_Docker
dataset_ 2.Start_a_container 2.load_images
2.Start_a_container
2._into_container 3.Run_SSD-Resnet34
3.Run_SSD-Resnet34
4._Run_command_for_server_and_offline_mode Setup_with_Docker
model_ 2.Start_and_log_into_a_container
2.Start_and_log_into_a_container
(2)_into_container 3.Run_DLRM 4.Run_Resnet50
3.Run_DLRM
Install_Dependencies_for_Resnet50 Download_Model
2.load_images
4.Run_Resnet50
Steps_to_run_RNNT
Note_on_Server_scenario Setup_with_Docker
To_verify_accuracy_of_your_workload,_run_your_command_with Code_Diagram
Code_Diagram
Known_issues
Heterogeneous_MIG_Workloads_for_Multi-MIG_Systems
for_short). How_the_HeteroMIG_harness_is_designed
How_the_HeteroMIG_harness_is_designed
NVIDIA_MLPerf_Quantization
refer_to_Intel's_readme_under_/closed/Intel_for_detailed Dell_Submission_Systems
Dell_Submission_Systems GPU_Implementations
GPU_Implementations
refer_to_/closed/NVIDIA_for_detailed_instructions,_including Dell_Submission_Systems
Inside_the_Docker_container,_[[file_closed/Fujitsu]]_will_be Before_you_run_commands Prerequisites
Before_you_run_commands
Run_Compliance_Tests_and_Update_Compliance_Logs Instructions_for_Auditors
Triton_Harness NVIDIA_Submissions
NVIDIA_Submissions
Inside_the_Docker_container,_[[file_closed/NVIDIA]]_will_be Prerequisites
Run_Triton_Harness Multi-MIG_Harness
Multi-MIG_Harness
*(DOCKER)*_Run_the_benchmark_ SSD-Resnet34 Run_the_BERT_benchmark Run_the_DLRM_benchmark Run_the_3D_U-Net_benchmark Limitations_and_Best_Practices_for_Running_MLPerf
SSD-Resnet34
Run_the_BERT_benchmark
Run_the_DLRM_benchmark
Run_the_3D_U-Net_benchmark
Limitations_and_Best_Practices_for_Running_MLPerf
you_add_your_entry_into_config.json*,_you_will_have_to_add_your Different_system_configurations_that_use_the_same_GPU_configuration
Different_system_configurations_that_use_the_same_GPU_configuration NUMA_configuration
NUMA_configuration
MultiStream Fix_INVALID_results Tune_parameters_for_better_performance Other_performance_tips
Fix_INVALID_results
Tune_parameters_for_better_performance
Other_performance_tips
permission_issue_when_container_tries_to_write_to_local get_=useradd__user_'root'_already_exists=_when_running
get_=useradd__user_'root'_already_exists=_when_running
do_I_install_programs_like_valgrind_in_the_container?* get_=nvcc_fatal_____Unsupported_gpu_architecture_'compute_80'=_error
get_=nvcc_fatal_____Unsupported_gpu_architecture_'compute_80'=_error
sure_you_run_the_below_commands_after_=results/=_is_populated_with Truncate_Accuracy_Logs
Truncate_Accuracy_Logs
Encrypting_your_project_for_submission
The_current_MLPerf_Inference_Results_Chair_is_Guenther Common_issues
Common_issues
Run_harness Notes_on_runtime_and_performance
enter_closed/Inspur*._From_now_on,_all_of_the_commands_detailed Launching_the_environment
=llvm_-mcpu=cortex-a72_-mfloat-abi=hard=
SingleStream_scenario
Prepare_your_submission Visualize_MLPerf_results
See_all_installed_packages_and_detected_components Resources Reproducibility_report__design_space_exploration Reproducibility_report__benchmarking Install_TFLite_model_(MobileNet_v2__Large__Minimalistic__224__1.0_ Install_PyTorch_model_(Resnet50__int8__quantized) Install_CK_workflow_Python_dependencies
Resources
WIP__DEFINE_PROD_AWS_ACCOUNT_OWNER_ID_=_{prod_aws_account_owner_id} Task_Owner_Setup
Task_Owner_Setup
Filling_in_the_rest_of_the_config Filling_in_=eval_config=
Filling_in_=eval_config=
2_*_Install_mlsphere_utility_and_download_the_image. Run
Run Open_discussions_and_developments
[NOTICE]_POSSIBLY_OUTDATED Web_Interface
Web_Interface
Running_the_API_server Frontend
Frontend
Concrete_example_that_illustrates_the_different_components_ Table_of_Contents
to_inform_their_work_or_research._The_way_a_given_task_is Codebase
Codebase
If_any_linter_doesn't_pass,_your_pull_request_is_not_going_to_be Migrations
Migrations
docker* virtualenv*
virtualenv*
your_model* Run_select_task
Run_select_task
The_cost_of_this_service_depends_on_the_instance_you_choose_and Creating_EC2_instance
Creating_EC2_instance
Open_EC2_ports_to_receive_requests Setting_up_AWS_environment
Setting_up_AWS_environment
This_service_is_free. Creating_user Creating_S3_bucket Creating_ECS_cluster
Creating_user
Creating_S3_bucket
The_cost_for_this_service_depends_on_the_size_of_the_files_that Creating_ECS_execution_role
Creating_ECS_execution_role
Creating_ECS_cluster
Create_SQS_queue Starting_the_app
Starting_the_app
Foldes_contents Resources_folder
Resources_folder
Checking_output_format Requirements
Run_Fast_api_swagger Test_your_endpoints
Test_your_endpoints
Removed [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-5-1][8.5.1 [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.07][22.07]]_- [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-4-1][8.4.1 [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.05][22.05]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.04][22.04]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.03][22.03]]_- [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-2-1][8.2.1 [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.10][21.10]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.09][21.09]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.08][21.08]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.07][21.07]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.05][21.05]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.03][21.03]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.02][21.02]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.12][20.12]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.11][20.11]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/20.10][20.10]]_- [[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-7.html#rel_7-2-1][7.2.1]]_- 21.02_Container_Release_-_2021-01-18 20.12_Container_Release_-_2020-12-17 v0.41.1_(2022-08-25) v0.40.4_(2022-08-17) v0.39.0_(2022-07-01) v0.37.3_(2022-05-04) v0.34.2_(2021-11-29) v0.33.2_(2021-10-21) v0.31.1_(2021-07-16) v0.27.0_(2021-04-06) v0.25.1_(2021-03-15) v0.23.1_(2021-02-05) v0.13.4_(2020-03-25) v0.7.1_(2019-08-29) v0.3.0_(2021-02-12) v0.2.2_(2020-06-17)
[[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-5-1][8.5.1
[[https_//github.com/NVIDIA/TensorRT/releases/tag/22.07][22.07]]_-
[[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-4-1][8.4.1
[[https_//github.com/NVIDIA/TensorRT/releases/tag/22.05][22.05]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/22.04][22.04]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/22.03][22.03]]_-
Changed [[https_//github.com/NVIDIA/TensorRT/releases/tag/22.02][22.02]]_- [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.04][21.04]]_- TensorRT_8.5_GA_Release_-_2022-11-2 Removed v0.47.0_(2023-03-28) v0.46.0_(2023-02-10) v0.45.2_(2023-01-25) v0.45.1_(2023-01-19) v0.40.2_(2022-08-12) v0.40.0_(2022-07-29) v0.37.2_(2022-04-20) v0.37.1_(2022-04-18) v0.36.4_(2022-04-12) v0.36.2_(2022-03-31) v0.35.0_(2022-01-06) v0.33.0_(2021-09-16) v0.31.0_(2021-07-02) v0.29.0_(2021-04-28) v0.28.3_(2021-04-22) v0.23.3_(2021-02-13) v0.23.2_(2021-02-11) v0.20.6_(2020-09-18) v0.14.1_(2020-04-17) v0.14.0_(2020-04-09) v0.13.3_(2020-03-20) v0.12.0_(2020-03-06) v0.11.2_(2020-02-11) v0.10.3_(2019-11-18) v0.10.1_(2019-10-31) v0.9.8_(2019-10-24) v0.9.6_(2019-10-15) v0.9.5_(2019-10-9) v0.9.3_(2019-10-1) v0.9.1_(2019-10-1) v0.9.0_(2019-09-30) v0.8.1_(2019-09-26) v0.8.0_(2019-09-18) v0.6.0_(2019-07-17) v0.3.21_(2022-08-19) v0.3.8_(2021-04-15) v0.3.1_(2021-02-12) v0.2.8_(2020-10-08) v0.2.6_(2020-09-25) v0.2.5_(2020-09-21) v0.1.3_(2020-02-26) v0.1.0_(2020-02-11) v0.0.7_(2022-08-10) v0.0.5_(2020-07-21) v0.0.4_(2020-07-18) v0.0.2_(2020-07-05)
[[https_//github.com/NVIDIA/TensorRT/releases/tag/22.02][22.02]]_-
[[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/#rel-8-2-1][8.2.1
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.10][21.10]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.09][21.09]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.08][21.08]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.07][21.07]]_-
Notes [[https_//github.com/NVIDIA/TensorRT/releases/tag/21.06][21.06]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.06][21.06]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.05][21.05]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.04][21.04]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.03][21.03]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/21.02][21.02]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/20.12][20.12]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/20.11][20.11]]_-
[[https_//github.com/NVIDIA/TensorRT/releases/tag/20.10][20.10]]_-
[[https_//docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-7.html#rel_7-2-1][7.2.1]]_-
Version*_ GPU*_ Relevant_Files
GPU*_
Driver_Version*_ Version*_
Relevant_Files
link*_ Steps_To_Reproduce
Steps_To_Reproduce
or_scripts*_ you_tried_[[https_//developer.nvidia.com/tensorrt][the_latest
you_tried_[[https_//developer.nvidia.com/tensorrt][the_latest this_model_run_on_other_frameworks?*_For_example_run_ONNX_model
this_model_run_on_other_frameworks?*_For_example_run_ONNX_model
Version_Info Setup
Quick_Start_Guide
Since_the_datasets_and_checkpoints_are_stored_in_the_directory (Optional)_Trying_a_different_configuration
(Optional)_Trying_a_different_configuration Advanced
Advanced
TensorRT_inference_process Accuracy
the_TensorRT_engine*_ a_question*_
a_question*_
F1_score*_ Performance
The_time_measurements_do_not_include_the_time_required_to_copy Results
Results 
Megatron_Large_with_Sparsity Inference_performance__NVIDIA_A30
Inference_performance__NVIDIA_A30
Software_Versions Quick_Start_Guide
TensorRT_inference_benchmark Results
Types_of_changes [1.3.4]_-_2023-02-02
[1.3.4]_-_2023-02-02
note_that_due_to_end-of-life,_Python_<=_3.6_is_no_longer File_Structure
File_Structure
Ubuntu_20.04_on_x86-64_with_cuda-11.6.2_(default)* Step_1__PyTorch_model_to_ONNX_model
Step_1__PyTorch_model_to_ONNX_model
Install_required_packages Running_demoDiffusion
Running_demoDiffusion
=getPluginCreator()_could_not_find_Plugin_<operator_name>_version_1= Custom_Layer_Support
Custom_Layer_Support
TensorRT_8.5_GA_Release_-_2022-11-2
Deprecated TensorRT_8.4_GA_Release_-_2022-6-6
TensorRT_8.4_GA_Release_-_2022-6-6
Fixes TensorRT_8.2_GA_Release_-_2021-11-23 TensorRT_8.2_EA_Release_-_2021-10-04 21.03_Container_Release_-_2021-03-09 TensorRT_7.2.1_Release_-_2020-10-20
TensorRT_8.2_GA_Release_-_2021-11-23
TensorRT_8.2_EA_Release_-_2021-10-04
Updated TensorRT_8.0_Release_-_2021-07-02 21.05_Container_Release_-_2021-05-17
TensorRT_8.0_Release_-_2021-07-02
21.05_Container_Release_-_2021-05-17
21.03_Container_Release_-_2021-03-09
21.02_Container_Release_-_2021-01-18
20.12_Container_Release_-_2020-12-17
TensorRT_7.2.1_Release_-_2020-10-20
Version*__*ONNX-TensorRT_Version_/_Branch*__*GPU_Type*_ Driver_Version*__*CUDA_Version*__*CUDNN_Version*__*Operating
Driver_Version*__*CUDA_Version*__*CUDNN_Version*__*Operating
or_Container_(if_container_which_image_+_tag)*_ Relevant_Files
Full_Dimensions_+_Dynamic_Shapes 
Supported_Operators Installation
InstanceNormalizaiton_Performance Executable_Usage
Executable_Usage
Python_Modules ONNX-TensorRT_Python_Backend_Usage
ONNX-TensorRT_Python_Backend_Usage
Tests Pre-trained_Models
Pre-trained_Models
Add_PyConfig.h Build_Python_bindings
Build_Python_bindings
GA_build*_* Packages*_*_[[https_//developer.nvidia.com/cuda-toolkit][CUDA]]
Packages*_*_[[https_//developer.nvidia.com/cuda-toolkit][CUDA]] Recommended_versions__*_cuda-12.2.0_+_cuDNN-8.8_*_cuda-11.8.0_+
Recommended_versions__*_cuda-12.2.0_+_cuDNN-8.8_*_cuda-11.8.0_+
Packages*_*_Containerized_build_* Downloading_TensorRT_Build
Downloading_TensorRT_Build
Building_TensorRT-OSS References
Common_Pitfalls Appendix
Appendix
Terminology NVIDIA_Copyright Pretraining_on_the_source_dataset
NVIDIA_Copyright
Yapf Test
Test
Quantization_mode Misc
Misc
NGC_Container Resources
A_Possible_Solution Running_The_Example
Running_The_Example
/This_example_requires_TensorRT_8.4_or_later./ Using_The_=--layer-precisions=_Option
Using_The_=--layer-precisions=_Option
Run_the_network_script_but_allow_TensorRT_to_ignore See_Also
See_Also
Comparing_Different_Models Further_Reading
Further_Reading
TIP__Generating_Script_Templates_Automatically Running_The_Example
Comparing_Per-Layer_Outputs_Between_ONNX-Runtime_And_TensorRT Further_Reading
v0.47.0_(2023-03-28)
Fixed v0.46.2_(2023-02-28) v0.46.1_(2023-02-27) v0.45.3_(2023-01-25) Removed v0.44.1_(2022-12-06) v0.44.0_(2022-11-30) v0.43.1_(2022-10-12) v0.43.0_(2022-10-06) 0.42.2_(2022-09-22) v0.42.1_(2022-09-07) v0.42.0_(2022-09-01) v0.41.0_(2022-08-24) v0.40.3_(2022-08-17) v0.40.1_(2022-08-08) v0.38.0_(2022-05-24) v0.36.3_(2022-04-07) v0.36.1_(2022-03-25) v0.36.0_(2022-02-24) v0.35.2_(2022-02-03) v0.35.1_(2022-01-14) v0.33.1_(2021-10-08) v0.32.0_(2021-08-10) v0.30.3_(2021-06-25) v0.30.2_(2021-06-15) v0.30.1_(2021-06-07) v0.30.0_(2021-05-26) v0.29.2_(2021-04-30) v0.28.7_(2021-04-26) v0.28.6_(2021-04-23) v0.28.5_(2021-04-23) v0.28.2_(2021-04-22) v0.28.1_(2021-04-22) v0.28.0_(2021-04-20) v0.26.1_(2021-04-01) v0.26.0_(2021-03-30) v0.25.0_(2021-03-01) v0.24.2_(2021-02-25) v0.24.1_(2021-02-22) v0.24.0_(2021-02-19) v0.23.4_(2021-02-15) v0.23.0_(2021-02-02) v0.22.0_(2021-01-20) v0.21.1_(2021-01-12) v0.20.13_(2020-10-08) v0.20.12_(2020-10-01) v0.20.10_(2020-09-23) v0.20.9_(2020-09-22) v0.20.8_(2020-09-22) v0.20.7_(2020-09-22) v0.20.4_(2020-09-14) v0.20.3_(2020-09-11) v0.20.2_(2020-09-11) v0.20.1_(2020-09-09) v0.20.0_(2020-09-08) v0.17.0_(2020-07-20) v0.16.0_(2020-06-11) v0.15.0_(2020-05-05) v0.13.1_(2020-03-17) v0.13.0_(2020-03-17) v0.11.3_(2020-02-25) v0.11.0_(2020-01-28) v0.10.6_(2019-12-11) v0.10.5_(2019-12-9) v0.10.4_(2019-12-4) v0.10.2_(2019-11-11) v0.9.7_(2019-10-18) v0.9.4_(2019-10-7) v0.7.0_(2019-07-30) v0.3.25_(2022-10-14) v0.3.24_(2022-08-31) v0.3.23_(2022-08-24) v0.3.22_(2022-08-22) v0.3.19_(2022-04-13) v0.3.17_(2022-03-18) v0.3.15_(2022-01-18) v0.3.14_(2021-10-14) v0.3.13_(2021-09-21) v0.3.10_(2021-05-20) v0.3.7_(2021-03-31) v0.3.6_(2021-03-27) v0.3.5_(2021-03-24) v0.3.4_(2021-03-10) v0.3.3_(2021-03-04) v0.3.2_(2021-02-13) v0.2.9_(2021-02-01) v0.2.7_(2020-09-29) v0.2.4_(2020-09-14) v0.2.3_(2020-06-17) v0.2.1_(2020-06-10) v0.1.2_(2020-02-19) v0.0.6_(2020-07-21) v0.0.1_(2022-06-23)
v0.46.2_(2023-02-28)
v0.46.1_(2023-02-27)
v0.46.0_(2023-02-10)
v0.45.3_(2023-01-25)
v0.45.2_(2023-01-25)
v0.45.1_(2023-01-19)
Added v0.45.0_(2023-01-12) v0.38.1_(2022-06-22) v0.37.0_(2022-04-18) v0.34.1_(2021-11-24) v0.34.0_(2021-11-22) v0.29.1_(2021-04-28) v0.28.4_(2021-04-23) v0.21.0_(2020-11-30) v0.20.11_(2020-09-25) v0.20.5_(2020-09-16) v0.13.2_(2020-03-20) v0.11.1_(2020-02-11) v0.10.0_(2019-10-28) v0.9.2_(2019-10-1) Changed v0.3.20_(2022-07-12) v0.3.18_(2022-03-31) v0.3.16_(2022-02-23) v0.3.12_(2021-08-24) v0.3.11_(2021-07-14) v0.3.9_(2021-04-20) v0.2.0_(2020-04-15) v0.1.1_(2020-02-11) v0.0.3_(2020-07-15)
v0.45.0_(2023-01-12)
v0.44.1_(2022-12-06)
v0.44.0_(2022-11-30)
v0.43.1_(2022-10-12)
v0.43.0_(2022-10-06)
0.42.2_(2022-09-22)
v0.42.1_(2022-09-07)
v0.42.0_(2022-09-01)
v0.41.1_(2022-08-25)
v0.41.0_(2022-08-24)
v0.40.4_(2022-08-17)
v0.40.3_(2022-08-17)
v0.40.2_(2022-08-12)
v0.40.1_(2022-08-08)
v0.40.0_(2022-07-29)
v0.39.0_(2022-07-01)
v0.38.1_(2022-06-22)
v0.38.0_(2022-05-24)
v0.37.3_(2022-05-04)
v0.37.2_(2022-04-20)
v0.37.1_(2022-04-18)
v0.37.0_(2022-04-18)
v0.36.4_(2022-04-12)
v0.36.3_(2022-04-07)
v0.36.2_(2022-03-31)
v0.36.1_(2022-03-25)
v0.36.0_(2022-02-24)
v0.35.2_(2022-02-03)
v0.35.1_(2022-01-14)
v0.35.0_(2022-01-06)
v0.34.2_(2021-11-29)
v0.34.1_(2021-11-24)
v0.34.0_(2021-11-22)
v0.33.2_(2021-10-21)
v0.33.1_(2021-10-08)
v0.33.0_(2021-09-16)
v0.32.0_(2021-08-10)
v0.31.1_(2021-07-16)
v0.31.0_(2021-07-02)
v0.30.3_(2021-06-25)
v0.30.2_(2021-06-15)
v0.30.1_(2021-06-07)
v0.30.0_(2021-05-26)
v0.29.2_(2021-04-30)
v0.29.1_(2021-04-28)
v0.29.0_(2021-04-28)
v0.28.7_(2021-04-26)
v0.28.6_(2021-04-23)
v0.28.5_(2021-04-23)
v0.28.4_(2021-04-23)
v0.28.3_(2021-04-22)
v0.28.2_(2021-04-22)
v0.28.1_(2021-04-22)
v0.28.0_(2021-04-20)
v0.27.0_(2021-04-06)
v0.26.1_(2021-04-01)
v0.26.0_(2021-03-30)
v0.25.1_(2021-03-15)
v0.25.0_(2021-03-01)
v0.24.2_(2021-02-25)
v0.24.1_(2021-02-22)
v0.24.0_(2021-02-19)
v0.23.4_(2021-02-15)
v0.23.3_(2021-02-13)
v0.23.2_(2021-02-11)
v0.23.1_(2021-02-05)
v0.23.0_(2021-02-02)
v0.22.0_(2021-01-20)
v0.21.1_(2021-01-12)
v0.21.0_(2020-11-30)
v0.20.13_(2020-10-08)
v0.20.12_(2020-10-01)
v0.20.11_(2020-09-25)
v0.20.10_(2020-09-23)
v0.20.9_(2020-09-22)
v0.20.8_(2020-09-22)
v0.20.7_(2020-09-22)
v0.20.6_(2020-09-18)
v0.20.5_(2020-09-16)
v0.20.4_(2020-09-14)
v0.20.3_(2020-09-11)
v0.20.2_(2020-09-11)
v0.20.1_(2020-09-09)
v0.20.0_(2020-09-08)
v0.17.0_(2020-07-20)
v0.16.0_(2020-06-11)
v0.15.0_(2020-05-05)
v0.14.1_(2020-04-17)
v0.14.0_(2020-04-09)
v0.13.4_(2020-03-25)
v0.13.3_(2020-03-20)
v0.13.2_(2020-03-20)
v0.13.1_(2020-03-17)
v0.13.0_(2020-03-17)
v0.12.0_(2020-03-06)
v0.11.3_(2020-02-25)
v0.11.2_(2020-02-11)
v0.11.1_(2020-02-11)
v0.11.0_(2020-01-28)
v0.10.6_(2019-12-11)
v0.10.5_(2019-12-9)
v0.10.4_(2019-12-4)
v0.10.3_(2019-11-18)
v0.10.2_(2019-11-11)
v0.10.1_(2019-10-31)
v0.10.0_(2019-10-28)
v0.9.8_(2019-10-24)
v0.9.7_(2019-10-18)
v0.9.6_(2019-10-15)
v0.9.5_(2019-10-9)
v0.9.4_(2019-10-7)
v0.9.3_(2019-10-1)
v0.9.2_(2019-10-1)
v0.9.1_(2019-10-1)
v0.9.0_(2019-09-30)
v0.8.1_(2019-09-26)
v0.8.0_(2019-09-18)
v0.7.1_(2019-08-29)
v0.7.0_(2019-07-30)
v0.6.0_(2019-07-17)
Adding_Tests Design_Principles
Design_Principles
Generating_Golden_Values Tips_And_Tricks
Tips_And_Tricks
Reduction_Modes Further_Reading
Sanity-checking_for_FP16_limitations Debugging_accuracy_failures
Debugging_accuracy_failures
*Polygraphy_supports_only_Python_3.6_and_later.*_*Before Installing_Prebuilt_Wheels
Installing_Prebuilt_Wheels
/On_Linux,_the_command-line_toolkit_is_usually_installed_to Building_From_Source
Building_From_Source
Building_Manually Installing_Dependencies Examples
Installing_Dependencies
/By_default,_dependencies_will_be_installed_using_the_current Installing_Manually
Installing_Manually Command-line_Toolkit
Command-line_Toolkit
Python_API Examples
Examples Raw_Binary_Request Unload Reference Determinism_when_scanning *ai.onnx.ml.Binarizer* *ai.onnx.ml.CastMap* *ai.onnx.ml.LinearClassifier* *Acosh* *Add* *AffineGrid* *And* *ArgMax* *ArgMin* *Asin* *Asinh* *Atan* *Atanh* *AveragePool* *BatchNormalization* *Bernoulli* *BitShift* *BitwiseAnd* *BitwiseNot* *BitwiseOr* *BitwiseXor* *BlackmanWindow* *Cast* *CastLike* *Ceil* *Celu* *CenterCropPad* *Clip* *Col2Im* *Compress* *Concat* *ConcatFromSequence* *ConstantOfShape* *Conv* *ConvInteger* *ConvTranspose* *Cos* *Cosh* *CumSum* *DFT* *DeformConv* *DepthToSpace* *DequantizeLinear* *Det* *Div* *Dropout* *DynamicQuantizeLinear* *Einsum* *Elu* *Equal* *Erf* *Exp* *Expand* *EyeLike* *Flatten* *Floor* *GRU* *Gather* *GatherElements* *GatherND* *Gelu* *Gemm* *GlobalAveragePool* *GlobalLpPool* *Greater* *GreaterOrEqual* *GroupNormalization* *HammingWindow* *HannWindow* *HardSigmoid* *HardSwish* *Hardmax* *Identity* *If* *ImageDecoder* *InstanceNormalization* *IsInf* *IsNaN* *LRN* *LSTM* *LayerNormalization* *LeakyRelu* *Less* *LessOrEqual* *LogSoftmax* *Loop* *LpNormalization* *MatMul* *MatMulInteger* *Max* *MaxPool* *MaxRoiPool* *Mean* *MeanVarianceNormalization* *MelWeightMatrix* *Min* *Mish* *Mod* *Mul* *Multinomial* *NegativeLogLikelihoodLoss* *NonMaxSuppression* *NonZero* *Not* *OneHot* *Optional* *Or* *PRelu* *Pad* *Pow* *QLinearConv* *QLinearMatMul* *QuantizeLinear* *RNN* *RandomNormal* *Reciprocal* *ReduceL1* *ReduceL2* *ReduceLogSum* *ReduceLogSumExp* *ReduceMax* *ReduceMean* *ReduceMin* *ReduceProd* *ReduceSum* *ReduceSumSquare* *RegexFullMatch* *Relu* *Reshape* *Resize* *ReverseSequence* *RoiAlign* *Round* *STFT* *Scan* *Scatter*_(deprecated) *ScatterElements* *ScatterND* *Selu* *SequenceAt* *SequenceLength* *Shape* *Shrink* *Sigmoid* *Sign* *Sin* *Sinh* *Size* *Slice* *Softmax* *SoftmaxCrossEntropyLoss* *Softplus* *Softsign* *SpaceToDepth* *Split* *SplitToSequence* *Sqrt* *Squeeze* *StringConcat* *StringNormalizer* *StringSplit* *Sub* *Sum* *Tan* *Tanh* *TfIdfVectorizer* *ThresholdedRelu* *Tile* *TopK* *Transpose* *Trilu* *Unique* *Unsqueeze* *Upsample*_(deprecated) *Where* *Xor* ai.onnx.preview.training *ai.onnx.preview.training.Adam* *ai.onnx.preview.training.Gradient* *ai.onnx.preview.training.Momentum*
To_help_you_get_started_with_the_API,_you_can_use_the Backends
Backends
Runners_may_reuse_their_output_buffers._Thus,_if_you_need Writing_A_Custom_Runner
Writing_A_Custom_Runner Comparator
Comparator
The_Comparator_is_designed_for_scenarios_where_you_need_to Data_Loaders
Data_Loaders
Polygraphy_provides_a_default_=DataLoader=_class_that_uses_numpy Logger
Logger
Building_Python_API_Documentation_Locally Deprecation_Policy
Deprecation_Policy
Modifying_Input_Shapes_In_An_ONNX_Model Advanced_Topics
Reducing_Failing_ONNX_Models Examples
For_CLI_run,_please_go_to_the_cloned_repository's_root_directory 2._Data_preparation
2._Data_preparation
B._Conversion_to_tfrecord Workflow
Workflow
2.2._TensorRT_Inference Additional_resources
Additional_resources
Aware_Training* 
Step_4__TensorRT_Deployment Results
Step_3__TensorRT_Deployment Results
no_residual_connections_exist_in_MobileNet-v1. MobileNet-v2
MobileNet-v2 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/efficientnet][EfficientNet]]
residual_connections_exist_in_MobileNet-v2. Notes
QAT Only_accuracy
Only_accuracy
Layer_Class NVIDIA(R)_vs_TensorFlow_Toolkit
NVIDIA(R)_vs_TensorFlow_Toolkit
Perform_custom_quantization_on_a_ResNet-like_model._More *Default_Quantization*
*Default_Quantization*
*Custom_Quantization_with_'Custom_Q/DQ_Insertion_Case'_(optimal)* *Library_provided_custom_Q/DQ_insertion_cases*
*Library_provided_custom_Q/DQ_insertion_cases*
Layers* Layers*_Other_layers_are_inherited_from_=BaseQuantizeWrapper=
Layers*_Other_layers_are_inherited_from_=BaseQuantizeWrapper= *How_to_add_a_new_wrapper?*
*How_to_add_a_new_wrapper?*
ResNet101-v2 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/mobilenet][MobileNet]]
[[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/mobilenet][MobileNet]]
[[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/efficientnet][EfficientNet]]
EfficientNet-B3 [[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/inception][Inception]]
[[https_//github.com/NVIDIA/TensorRT/tree/main/tools/tensorflow-quantization/examples/inception][Inception]]
Dependencies
>=_2.8\\ >=_1.10.1\\
>=_1.10.1\\
(optional)_>=_8.4_GA Installation
Local Documentation
Documentation License
You_still_need_to_set_=Graph=_inputs_and_outputs_yourself! Running_the_example
Running_the_example
be_folded_-_=((x_+_c0)_+_c1)_+_c2=_will_*not*_be_folded,_even Prerequisites
v0.3.25_(2022-10-14)
v0.3.24_(2022-08-31)
v0.3.23_(2022-08-24)
v0.3.22_(2022-08-22)
v0.3.21_(2022-08-19)
v0.3.20_(2022-07-12)
v0.3.19_(2022-04-13)
v0.3.18_(2022-03-31)
v0.3.17_(2022-03-18)
v0.3.16_(2022-02-23)
v0.3.15_(2022-01-18)
v0.3.14_(2021-10-14)
v0.3.13_(2021-09-21)
v0.3.12_(2021-08-24)
v0.3.11_(2021-07-14)
v0.3.10_(2021-05-20)
v0.3.9_(2021-04-20)
v0.3.8_(2021-04-15)
v0.3.7_(2021-03-31)
v0.3.6_(2021-03-27)
v0.3.5_(2021-03-24)
v0.3.4_(2021-03-10)
v0.3.3_(2021-03-04)
v0.3.2_(2021-02-13)
v0.3.1_(2021-02-12)
v0.3.0_(2021-02-12)
v0.2.9_(2021-02-01)
v0.2.8_(2020-10-08)
v0.2.7_(2020-09-29)
v0.2.6_(2020-09-25)
v0.2.5_(2020-09-21)
v0.2.4_(2020-09-14)
v0.2.3_(2020-06-17)
v0.2.2_(2020-06-17)
v0.2.1_(2020-06-10)
v0.2.0_(2020-04-15)
v0.1.3_(2020-02-26)
v0.1.2_(2020-02-19)
v0.1.1_(2020-02-11)
v0.1.0_(2020-02-11)
Tensor example_constant_tensor_from_ResNet50_*
example_constant_tensor_from_ResNet50_*
Node example_ReLU_node_from_ResNet50_*
example_ReLU_node_from_ResNet50_*
Graph Exporters
Exporters Advanced
v0.0.7_(2022-08-10)
v0.0.6_(2020-07-21)
v0.0.5_(2020-07-21)
v0.0.4_(2020-07-18)
v0.0.3_(2020-07-15)
v0.0.2_(2020-07-05)
v0.0.1_(2022-06-23)
Of_Contents* Description
Setup_the_algorithm_selectors Preparing_sample_data
Preparing_sample_data
Sample_=--help=_options Additional_resources Models_other_than_ResNet-50_with_custom_configuration
- License per-tensor_dynamic_range_*_- -
2019*_-_This_=README.md=_file_was_recreated,_updated_and Known_issues
Of_Contents*_-_[[#description][Description]]_- Description
TensorRT_API_layers_and_ops Preparing_sample_data Prerequisites Running_the_sample
2022*_-_Migrated_code_from_parsing_a_=caffe=_model_to_an_=onnx= 2021*_-_Change_names_and_topic_from_"reformat-free"_to_"I/O
2021*_-_Change_names_and_topic_from_"reformat-free"_to_"I/O
2019*_-_This_is_the_first_release_of_the_=README.md=_file_and Known_issues
Running_the_sample Additional_resources
Benchmark_Engine Inference
Inference Plot_the_final_results
Sample_Images Evaluate_mAP_Metric
Evaluate_mAP_Metric
This_sample_is_not_supported_on_Ubuntu_14.04_and_older. Prerequisites
2._EfficientNet_V2 Create_ONNX_Graph
Create_ONNX_Graph
INT8_Precision Benchmark_TensorRT_Engine
Benchmark_TensorRT_Engine Inference
Depending_on_the_saved_model_exporter,_some_EfficientNet_V1 Inference_in_Python
Inference_in_Python
Please_make_sure_that_the_=onnx-graphsurgeon=_module_installed Model_Conversion
Model_Conversion
TFOD_EfficientDet_models_will_have_a_slightly_reduced_throughput 3._TFHub_Models
3._TFHub_Models Create_ONNX_Graph
Sample_--help_options Additional_resources
In_order_to_proceed,_you_need_to_re-export_the_saved_model._If Create_ONNX_Graph
If_you_receive_any_error_messages_about_non_sufficient_workspace INT8_Precision
Mask_R-CNN Evaluate_mAP_Metric
R-CNN*,_default_is_0.5. TF_vs_TRT_Comparison
TF_vs_TRT_Comparison
onnx_resnet50 Prerequisites
-_[[https_//arxiv.org/pdf/1512.03385.pdf][Deep_Residual -
3._Application_Samples Known_Limitations
Known_Limitations
Of_Contents*_- Description
Additional_preprocessing_needs_to_be_applied_to_the_data_before TensorRT_API_layers_and_ops
Layer*_-_[[https_//arxiv.org/abs/1807.03247][Arxiv_paper_by -_[[https_//github.com/onnx/onnx][GitHub__ONNX]]_-
-_[[https_//github.com/onnx/onnx][GitHub__ONNX]]_-
If_you_wanted_to_train_your_own_model_and_then_perform_inference TensorRT_API_layers_and_ops
Of_Contents*_-_[[#tensorrt-command-line-wrapper-trtexec][TensorRT Description
network*_-_If_you_have_a_model_saved_as_a_UFF_file,_ONNX engine_generation*_-_If_you_generate_a_saved_serialized
engine_generation*_-_If_you_generate_a_saved_serialized Building_=trtexec=
Building_=trtexec=
Example_6__Tune_throughput_with_multi-streaming Tool_command_line_arguments
Tool_command_line_arguments
Specifying_the_=--safe=_parameter_turns_the_safety_mode_switch Additional_resources
Models_other_than_ResNet-50_with_custom_configuration
per-tensor_dynamic_range_*_-
It's_important_to_preprocess_the_data_and_convert_it_to_the TensorRT_API_layers_and_ops
Enabling_proto2_features Generated_code
Generated_code
Extensions APIs
APIs
Serialization_performance The_cpp_performance_can_be_improved_by_using
The_cpp_performance_can_be_improved_by_using
To_iterate_over_all_oneofs Updating_Reflection
Updating_Reflection
Programming_Languages C#__https_//silentorbit.com/protobuf/_*_C#/.NET/WCF/VB_
C#__https_//silentorbit.com/protobuf/_*_C#/.NET/WCF/VB_
Presence_in_proto3_APIs Semantic_differences
Semantic_differences
Considerations_for_change-compatibility How_to_enable_/explicit_presence/_in_proto3
How_to_enable_/explicit_presence/_in_proto3
Coding_Style Contributing_Process
Contributing_Process
Installation_from_PECL PHP_Package
PHP_Package
Installation_from_composer Protoc
Protoc Usage
Example_build_invocation Options
Options displayInput___default=true_|_false=hide_input._*_displayPrevious__
Windows_build To_push_artifacts_to_Maven_Central
To_push_artifacts_to_Maven_Central
Use_Java_Protocol_Buffers_with_Bazel Build_from_Source
Build_from_Source
Build_from_Source_-_Without_Maven Compatibility_Notice
Compatibility_Notice
dependent_packages* for_Mac_users*
for_Mac_users*
for_AIX_users* C++_Installation_-_Windows
C++_Installation_-_Windows
(no_default) Objective_C_Generator_=protoc=_Options
Objective_C_Generator_=protoc=_Options
C Run_instructions Benchmark_datasets
Run_instructions
CPP_generated_code_ Go Go_
Go
PHP_with_c_extension Node.js
Node.js
Go_
Benchmark_datasets
Unit_Tests Compiling
Compiling
Of_Contents*_-_[[#description][Description]]_* Description
input*_The_scores_input_are_of_shape Parameters
Parameters Limitations License Additional_Resources
Structure Parameters Additional_resources SIG_-_Special_Interest_Groups
-_[[https_//arxiv.org/pdf/1812.05784][PointPillars]] License
The_above_settings_are_slightly_different_to_the_original Additional_resources
Of_Contents*_-_[[#changelog][Changelog]]_- Changelog
Changelog
Transformation*__This_flag_primarily_defines_various_offsets Malformed_Boxes_by_+1*__Some_legacy_implementations_of_ROI
Malformed_Boxes_by_+1*__Some_legacy_implementations_of_ROI Additional_Resources
Additional_Resources 
-_[[https_//arxiv.org/abs/1506.04579][ParseNet_Paper]]\\ License
Anchors_Input_(Optional) Dynamic_Shape_Support
Dynamic_Shape_Support
Limitations
Using_the_Fused_Box_Decoder Additional_Resources
-_[[https_//arxiv.org/abs/1512.02325][SSD__Single_Shot License
=t_w=_and_=t_h=_from_the_input_remain_unchanged. Parameters
-_[[https_//arxiv.org/abs/1612.08242][YOLOv2_paper]] License
-_[[https_//arxiv.org/pdf/2010.04159.pdf][Deformable_DETR]] License
-_[[https_//arxiv.org/abs/1504.08083][Original_ROI License
-_[[https_//arxiv.org/abs/1504.08083][ROI_Pooling License
-_[[https_//arxiv.org/abs/1810.04805][BERT]] License
-_[[https_//arxiv.org/abs/1706.03762][Transformer]] License
-_[[https_//arxiv.org/abs/1506.01497][Faster_R-CNN]] License
This_code_is_almost_the_same_to_=CodeTypeSSD__CENTER_SIZE=_using =inputOrder=
=inputOrder= Additional_resources
Of_Contents*_-_[[#coordconvacplugin][coordConvACPlugin]]_- Description
What_if_the_limit_is_zero? 7._Verify_download
7._Verify_download
Run_Hello_World_MLCube_example Setup_Docker
Setup_Docker
Workspace MNIST_MLCube_directory_structure_summary
MNIST_MLCube_directory_structure_summary
docs-site_Action_Development_documentation python-publish_action
python-publish_action
On_Windows Installation
NEW__The_KiTS23_Challenge_is_Underway! KiTS19
KiTS19
Labeling_Errors Challenge_Results_and_References
Challenge_Results_and_References
FileSet
RecordSet
Field
DataSource
extract
fileProperty
[[https_//schema.org/Text][sc_Text]] column jsonPath Reference BoundingBox
column
jsonPath
Reference
BoundingBox Properties
Properties
[[#fileobject][FileObject]],_[[#fileset][FileSet]] includes
includes
[[#fileset][FileSet]] excludes source
excludes
source
[[#recordset][RecordSet]],_[[#field][Field]] key
key
[[#recordset][RecordSet]] field subField transform
field
subField
[[#field][Field]] parentField dataType references data
parentField
dataType
references
data
JSON_Text_that_matches_the_fields_of_the_=RecordSet=.
transform
[[#datasource][DataSource]] format Open_issues/questions
format
Open_issues/questions
Loading_a_=distribution=_via_HTTP_with_Basic_Auth Programmatically_build_JSON-LD_files
Programmatically_build_JSON-LD_files
note/*__It's_worth_pointing_out_that_we_divide_the_loss_by Gradient_computation_&_optimization
Gradient_computation_&_optimization Hands-on_--_Let's_train_an_NMT_model
Hands-on_--_Let's_train_an_NMT_model
Inference_--_How_to_generate_translations Intermediate
Intermediate
matters_in_the_attention_mechanism?/* Attention_Wrapper_API
Attention_Wrapper_API
Hands-on_--_building_an_attention-based_NMT_model Tips_&_Tricks
Tips_&_Tricks
Three_models_in_a_single_graph_and_sharing_a_single_Session* Three_models_in_three_graphs,_with_three_Sessions_sharing_the
Three_models_in_three_graphs,_with_three_Sessions_sharing_the Data_Input_Pipeline
Data_Input_Pipeline
module._Data_iterators_are_flexible,_easy_to_reason_about_and Other_details_for_better_NMT_models
Other_details_for_better_NMT_models
Bahdanau-style_attention_often_requires_bidirectionality Multi-GPU_training
Multi-GPU_training Benchmarks Abstractions
Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s WMT_German-English
WMT_German-English
Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s WMT_English-German_---_Full_Comparison
WMT_English-German_---_Full_Comparison
Standard_HParams Other_resources
Other_resources
Reproduced_papers List_of_all_sorted_CM_scripts
List_of_all_sorted_CM_scripts
Third_level_files Examples
Differentiating_ML_artifacts Environment_variables
Environment_variables
rename CM_internal_automations
CM_internal_automations
default,_CM_will_pull_Git_repositories_and_cache_installations_and Ubuntu,_Debian
Ubuntu,_Debian
that_you_must_set_up_virtual_env_on_Ubuntu_23+_before_using_any Red_Hat
Red_Hat
CM_CLI_testing
Reusable_automation_actions
Show/clean_CM_cache_with_all_installations Windows
2022 Resources
2021-2023_[[https_//mlcommons.org][MLCommons]] [[../LICENSE.md][Apache_2.0]]
[[../LICENSE.md][Apache_2.0]] Collective_Mind_automation_language_(CM)
Collective_Mind_automation_language_(CM)
Power_Measurement_Setup Reproducing_the_Nvidia_Jetson_AGX_Orin_Submission
Reproducing_the_Nvidia_Jetson_AGX_Orin_Submission
Full_run Resnet50 Retinanet RNNT 3d-unet
Other_backends Run_benchmarks_and_submit_results
Run_benchmarks_and_submit_results
Measure_power Debug_benchmarks
Debug_benchmarks 
Add_new_data_set Participate_in_reproducibility_and_optimization_challenges
Participate_in_reproducibility_and_optimization_challenges
BERT-99.9%__MobileBERT_Offline_-_DeepSparse ResNet50
ResNet50
System_requirements_to_run_MLPerf_on_Nvidia_GPU MLCommons_CM_automation_meta-framework
MLCommons_CM_automation_meta-framework
Compile_MLPerf_loadgen CM_automation_for_the_MLPerf_benchmark
CM_automation_for_the_MLPerf_benchmark
Prepare_MLPerf_submission Trying_deepsparse_backend
Trying_deepsparse_backend
Run_Command Run_ResNet50_TFLite_via_CM
Run_ResNet50_TFLite_via_CM
What_is_the_difference_between_Repeatability,_Reproducibility_and Discussions
Discussions
Running_the_power_server_inside_a_docker_container Running_a_dummy_workload_with_power_(on_host_machine)
Running_a_dummy_workload_with_power_(on_host_machine)
Run_a_dummy_workload_with_power_inside_a_docker_container Running_MLPerf_Image_Classification_with_power
Running_MLPerf_Image_Classification_with_power
Running_MLPerf_Image_Classification_with_power_inside_a_docker Further_questions?
Further_questions?
in_the_same_repository_(specified_by_/./) Viewing_CM_meta_description
Viewing_CM_meta_description
Creating_other_types_of_artifacts Reusing_others'_artifacts_in_the_CM_format
Reusing_others'_artifacts_in_the_CM_format
From_zip_file Adding_reusable_automations_for_related_artifacts
Adding_reusable_automations_for_related_artifacts
and_a_/module.py*_with_the_automation_actions_implemented_as Extending_meta_descriptions_of_artifacts
Extending_meta_descriptions_of_artifacts
STMicroelectronics_NUCLEO-L4R5ZI Download_and_run_EEMBC_Energy_Runner
Download_and_run_EEMBC_Energy_Runner
With_one_CM_command_that_will_install_all_dependencies Use_Python_virtual_environment_with_CM_and_MLPerf The_next_steps
Use_Python_virtual_environment_with_CM_and_MLPerf The_next_steps
The_next_steps
Extra_system_requirements_for_Nvidia_GPU MLCommons_CM_automation_language
MLCommons_CM_automation_language
Install_ONNX_runtime_for_CPU Download_Bert-large_model_(FP32,_ONNX_format)
Download_Bert-large_model_(FP32,_ONNX_format)
fp32 Acknowledgments
Acknowledgments
Install_virtual_environment CM_automation_for_the_MLPerf_benchmark
MLPerf_inference_-_Python_-_ResNet50_FP32_-_ImageNet_-_TVM_-_CPU_-
Stage/*_##_Run_Commands_###_Quick_submission_run_(short_run) Customizations
Customizations
Run_experiments Second_approach__adding_CM_interface_to_your_research_project Notes Setup_for_RPi4_CPU
Second_approach__adding_CM_interface_to_your_research_project
Git_project Adding_CM_script_to_prepare_and_run_your_experiment
Adding_CM_script_to_prepare_and_run_your_experiment
MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_ONNX_-
MLPerf_inference_-_C++_-_RetinaNet_FP32_-_Open_Images_-_ONNX_-_GPU_-
MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-_PyTorch_-
CUDA Backend_(ML_framework)
Backend_(ML_framework)
TVM_ONNX_(Python) Datasets
Power_measurements Prepare_submission
Prepare_submission The_next_steps
2023 Resources
Artifacts_reusable_(pilot_project_with_MLCommons) Distinguished_artifact_award
Distinguished_artifact_award
can_skip_this_step_if_you_want_to_share_your_artifacts_without_the Making_artifacts_available_to_evaluators
Making_artifacts_available_to_evaluators
if*_they_have_been_placed_on_any_publicly_accessible_archival Submitting_artifacts
Submitting_artifacts
Models Installation
Please_check_the How_to_deal_with_numerical_accuracy_and_instability?
How_to_deal_with_numerical_accuracy_and_instability?
V1.0.0 Prototyping_phase
Prototyping_phase
Reproduce_results_from_ACM/IEEE/NeurIPS_papers Project_coordinators
Project_coordinators
doc Maintainers
Maintainers
any Maintainers
uid Maintainers
reindex Maintainers
[[../README.md][TOC]]_]* MLPerf™_Inference_v1.0__speech_recognition MLPerf™_Inference_v1.0__recommendation Customize_MLPerf™_inference_benchmark MLPerf™_Inference_v1.0__object_detection MLPerf™_Inference_v1.0__image_classification MLPerf™_Inference_v1.0__NLP MLPerf™_Inference_v1.0__medical_imaging Ideas_to_improve_CK Ideas_to_improve_automation Standardization Preparing_models Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Object_Detection_- Reproducibility_reports__MLPerf™_inference_benchmark_v1.1 MLPerf™_Inference_v0.7_-_Image_Classification_-_Nvidia_Jetson_Xavier Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Image Common_setup_for_the_MLPerf_inference_benchmark Common_workflow_for_MLPerf_inference Misc_MLPerf™_inference_notes Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit Nvidia-based_generic_platforms_with_Ubuntu Nvidia_Jetson_Nano_board Rapsberry_Pi_4_with_a_standard_port_of_Debian x8664-based_generic_platforms_with_Yocto Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit_with_Coral_Edge x8664-based_generic_platforms_with_Ubuntu Example_of_CK_dashboards_for_ML_Systems_DSE Analyse_MLPerf™_inference_results Automated_design_space_exploration_of_ML/SW/HW_stacks CK_workflows_for_speech_recognition_with_PyTorch CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_PyTorch CK_workflows_for_image_classification_with_TensorFlow CK_workflows_for_object_detection_with_TFLite CK_workflows_for_object_detection_with_ONNX CK_workflows_for_object_detection_with_TensorRT CK_workflows_for_the_MLPerf_inference_benchmark CK_workflows_for_language_(NLP)_with_ONNX CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_ONNX CK_workflows_for_image_classification_with_TVM CK_workflows_for_image_classification_with_OpenVino CK_workflows_for_image_classification_with_PyTorch CK_workflows_for_object_detection_with_TVM CK_workflows_for_image_classification_with_ONNX CK_workflows_for_image_classification_with_TFLite MLPerf™ Upgrade_the_CK_framework Logging_infrastructure MLCube™_project Continuous_integration_for_CK_workflows CK_components_for_ML_Systems_(automation_recipes)
MLPerf™_Inference_v1.0__speech_recognition
MLPerf™_Inference_v1.0__recommendation
Customize_MLPerf™_inference_benchmark
MLPerf™_Inference_v1.0__object_detection
MLPerf™_Inference_v1.0__image_classification
MLPerf™_Inference_v1.0__NLP
MLPerf™_Inference_v1.0__medical_imaging
Ideas_to_improve_CK
Ideas_to_improve_automation
Standardization
Preparing_models
MLPerf_inference_v1.1__Image_Classification__DSE_(Pareto Install_system_dependencies
Install_system_dependencies
Development_(live)_components_for_MLPerf Activate_virtual_environment
Activate_virtual_environment
Reproducibility_report__design_space_exploration
Visualize_MLPerf_results
by_[[https_//cKnowledge.org/gfursin][Grigori_Fursin]]_on MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.5.0_RUY_(x86) MLPerf™_Inference_v0.5_-_Image_Classification_-_OpenVino_2019_R3 MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1 MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_2.4.1_with_RUY MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1_(x86) System_packages
MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU
Install_Collective_Knowledge_(CK) Pull_[[https_//github.com/mlcommons/ck-mlops][CK_MLOps_repository]]
Pull_[[https_//github.com/mlcommons/ck-mlops][CK_MLOps_repository]]
Install_COCO_2017_val_dataset_(5000_images)_and Setup_for_EdgeTPU_(Host__RPi_4) Setup_for_RPi4_CPU
Setup_for_EdgeTPU_(Host__RPi_4)
MLPerf_inference_v1.1__Image_Classification__Resnet50__ONNX_(out Install_system_dependencies
Reproducibility_report__benchmarking
Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Object_Detection_-
Run_a_container_and_record_experiments_locally
MLPerf_inference_v1.1__Image_Classification__Resnet50_ Install_system_dependencies
Install_TFLite_model_(MobileNet_v2__Large__Minimalistic__224__1.0_
MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite
Setup_for_RPi4_CPU
Run_experiments_(via_cmdgen)
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM__AWS Install_system_dependencies
Reproducibility_reports__MLPerf™_inference_benchmark_v1.1
by_the Reproducing_MLPerf™_inference_benchmarks_(v0.7_and_v1.0)
Reproducing_MLPerf™_inference_benchmarks_(v0.7_and_v1.0)
Using_CK_adaptive_containers_(to_be_tested!) Other_reproducibility_studies
Other_reproducibility_studies
MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.5.0_RUY_(x86)
Preprocess_using_OpenCV_(better_accuracy_but_may_fail_on_some Optional__install_reduced_ImageNet_2012_val_dataset_with_the_first
Optional__install_reduced_ImageNet_2012_val_dataset_with_the_first
Performance__Single_Stream_(500_samples) note_from_the_community_*_A_valid_SingleStream_performance_run
note_from_the_community_*_A_valid_SingleStream_performance_run
Performance__Offline_(500_samples) note_from_the_community_*_A_valid_Offline_performance_run
note_from_the_community_*_A_valid_Offline_performance_run
MLPerf™_Inference_v0.5_-_Image_Classification_-_OpenVino_2019_R3
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM__GCP Install_system_dependencies
MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1
Preprocess_using_pillow_(slightly_worse_accuracy_but_works_most_of Install_reduced_ImageNet_2012_val_dataset_with_the_first_500_images Install_framework_TFLite_2.4.1_with_RUY
Install_reduced_ImageNet_2012_val_dataset_with_the_first_500_images
Install_framework_TFLite_2.4.1_with_RUY
ResNet-50_(no-argmax) Run_MLPerf™_benchmark
Run_MLPerf™_benchmark
MLPerf™_Inference_v1.0_-_Object_Detection_-_TFLite_2.4.1_with_RUY
System_packages Install_Collective_Knowledge_(CK)_and_Virtual_Environment
Install_Collective_Knowledge_(CK)_and_Virtual_Environment
MLPerf™_Inference_v0.7_-_Image_Classification_-_Nvidia_Jetson_Xavier
MLPerf™_Inference_v1.0_-_Image_Classification_-_TFLite_2.4.1_(x86)
Adaptive_CK_container_for_MLPerf™_Inference_v1.0_-_Image
Linux Run_a_container_and_record_experiments_locally Load_and_run_a_model_in_C++
Run_a_container_with_external_ImageNet 
MLPerf_inference_v1.1__Image_Classification__Resnet50__TVM_ Install_system_dependencies
20210723 PyTorch_1.5.0_*_TorchVision_0.6.0_(works_with_PyTorch_1.5.0)_*_ONNX
PyTorch_1.5.0_*_TorchVision_0.6.0_(works_with_PyTorch_1.5.0)_*_ONNX
Install_any_available_version Install_CK_packages_with_ONNX_(GPU) Notes Install_CK_packages_with_TensorFlow_(GPU) Tested_configurations
Install_CK_packages_with_ONNX_(GPU)
Common_setup_for_the_MLPerf_inference_benchmark
Install_CK_packages_with_TensorFlow_(GPU)
Tested_configurations
Common_workflow_for_MLPerf_inference
Export_all_MLPerf_inference_results Coordinator
Coordinator
Misc_MLPerf™_inference_notes
that_this_CK-MLPerf_documentation_is_discontinued_after_the MLPerf™_inference_benchmark_automation
MLPerf™_inference_benchmark_automation
Customizable_dashboards Table_of_contents
Table_of_contents
Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit
Nvidia-based_generic_platforms_with_Ubuntu
TensorRT Test_CK_automation_(platform_detection) Building_for_JetPack_4.x
Test_CK_automation_(platform_detection)
Nvidia_Jetson_Nano_board
Rapsberry_Pi_4_with_a_standard_port_of_Debian
x8664-based_generic_platforms_with_Yocto
Rapsberry_Pi_4_with_Ubuntu_Server_20.04.2_LTS_64-bit_with_Coral_Edge
x8664-based_generic_platforms_with_Ubuntu
Example_of_CK_dashboards_for_ML_Systems_DSE
View_CK_dashboard_in_your_browser Demo_of_a_Docker_with_MLPerf™_dashboards_for_ML_Systems_DSE_(Linux
Demo_of_a_Docker_with_MLPerf™_dashboards_for_ML_Systems_DSE_(Linux
Analyse_MLPerf™_inference_results
Download_and_install_MLPerf™_inference_results_via_CK Available_results
Available_results
v1.0 
[[../README.md][Back_to_TOC]]_]* Shortcuts
Shortcuts
TF_SSD_Mobilenet-v1_non-quantized Convert_COCO_to_1200x1200
Convert_COCO_to_1200x1200
Preprocess_using_Pillow_(slightly_worse_accuracy_but_works_most_of Plug_in_full_ImageNet_2012_val_dataset_with_50000_images
Plug_in_full_ImageNet_2012_val_dataset_with_50000_images
Automated_design_space_exploration_of_ML/SW/HW_stacks
CK_based_object_detection_DSE
CK_workflows_for_speech_recognition_with_PyTorch
CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_PyTorch
MLPerf_tasks TBD
TBD Notes
Use_ONNX Scenario__Accuracy__Single_Stream Scenario__Performance__Single_Stream
Scenario__Accuracy__Single_Stream
model,image-classification,mlperf,onnx,resnet50,v1.5-opset-11 Scenario__Performance__Single_Stream
Scenario__Performance__Single_Stream
CK_workflows_for_image_classification_with_TensorFlow
CK_workflows_for_object_detection_with_TFLite
CK_workflows_for_object_detection_with_ONNX
CK_workflows_for_object_detection_with_TensorRT
CK_workflows_for_the_MLPerf_inference_benchmark
CK_workflows_for_language_(NLP)_with_ONNX
Install_SSD-ResNet34_1200x1200_non-quantized_fp32_for_ONNX_opset-8 Benchmark
Benchmark Analyze_experimental_results
Record_benchmarking_results_to_the_CK_repository Analyze_experimental_results
Analyze_experimental_results
Start_Docker_while_mounting_CK_repository_with_experiments_ Integration_with_web_services_and_CI_platforms
Integration_with_web_services_and_CI_platforms Questions_and_feedback
Questions_and_feedback
Record_results_to_the_CK_repository PyTorch-based_models_for_CPU
PyTorch-based_models_for_CPU
CK_workflows_for_medical_imaging_(3d-unet_and_BraTS)_with_ONNX
CK_workflows_for_image_classification_with_TVM
CK_workflows_for_image_classification_with_OpenVino
CK_workflows_for_image_classification_with_PyTorch
CK_workflows_for_object_detection_with_TVM
CK_workflows_for_image_classification_with_ONNX
CK_workflows_for_image_classification_with_TFLite
MLPerf™
Upgrade_the_CK_framework
Logging_infrastructure
MLCube™_project
Run_benchmark CK_automation
CK_automation
Continuous_integration_for_CK_workflows
[[../reproduce/README.md#][Back_to_MLPerf_v1.1_reproducibility MLPerf_inference_v1.1_reproducibility_report_for_the_OctoML
MLPerf_inference_v1.1_reproducibility_report_for_the_OctoML
Install_PyTorch_model_(Resnet50__int8__quantized)
and_simplifying_MLPerf Authors
Authors
Use_reduced_ImageNet_to_test_the_MLPerf_workflow Install_PyTorch_model_(Resnet50__int8__quantized)
Install_CK_workflow_Python_dependencies
CK_components_for_ML_Systems_(automation_recipes)
Automated_workflows Coordinator
Update_program_sources Update_software_dependencies
Update_software_dependencies
Add_new_CK_packages /PACKAGE_DIR/_-_the_path_to_the_CK_package_entry._This_is_useful_if
/PACKAGE_DIR/_-_the_path_to_the_CK_package_entry._This_is_useful_if
Using_CK_modules Generate_reproducible_and_interactive_articles
Generate_reproducible_and_interactive_articles
Add_CK_entries_from_a_zip_file_to_an_existing_CK_repository CLI_to_manage_CK_entries
CLI_to_manage_CK_entries
Copy_a_given_CK_entry CLI_to_manage_CK_actions
CLI_to_manage_CK_actions
Android_(Linux_host) CK_installation
CK_installation
that_on_Windows_you_also_need_to_install_/ctuning@ck-win* Docker
Docker Further_info
actions/*_are_implemented_using modules/*_are_always_stored_in_*/module_/_<_CK_module_name_>/*
modules/*_are_always_stored_in_*/module_/_<_CK_module_name_>/*
platform/*_to_help_the_community_share_CK_components,_create_live How_CK_supports_collaborative_and_reproducible_ML&systems_research
How_CK_supports_collaborative_and_reproducible_ML&systems_research
Further_info
Push_data_to_a_dashboard Notes
that_the_1st_generation_of_the_CK_framework_was_discontinued_in Collective_Knowledge_framework_(CK)
Collective_Knowledge_framework_(CK)
Tutorials Releases
Releases
Stable_versions Current_projects
Current_projects
Other_use_cases CK_portal
CK_portal
Organizers Initial_discussion_and_materials
Initial_discussion_and_materials
Generate_and_upload_MLPerf_submission Questions?_Suggestions?
Questions?_Suggestions?
Generate_MLPerf_submission Use_=--submitter=<Your_name>=_if_your_organization_is_an_official
Use_=--submitter=<Your_name>=_if_your_organization_is_an_official
Challenge 
Test_CUDA_installation Install_Python_virtual_environment
Install_Python_virtual_environment
Push_the_results_to_GitHub_repo Try_PyTorch_backend Using_ARMNN_with_NEON Tensorflow_backend
Try_PyTorch_backend Test_composable_ML_benchmark_with_other_models,_data_sets,_frameworks
Test_composable_ML_benchmark_with_other_models,_data_sets,_frameworks The_next_steps
Generate_actual_submission_tree Pytorch_backend Tensorflow_backend Tensorflow_backend_(Reference_implementation)
Pytorch_backend
Tensorflow_backend
Tensorflow_backend_(Reference_implementation)
test Maintainers
Platform_information List_of_all_sorted_CM_scripts
show Maintainers
list_files_recursively Maintainers
add Maintainers
replay Maintainers
CM_script_execution_flow If_a_script_is_already_cached,_then_the_=preprocess=,_=run_file=_and
If_a_script_is_already_cached,_then_the_=preprocess=,_=run_file=_and
Dynamic_variations ENV_flow_during_CM_script_execution
ENV_flow_during_CM_script_execution
Special_env_keys Script_Meta
Script_Meta
Special_keys_in_script_meta How_cache_works?
How_cache_works?
prepare Maintainers
Caching_output_of_CM_scripts Assembling_pipeline_to_compile_and_run_image_corner_detection
Assembling_pipeline_to_compile_and_run_image_corner_detection
Customizing_sub-dependencies_in_a_pipeline Using_Python_virtual_environments
Using_Python_virtual_environments
CM_script_automation_help CM_CLI
CM_CLI
CM_modular_Docker_container Customization
Customization
CLI_flags_can_be_used_in_the_Python_CM_API_as_follows_* Default_environment Script_flags_mapped_to_environment
Default_environment Script_workflow,_dependencies_and_native_scripts
Script_workflow,_dependencies_and_native_scripts
How_to_use =[DOCKER_OS_VERSION]=_is_one_of_=18.04=,_=20.04=,_=22.04=_for_=ubuntu= =[--docker_os,_--docker_os_version,_--cm_repo_and_--script_tags]=_are
=[DOCKER_OS_VERSION]=_is_one_of_=18.04=,_=20.04=,_=22.04=_for_=ubuntu=
Versions Script_workflow,_dependencies_and_native_scripts Script_output
New_environment_keys_(filter) Maintainers
Script_flags_mapped_to_environment
New_environment_keys_auto-detected_from_customize Maintainers
Default_variations Script_workflow,_dependencies_and_native_scripts
Script_output
Valid_variation_combinations_checked_by_the_community Script_workflow,_dependencies_and_native_scripts
Managing_the_configuration_files
When_custom_config_files_are_generated_they_override_the Information
Information
Setup_for_Google_Cloud_Instances
System_dependencies
Supported_and_Tested_OS Examples CLI
Detect_CUDA_on_Windows System_dependencies
ONNX,_CPU Run_command
Other_Input_Options_ Use_modular_Docker_container_with_the_CM_API
Use_modular_Docker_container_with_the_CM_API
Open_discussions_and_developments
Contact_us
=[--docker_os,_--docker_os_version,_--cm_repo_and_--script_tags]=_are
Choices_(flags) Example__MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-
Example__MLPerf_inference_-_Python_-_RetinaNet_FP32_-_Open_Images_-
CLI
Detect_llvm_with_non-standard_name Force_new_detection_even_if_llvm_is_already_found_and_cached
Force_new_detection_even_if_llvm_is_already_found_and_cached
Preprocess_the_dataset_with_=Channel=_component_at_beginning Input_Variables_coming_from_Dependencies
Input_Variables_coming_from_Dependencies
Set_up
Docker_Setup Run_Commands
Run_Commands
Using_ARMNN_with_NEON
Further_analysis_of_results Contact_us
Download_the_needed_files
New_state CLI
Detect_python_with_non-standard_name Force_new_detection_even_if_python_is_already_found_and_cached
Force_new_detection_even_if_python_is_already_found_and_cached
Using_Docker Future_work
Future_work
Private_challenges Copyright
Copyright
CK_components_can_be_found_at Author Status Minimal_CK_installation
Author
Option_2_-_Execute_the_whole_ML_pipeline_from_a_Python_script_ _dart__Dashboard
_dart__Dashboard
🗺_Overview 🖥_Run_the_example
🖥_Run_the_example
▶️_Run_the_Code CLI_Commands_for_the_Label_Studio_Integration
CLI_Commands_for_the_Label_Studio_Integration
🧽_Clean_up 📜_Learn_more
📜_Learn_more
SOON_*_We_also_recommend_you_check_out_our 🧰_How_the_example_is_implemented
🧰_How_the_example_is_implemented 🖥_Run_it_locally
🖥_Run_it_locally
ZenML_Test_Environments The_ZenML_Test_CLI
The_ZenML_Test_CLI
2.3_Copyright_license_back_to_You 3._Patents
3._Patents
3.2_Revocation_of_patent_license 4._License_obligations_by_Us
4._License_obligations_by_Us
8.3_In_the_event_of_a_termination_of_this_Agreement_Sections_5., 9._Miscellaneous
9._Miscellaneous
Building_the_API_Docs_locally Contributors
Contributors
the_server* up_a_local_ZenML_Server*
up_a_local_ZenML_Server*
to_a_pre-existing_server* your_deployed_server_details*
your_deployed_server_details* The_ZenML_Dashboard_is_now_available
The_ZenML_Dashboard_is_now_available
👣_How_to_migrate_your_Profiles Decoupling_Stack_Component_configuration_from_implementation
Decoupling_Stack_Component_configuration_from_implementation
to_migrate*__Rename_all_references_to_=Repository=_in_your_code_to The_=BaseStepConfig=_class_is_now_called_=BaseParameters=
The_=BaseStepConfig=_class_is_now_called_=BaseParameters=
to_migrate*__Rename_all_references_to_=BaseStepConfig=_in_your_code Configuration_Rework
Configuration_Rework
the_=enable_xxx=_decorators* to_migrate*__Simply_remove_the_decorator_and_pass_something_like
to_migrate*__Simply_remove_the_decorator_and_pass_something_like
=pipeline.with_config(...)=* to_migrate*__Replaced_with_the_new_=pipeline.run(config_path=...)=.
to_migrate*__Replaced_with_the_new_=pipeline.run(config_path=...)=.
=step.with_return_materializer(...)=* to_migrate*__Simply_remove_the_=with_return_materializer=_method
to_migrate*__Simply_remove_the_=with_return_materializer=_method
is_now_renamed_to_=DockerSettings=* to_migrate*__Rename_=DockerConfiguration=_to_=DockerSettings=_and
to_migrate*__Rename_=DockerConfiguration=_to_=DockerSettings=_and
is_now_renamed_to_=ResourceSettings=* to_migrate*__Rename_=ResourceConfiguration=_to_=ResourceSettings=
to_migrate*__Rename_=ResourceConfiguration=_to_=ResourceSettings=
the_=requirements=_and_=required_integrations=_parameters* to_migrate*__Simply_remove_the_parameters_and_use_the
to_migrate*__Simply_remove_the_parameters_and_use_the new_pipeline_intermediate_representation*
new_pipeline_intermediate_representation*
to_migrate*__If_you_have_written_a =PipelineSpec=_now_uniquely_defines_pipelines
=PipelineSpec=_now_uniquely_defines_pipelines
to_migrate*__No_code_changes,_but_rather_keep_in_mind_the_behavior New_post-execution_workflow
New_post-execution_workflow
to_migrate*__Replace_all_post-execution_workflows_from_the_paradigm 📡Future_Changes
📡Future_Changes
GCR_container_registry Authentication_Methods
Authentication_Methods Caveats How_do_you_use_it?
GCP_OAuth_2.0_token Auto-configuration
Auto-configuration
Local_and_remote_availability Register_Service_Connectors
Register_Service_Connectors
Service_Connector_Verification Configure_local_clients
Configure_local_clients
ACR_container_registry Authentication_Methods
Azure_Access_Token Auto-configuration
ECR_container_registry Authentication_Methods
AWS_Federation_Token Auto-configuration
Base_Abstraction_3__=Flavor= Implementing_a_Custom_Stack_Component_Flavor
Implementing_a_Custom_Stack_Component_Flavor
Interactive_stack_deployment Displaying_Terraform_outputs_for_stacks_deployed_with_mlstacks
Displaying_Terraform_outputs_for_stacks_deployed_with_mlstacks
Container_Registry 7)_Create_Stack
7)_Create_Stack And_you're_already_done!
And_you're_already_done!
Trackers* Stores*
Stores*
Registries* Other_configuration
Other_configuration
Model_Registry_Flavors How_to_use_it
How_to_use_it
List_of_available_parameters Register_models_via_the_CLI
Register_models_via_the_CLI
allow_you_to_send_messages_to_chat_services_(like_Slack, Alerter_Flavors
Alerter_Flavors
DISCORD_TOKEN How_to_Use_the_Discord_Alerter
How_to_Use_the_Discord_Alerter
Configuring_a_Custom_Seldon_Core_Secret* How_do_you_use_it?
How_do_you_use_it?
Caveats
with_various_tools_for_each_category._Once_code_is Available_integrations
Available_integrations
In_a_ZenML_Step Secret_Schemas
Secret_Schemas
Configuration_use-case__GCP_Service_Connector_with_different Configuring_the_stack
Configuring_the_stack
to_delete_a_scheduled_pipeline* Additional_configuration
Additional_configuration
Infrastructure_Deployment How_to_use_it How_to_find_the_registry_URI
job_->_S3* Enabling_CUDA_for_GPU-backed_hardware
Enabling_CUDA_for_GPU-backed_hardware Important_Note_for_Multi-Tenancy_Deployments
Important_Note_for_Multi-Tenancy_Deployments
Build_your_own_custom_orchestrator Implementation_guide
Implementation_guide
How_to_find_the_registry_URI
repository_instead,_you'll_have_to How_to_find_the_registry_URI
container_registry_or_when_using_a_remote_container_registry Local_registry_URI_format
Local_registry_URI_format
Advanced_Configuration How_do_you_use_it?
Artifact_Store_Flavors How_to_use_it
effect_on_the_=zenml.io.fileio=* Build_your_own_custom_artifact_store
Build_your_own_custom_artifact_store
Warning Stack_Component__=KubernetesSparkStepOperator=
Stack_Component__=KubernetesSparkStepOperator=
Configuring_RBAC How_to_use_it
Call_Evidently_directly Visualizing_Evidently_Reports
Visualizing_Evidently_Reports
Data_Validator_Flavors How_to_use_it
Call_whylogs_directly Visualizing_whylogs_Profiles
Visualizing_whylogs_Profiles
Experiment_Tracker_Flavors How_to_use_it
over_*pipeline-level*_defined_hooks._{%_endhint_%} Accessing_step_information_inside_a_hook
Accessing_step_information_inside_a_hook
Supported_orchestrators Stopping/pausing_a_scheduled_run
Stopping/pausing_a_scheduled_run
Step_output_names Configure_steps/pipelines
Configure_steps/pipelines
and_caching* and_caching* Pass_any_kind_of_data_to_your_steps
Pass_any_kind_of_data_to_your_steps
artifacts*_can_be_used_to_pass_values_to_steps_that_are Using_a_custom_step_invocation_ID
Using_a_custom_step_invocation_ID
Enable_or_disable_logs_storing Settings_in_ZenML
Settings_in_ZenML
objects_or_dicts* Utilizing_the_settings
Utilizing_the_settings
Storing_and_retrieving_the_artifact (Optional)_How_to_Visualize_the_Artifact
(Optional)_How_to_Visualize_the_Artifact
(Optional)_Which_Metadata_to_Extract_for_the_Artifact Usage
Configuring_materializers_at_runtime Basic_example
Basic_example
Interaction_with_custom_artifact_stores
Example_ Visualization_via_Materializers
Visualization_via_Materializers
Example__Facets_Data_Skew_Visualization Custom_Class*_The
Custom_Class*_The
Step*_There_are_three_different_steps_in_the_=facets=_integration Disabling_Visualizations
Disabling_Visualizations
Additional_logs* Client_and_server_logs
Client_and_server_logs
Updated*__October_17,_2023 Suggestions_for_Resolving_Dependency_Conflicts
Suggestions_for_Resolving_Dependency_Conflicts
Stacks,_Infrastructure,_Authentication Client_Methods
Client_Methods
Methods* Methods*
Update,_and_Delete_Methods* Active_User_and_Active_Stack
Active_User_and_Active_Stack Resource_Models
Resource_Models
Speeding_up_Docker_builds_for_containerized_components Registering_a_code_repository
Registering_a_code_repository
Tracking_code_version_for_pipeline_runs Available_implementations
Available_implementations
GitLab Developing_a_custom_code_repository
Developing_a_custom_code_repository
for_the_GPU_hardware_to_be_properly_utilized._If_you_don't 1._*Specify_a_CUDA-enabled_parent_image_in_your_=DockerSettings=*
1._*Specify_a_CUDA-enabled_parent_image_in_your_=DockerSettings=*
If_I_share_my_email,_will_you_spam_me? Version_mismatch_(downgrading)
Version_mismatch_(downgrading)
Automate_build_reuse_by_connecting_a_code_repository Customize_the_Docker_building
Customize_the_Docker_building
files_get_included* Installing_additional_pip_dependencies_or_apt_packages
Installing_additional_pip_dependencies_or_apt_packages
What_is_already_built_in? How_do_I_use_it?
How_do_I_use_it?
that_allows_you_to_fetch_or_reference_them_in_your_pipelines_and Centralized_secrets_store
Centralized_secrets_store
register_missing_secrets_for_your_stack* Set_scope_for_secrets
Set_scope_for_secrets
Recap
Deploying_a_ZenML_Server Using_the_ZenML_CLI_to_connect_to_a_deployed_ZenML_Server
Using_the_ZenML_CLI_to_connect_to_a_deployed_ZenML_Server
This_simply_means_that_any_pipeline_you_run_will_be_using_the stack*_as_its_environment._{%_endhint_%}_{%_endtab_%}_{%_endtabs
stack*_as_its_environment._{%_endhint_%}_{%_endtab_%}_{%_endtabs Components_of_a_stack
Components_of_a_stack
store*. Orchestrator
Orchestrator
store*_and_then_loaded_from_there_when_the_next_step_needs Registering_a_stack
Registering_a_stack
List_Pipelines_via_CLI Runs
Runs
Component-Specific_Metadata Steps
Steps
Step_Information Artifacts
Artifacts
Artifact_Visualizations Code_Example
Code_Example
set_caching_to_=False=_on_steps_that_depend_on_*external Configuring_caching_behavior_of_your_pipelines
Configuring_caching_behavior_of_your_pipelines
is_a_Python_package_that_can_be_installed_directly_via_=pip=_ Install_with_the_dashboard
Install_with_the_dashboard
is_an_extensible,_open-source_MLOps_framework_for_creating 1._Development
1._Development
Parameters_&_Settings 2._Execution
2._Execution
tailored_to_specific_use_cases/tools._With_ZenML_installed, Stack_Switching
Stack_Switching 3._Management
3._Management
it_should_use,_the_*default_user_details,*_and_more._The Secret_store_environment_variables
Secret_store_environment_variables
Advanced_server_configuration_options Run_the_ZenML_server_with_Docker
Run_the_ZenML_server_with_Docker
ZenML_server_with_=docker-compose= Troubleshooting
Troubleshooting Apply_Perf_Optmization_(AGX_and_NX_applicable) Setup_the_Jetson_Orin_NX_System Apply_Perf_Optmization_for_AGX/NX Apply_Perf_Optmization
Optional_cluster_services ZenML_Helm_Installation
ZenML_Helm_Installation
Connect_to_the_deployed_ZenML_server ZenML_Helm_Deployment_Scenarios
ZenML_Helm_Deployment_Scenarios
Use_a_DNS_service_to_map_a_different_hostname_to_the_Ingress Secret_Backends
Secret_Backends
Having_an_existing_NGINX_Ingress_Controller Existing_hosted_SQL_database
Existing_hosted_SQL_database Configuration_file_templates
Configuration_file_templates
Cloud-specific_settings Connecting_to_deployed_ZenML
Connecting_to_deployed_ZenML
🚨_Reporting_a_Vulnerability Coding_Conventions
Coding_Conventions
A_private,_written_warning_from_community_leaders, 2._Warning
2._Warning
A_warning_with_consequences_for_continued_behavior._No 3._Temporary_Ban
3._Temporary_Ban
A_temporary_ban_from_any_sort_of_interaction_or_public 4._Permanent_Ban
4._Permanent_Ban
A_permanent_ban_from_any_sort_of_public_interaction Attribution
Attribution
document._-_[_]_If_my_change_requires_a_change_to Types_of_changes
Changelog*_ 0.45.4 0.45.3 0.45.2 0.44.3 0.44.1 0.43.0 0.42.1 0.42.0 0.41.0 0.40.3 0.40.2 0.40.1 0.40.0 0.39.1 0.39.0 0.38.0 0.37.0 0.36.1 0.36.0 0.35.1 0.35.0_(YANKED) 0.34.0 0.33.0 0.32.1 0.32.0 0.31.1 0.31.0 0.30.0 0.23.0 0.22.0 0.21.1 0.21.0 0.20.5 0.20.4 0.20.3 0.20.2 0.20.0_/_0.20.1 0.13.2 0.13.1 0.13.0 0.12.0 0.11.0 0.10.0 0.9.0 0.8.1 0.8.0 0.7.2 0.7.1 0.6.3 New_Features 0.5.5 0.5.4 0.5.3 0.5.2 0.5.1
0.45.4
If_you_upgraded_to_ZenML_v0.45.2_or_v0.45.3_and_are What's_Changed
What's_Changed 0.44.0 0.7.0 0.6.1
0.45.3
If_you_upgraded_to_ZenML_v0.45.2_and_are_experiencing What's_Changed
0.45.2
This_change_disrupts_existing_pipeline_schedules._After Performance_enhancements_(#3207)
Performance_enhancements_(#3207)
0.44.3
Changelog*__https_//github.com/zenml-io/zenml/compare/0.44.2...tes 0.44.2
0.44.2
0.44.1
/0.44.0_was_removed_from_pypi_due_to_an_issue_with_the_alembic What's_Changed
0.44.0
0.43.0
0.42.1
Disable_Implicit_Auth_Methods_for_Service_Connectors_by_Default What's_Changed
0.42.0
Dependency_and_Integration_Version_Updates What's_Changed
0.41.0
0.40.3
0.40.2
0.40.1
0.40.0
0.39.1
0.39.0
0.38.0
0.37.0
it_is_not_recommended_to_continue_using_MLflow_older_than Breaking_Changes
Breaking_Changes Changes_in_D3_5.0
0.36.1
0.36.0
0.35.1
/This_release_replaces_the_previous_0.35.0_release_that_was Breaking_Changes
0.35.0_(YANKED)
0.34.0
0.33.0
0.32.1
0.32.0
0.31.1
0.31.0
0.30.0
0.23.0
0.22.0
0.21.1
0.21.0
0.20.5
0.20.4
0.20.3
0.20.2
0.20.0_/_0.20.1
0.13.2
0.13.1
0.13.0
0.12.0
0.11.0
0.10.0
0.9.0
0.8.1
0.8.0
🙌_Community_Contributions 0.7.3
0.7.3
0.7.2
0.7.1
0.7.0
0.6.3
New_Contributors 0.6.2
0.6.2
0.6.1
What's_changed 0.6.0
0.6.0
➕_Other_updates,_additions_and_fixes 0.5.7
0.5.7
New_Features
0.5.5
0.5.4
0.5.3
0.5.2
0.5.1
Overview 0.5.0
0.5.0
What_to_expect_in_the_next_weeks_and_the_new_ZenML 0.5.0rc2 0.3.7.1
0.5.0rc2
0.3.7.1
Bug_Fixes_+_Refactor 0.3.7 0.3.6 0.3.5 0.3.4
0.3.7
0.3.6
0.3.5
0.3.4
👭_4._Start_the_Dashboard 🗺_Roadmap
🗺_Roadmap
Install_dependencies CLI Installation
Import_in_all_the_right_places Step_4__Create_a_PR_and_celebrate__tada_
Step_4__Create_a_PR_and_celebrate__tada_
Install_the_Chart Configuration
Advanced_Options Telemetry
Telemetry
Authentication_for_Google_Cloud_Container_Registry Installation
Trigger_build_and_push_of_images_on_other_branch GCP_Data_and_Experiment_Integration
GCP_Data_and_Experiment_Integration
Saving_Experiments_to_GCP Getting_Information_from_a_Container
Getting_Information_from_a_Container
Mounting_Local_Repository Submitting_PRs
Submitting_PRs
Other_Info ToDo
ToDo
for_NVIDIA_GPU_set_up*__You_may_have_to_install_the Building_Docker_Image
Building_Docker_Image
Using_Singularity/Apptainer_instead_of_Docker Getting_Started
Getting_Started
Rules
Shared_data_pipelines_between_JAX_and_PyTorch FAQS
FAQS
How_do_I_run_this_on_my_SLURM_cluster? Submissions
Submissions
Can_submission_be_structured_using_multiple_files? Citing_AlgoPerf_Benchmark
Citing_AlgoPerf_Benchmark
Start_tmux_session_(Recommended) Datasets
WMT FastMRI
FastMRI
Librispeech
Coding_your_submission Run_your_submission
Run_your_submission
to_score_your_submission_on_a_workload,_from_the Pytorch_DDP
Pytorch_DDP Run_your_submission_in_a_Docker_container
Run_your_submission_in_a_Docker_container
Docker_Tips Score_your_submission
Score_your_submission
0.0.16_/(Last_updated_28_April_2023)/ Introduction
Introduction
Submission_functions
Data_selection Evaluation_during_training
Evaluation_during_training
Software_dependencies Tuning
Tuning
To_estimate_the_variance_of_the_results,_this_tuning_will_be Self-tuning_ruleset
Self-tuning_ruleset Workloads
Workloads
Qualification_set Scoring
Scoring
Alternative_scores Benchmark_Procedure
Benchmark_Procedure
Requesting_Additional_Baselines Licensing
Licensing
Awards_and_prize_money Model_Track
Model_Track
Part_1._Concurrent_inference_and_dynamic_batching
Expected_output Demonstration_case_2__Dynamic_batching
Demonstration_case_2__Dynamic_batching
GRPC_Options
In-Process_Triton_Server_API
Inference_APIs Java_bindings_for_In-Process_Triton_Server_API
Java_bindings_for_In-Process_Triton_Server_API
CPU-only_container_composition Build_it_yourself
Build_it_yourself
CPU-Only_Build Building_Without_Docker
Building_Without_Docker
Building_for_JetPack_4.x
Extract_Build_Artifacts Building_on_Unsupported_Platforms
Building_on_Unsupported_Platforms
Development_Build_of_Backend_or_Repository_Agent Building_with_Debug_Symbols
Building_with_Debug_Symbols
The_repository_agent_API_is_beta_quality_and_is_subject_to Using_a_Repository_Agent
Using_a_Repository_Agent
to_Triton_Inference_Server?*_Make_use_of *Installation* Serve_a_Model_in_3_Easy_Steps
*Installation*
Inference_Request/Response_Cache Model_Pipeline
Model_Pipeline *Resources*
*Resources*
Example_Request Generate_Response_JSON_Object
Generate_Response_JSON_Object
Example_Response Generate_Response_JSON_Error_Object
Generate_Response_JSON_Error_Object
Example_Usage GRPC
GRPC
Statistics_Response_JSON_Error_Object GRPC
Unregister CUDA_Shared_Memory GRPC
CUDA_Shared_Memory
Trace_Setting_Request_JSON_Object GRPC
Raw_Binary_Request
Unload GRPC
Pending_Request_Count_(Queue_Size)_Per-Model Latencies
Latencies
Summaries GPU_Metrics
GPU_Metrics
Triton-reported_Response_Cache_Metrics Custom_Metrics
Custom_Metrics
this_your_first_time_setting_up_a_model_repository?*_Check_out Repository_Layout
Repository_Layout
sure,_that_=TRITON_GCS_MOUNT_DIRECTORY=_exists_on_your_local S3
S3
sure,_that_=TRITON_AWS_MOUNT_DIRECTORY=_exists_on_your_local Azure_Storage
Azure_Storage
sure,_that_=TRITON_AZURE_MOUNT_DIRECTORY=_exists_on_your_local Cloud_Storage_with_Credential_file_(Beta)
Cloud_Storage_with_Credential_file_(Beta)
Caching_of_Cloud_Storage Model_Versions
Model_Versions
Python_model_using_Python_Backend Deploying_Decoupled_Models
Deploying_Decoupled_Models
this_your_first_time_writing_a_config_file?*_Check_out Minimal_Model_Configuration
Minimal_Model_Configuration
Decoupled Maximum_Batch_Size
Maximum_Batch_Size
of_Tensors_as_Input_/* Auto-Generated_Model_Configuration
Auto-Generated_Model_Configuration
Default_Max_Batch_Size_and_Dynamic_Batcher Datatypes
Datatypes
Priority Ensemble_Model_Instance_Groups
Ensemble_Model_Instance_Groups CUDA_Compute_Capability
CUDA_Compute_Capability
Custom_Batching Sequence_Batcher
Sequence_Batcher
Ensemble_Scheduler Optimization_Policy
Optimization_Policy
When_building_Triton_on_Jetson,_you_will_require_a_recent Runtime_Dependencies_for_Triton
Runtime_Dependencies_for_Triton
Model_Instances Framework-Specific_Optimization
Framework-Specific_Optimization
TensorFlow_Automatic_FP16_Optimization NUMA_Optimization
NUMA_Optimization
Other_Areas_of_Interest End-to-end_Example
End-to-end_Example
gRPC_Endpoint Handling_in_Triton_Core
Handling_in_Triton_Core
Currently,_Triton_core_does_not_detect_cancellation_status_of_a Handling_in_Backend
Handling_in_Backend
Initializing_State_from_File Scheduling_Strategies
Scheduling_Strategies
Oldest Ensemble_Models
Ensemble_Models
the_following_flags_are_*deprecated*_ Supported_Trace_Level_Option
Supported_Trace_Level_Option
3._Build_with_Debug_Flags* Specific_Issues
Specific_Issues
Symbols* Server_Issues
Server_Issues
Deadlock Client_Issues
Client_Issues
Performance_Profiling Submitting_an_Issue
Submitting_an_Issue
Custom_Cache Deprecation_Notes
Deprecation_Notes
There_is_no_synchronization_between_when_Triton_polls_the Modifying_the_Model_Repository
Modifying_the_Model_Repository
to_Triton_Inference_Server_and_want_do_just_deploy_your_model Create_A_Model_Repository
Create_A_Model_Repository
Verify_Triton_Is_Running_Correctly Send_an_Inference_Request
Send_an_Inference_Request
A_clear_and_concise_description_of_what_the_bug_is. Information*_What_version_of_Triton_are_you_using?
Information*_What_version_of_Triton_are_you_using? Reproduce*_Steps_to_reproduce_the_behavior.
Reproduce*_Steps_to_reproduce_the_behavior.
RELEASE__You_are_currently_on_the_main_branch_which_tracks to_Triton_Inference_Server?*_Make_use_of
Serve_a_Model_in_3_Easy_Steps
Client_Support_and_Examples Extend_Triton
Extend_Triton
Additional_Documentation Contributing
Contributing
A_demo_to_query_inception_model Additional_Resources
Helm_v3 Model_Repository
Model_Repository
Helm_v2 Model_Repository
GCS_Permissions Deploy_Prometheus_and_Grafana
Deploy_Prometheus_and_Grafana
AWS_Model_Repository Deploy_Prometheus_and_Grafana Deploy_the_Triton_Inference_Server
Supported_flavors Requirements
Triton_flavor Deploy_models_tracked_in_MLflow_to_Triton
Deploy_models_tracked_in_MLflow_to_Triton
Perform_inference MLflow_Deployments
MLflow_Deployments
Deploy_the_Triton_Inference_Server
Prometheus_ServiceMonitor_Support Using_Triton_Inference_Server
Using_Triton_Inference_Server
Known_Issues
Of_Contents*_-_[[#models][Models]]_- Models
Status
Only_original_source_code_from_you_and_other_people_that_have Contributing_code
Contributing_code
Client_side bert-99.9
bert-99.9
the_MLPerf_Inference_container*,_launch_a_Python_console_and_run NVIDIA_DGX_Stations,_this_method_will_fail*,_since_the_Mellanox_NICs
NVIDIA_DGX_Stations,_this_method_will_fail*,_since_the_Mellanox_NICs
stopping*__under_the_new_rules,_/min_query_count/_is_no_longer_a Fixing_INVALID_results
refer_to_/closed/NVIDIA_for_detailed_instructions_for_NVIDIA_GPU H3C_Submission_Systems Fujitsu_Submission_Systems
H3C_Submission_Systems
contains_RetinaNetNMS_PVA_kernel NMSPVAPlugin___Sample_application_to_demonstrate_how_to_use_this
NMSPVAPlugin___Sample_application_to_demonstrate_how_to_use_this
Aarch64-Linux_or_Tegra-Linux_Specific_Paths Steps_to_build_the_standalone_plugin
Steps_to_build_the_standalone_plugin MACROS_in_the_NMSPVAPlugin
MACROS_in_the_NMSPVAPlugin
for_DLRMv2*,_the_dataset_is_quite_large._We_recommend that_once_the_scratch_space_is_setup_and_all_the_data,_models,_and
Download_the_datasets
Downloading_the_model_files
the_above_steps_(/Download_the_datasets,_Downloading_the_model Setting_up_the_DLRMv2_Scratch_Space
Setting_up_the_DLRMv2_Scratch_Space
Launching_the_environment_on_datacenter/desktop_systems
Launching_the_environment_on_Jetson_Orin_systems
measurements,_and_systems_directories_in_your_submission*_for later,_you_wish_to_remove_a_system*,_simply_edit_this_file_and
later,_you_wish_to_remove_a_system*,_simply_edit_this_file_and
this_webpage_has_not_yet_been_finalized,_so_the Instructions_for_Auditors
you_proceed_to_try_to_build_and_run_from_this_directory,_it_is Running
Running Loading_and_processing_traces
Power_Regulator_Settings__OS_Control_Mode Fans
Fans
Thermal_Configuration__Optimal_Cooling Maximum_Frequency
Maximum_Frequency
Setup_with_docker_image Run_Benchmarks
option_2__pull_docker convert_dataset_and_model
convert_dataset_and_model
Steps_to_run_RNN-T_with_three_options
2._End-to-end_run_inference Option_2__Build_docker_container
Option_2__Build_docker_container
Run_Benchmarks_with_Int8 Docker_Instructions
Docker_Instructions
Build Setup_Instructions_-_Docker
Setup_Instructions_-_Docker
Quantize_Torchscript_Model_and_Check_Accuracy Run_Benchmark_(Common_for_Docker_&_Baremetal)
Run_Benchmark_(Common_for_Docker_&_Baremetal)
3.b_Option_3__pull_docker 4._Run_command_for_accuracy_and_performance
4._Run_command_for_accuracy_and_performance
Preprocess_Data Run_the_Benchmark
Run_the_Benchmark Get_Started_with_ResNet50
Get_the_Results Get_started_with_BERT Get_started_with_DLRM2 Get_Started_with_Retinanet Complinace_Test Get_started_with_DLRM Get_Started_with_ResNet50
Get_started_with_BERT
Convert_Dataset_and_Model Run_the_Benchmark
Get_started_with_DLRM2
Login_to_Docker_Container Preprocess_model_and_dataset Run_the_Benchmark
Preprocess_model_and_dataset
Calibrate_and_dump_int8_model Run_the_Benchmark
Get_Started_with_ResNet50
Get_Started_with_Retinanet
Get_the_results Get_Started_with_RNNT
Get_Started_with_RNNT
Steps_to_run_GPT-J
9._run Docker
Launching_the_environment_on_Jetson_Orin_AGX/NX
power_measurement*_with_VF_configuration,_you_need_to_allow Launching_the_environment_on_a_MIG_(Multi-Instance_GPU)_instance
Run_performance Results
Download_dataset Reproduce_results
Reproduce_results
generate_results_for_accuracy_and_performance_separately_add FP8_flow
FP8_flow
refer_to_/closed/NVIDIA/README.md_for_detailed_instructions_for Dell_Technologies_Submission_Systems
Dell_Technologies_Submission_Systems
Alternative_cross_compile_option Troubleshooting
Apply_Perf_Optmization_(AGX_and_NX_applicable)
USB-C_Power_Adapters Apply_Perf/W_Optmization_(only_AGX_applicable) Download_Data,_Model_and_Preprocess_the_data Running_a_Benchmark Apply_Perf/W_Optmization_for_AGX Apply_Perf/W_Optmization_for_NX
Apply_Perf/W_Optmization_(only_AGX_applicable)
Download_Data,_Model_and_Preprocess_the_data
the_datasets_for_inferences*_described_in Running_a_Benchmark
Running_a_Benchmark
DF_Cstates__Auto DF_Common_Options
NUMA_nodes_per_socket__NPS1 CPU_Common_Options
SMT_Control__Disable Prefetcher_Settings Management_Firmware_Settings Global_C-state_Control__Enabled
Prefetcher_Settings
L2_Up/Down_Prefetcher__Auto Core_Performance_Boost__Disable
Core_Performance_Boost__Disable Management_Firmware_Settings
ResNet50_(6,900_RPM) Power_Consumption_Settings Maximum_Frequency
Power_Consumption_Settings
ResNet50_Server__Disabled Maximum_Frequency
Redirect_scrubber_control__Auto Memory_Addressing
Memory_Addressing
NUMA_nodes_per_socket__NPS4 CPU_Common_Options
Redirect_scrubber_control__Disabled Memory_Addressing
ACPI_SRAT_L3_Cche_As_NUMA_Domain__Disabled CPU_Common_Options
Global_C-state_Control__Enabled Management_Firmware_Settings
BERT-99.9_and_ResNet50_(6,900_RPM) Maximum_Frequency
Download_the_dataset_and_the_model Running_your_first_benchmark
enter_closed/Azure*._From_now_on,_all_of_the_commands_detailed Launching_the_environment_on_datacenter/desktop_systems
Further_reading
that_the_same_scale_factor_is_used_for_the_Q,_K,_and_V_output Quantization_in_the_Open_Division_Submissions
Quantization_in_the_Open_Division_Submissions
enter_closed/ConnectTechInc*._From_now_on,_all_of_the_commands Launching_the_environment
enter_closed/IEI*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment
Complinace_Test
refer_to_/closed/Intel_for_detailed_instructions_for_Intel_CPU Dell_Technologies_Submission_Systems Dell_Technologies_Open_Submission_Systems
enter_closed/Dell*._From_now_on,_all_of_the_commands_detailed_in Launching_the_environment_on_datacenter/desktop_systems
Fujitsu_Submission_Systems
your_system_is_not_listed_above_or_in Running_your_first_benchmark
enter_closed/Nutanix*._From_now_on,_all_of_the_commands_detailed Launching_the_environment
Adding_a_New_or_Custom_System
Setup_the_Jetson_Orin_NX_System
Flash_the_board Apply_Perf_Optmization_(AGX_and_NX_applicable)
Apply_Perf_Optmization_for_AGX/NX
Apply_Perf/W_Optmization_for_AGX
Apply_Perf/W_Optmization_for_NX
Orin_NX_NVME_ASPM Download_Data,_Model_and_Preprocess_the_data
This_method_augments_a_sample_library_to_a_device, Configuring_the_server_is_facilitated_by_this_method,_which
Configuring_the_server_is_facilitated_by_this_method,_which
A_pivotal_function_responsible_for_forwarding_queries_to Device_Management
Device_Management
This_virtual_method_necessitates_subclass_overrides_for Allocation_management_for_input_or_output_data,_inclusive
Allocation_management_for_input_or_output_data,_inclusive
This_method_readies_input_data_for_inference,_involving DeviceGptJ__Specialized_Device
DeviceGptJ__Specialized_Device
This_function_primarily_focuses_on_processing This_method_spearheads_batch-based_inference,_utilizing
This_method_spearheads_batch-based_inference,_utilizing
Steps_to_calibrate_GPT-J
Dell_Technologies_Open_Submission_Systems
INT8_Quantization Results
Benchmarks*._Implementation_of_DLRM_benchmarks_in_./bench How_to_run_dlrm_code?
How_to_run_dlrm_code?
Other_operations Tested_software_versions
Tested_software_versions
Arguments Result_Summarizer_-_Computing_power_metric closure_js_binary phantomjs_test closure_js_deps closure_js_template_library closure_java_template_library closure_py_template_library closure_css_binary closure_js_proto_library closure_proto_library
Result_Summarizer_-_Computing_power_metric
Computing_the_power_result Step_by_step_examples
Step_by_step_examples
Check/clean_CM_cache Add_CM_interface_for_new_projects_and_papers
Add_CM_interface_for_new_projects_and_papers
Reusability_using_MLCommons_CM_automation_language Install_Python_virtual_environment_via_CM
Install_Python_virtual_environment_via_CM
About 
View_MLPerf_inference_v3.1_result 
Major_Features_and_Improvements Release_1.0.0 Release_0.2.2 Release_0.1.0
Release_1.0.0
Release_0.2.2
Bug_Fixes Release_0.2.1 Release_0.2.0
Release_0.2.1
Release_0.2.0
Release_0.1.0
Start_the_Sax_GPU_model_server Use_Sax
Use_Sax
Install_Python_packages_(in_user-space) Prevent_running_out_of_memory
Prevent_running_out_of_memory
The_dependencies_are_needed_for_ Install_via_=ck=
Install_via_=ck=
Use_(CUDA_8_and_GCC_5)_or_(CUDA_9_and_GCC_6). Detect_Python,_Keras
Detect_Python,_Keras
Use_Python_3. TensorFlow_[=x86_64=]
TensorFlow_[=x86_64=]
Use_Python_3,_(CUDA_8_and_GCC_5),_cuDNN_6. TensorFlow_[build_from_sources]
TensorFlow_[build_from_sources]
Use_Java_1.8,_Bazel_0.8,_Python_3,_(CUDA_8_and_GCC_5)_or_(CUDA_9 YAD2K
YAD2K
The_model_is_currently_cloned_into_=${INSTALL_DIR}=,_which Run_YAD2K_demo
Run_YAD2K_demo
Preprocess_the_calibration_dataset Calibrate_the_model
Calibrate_the_model
Download_the_COCO_training_dataset
Select_the_calibration_dataset
Detect_a_pregenerated_profile
Describe_how_the_=--env.CK_ENABLE_BATCH=_flag_enables_the_choice =ck_custom_preprocess=,_=ck_custom_preprocess_batch=
=ck_custom_preprocess=,_=ck_custom_preprocess_batch=
Input_Parameters* =custom_tensorRT.py=
=custom_tensorRT.py=
Describe_how_the_=--env.CK_ENABLE_TENSORRT=_flag_enables_the =load_graph_tensorrt_custom=_
=load_graph_tensorrt_custom=_
Hint_install_prebuilt_TensorFlow_via_pip_to_check_all_suitable Prevent_running_out_of_memory
This_package_is_deprecated_by_=1.15.0=,_which_includes_additional Unresolved_issues
Unresolved_issues
Cannot_build_for_Android_(hence_removed_patches) Resolved_issues
Resolved_issues Notes
To_use_machine-specific_build_options_(very_important_on_Raspberry Unresolved_issues
Cannot_build_for_Android Resolved_issues
For_official_MLPerf_Inference_submissions_on_50,000_images, Variations
Variations
Equivalent_to_=all.500=_for_the_"min"_dataset. MLPerf_Inference_option_1
MLPerf_Inference_option_1
This_option_was_used_for_MLPerf_Inference_v0.5_by_Intel_and MLPerf_Inference_option_2
MLPerf_Inference_option_2
Unit-tests
=first.1=_and_=first.5=_use_a_file_list_(with_the_first_and_the Accuracy_with
Accuracy_with
This_is_equivalent_to_ Build-thread_variations Known_issues
Build-thread_variations
gcc_5.4_is_required_on_Ubuntu_16.04,_see Patch
Patch
On_25/Apr/2019_we_informed_Google_of_a_bug_in_their_converter, Manual_instructions
Manual_instructions
Convert Semi-automated_instructions
Semi-automated_instructions
Need_to_introduce_an_environment_variable_for_the_model Convert
Update_with_manual_and_semi-automatic_instructions. Regular_NMS
Regular_NMS
Backend_(CPU_and_GPU_acceleration)_tags_ Examples_
Examples_
ImageNet_validation_dataset_(required_for_calibration) Example_
Using_Python_3_is_recommended. Dependencies
We_now_have_=ck-env_package_lib-python-cython=_but_it_does_not Build_warning
Build_warning
Refresh_all_CK_repositories_after_any_updates_(e.g. bug_fixes)_ Build Set_up_environment_variables Build_(Linux_or_Windows) Latest
See_the_quotes_magic_explained Run_the_default_command
Run_the_default_command
Set_up_environment_variables
This_is_equivalent_to_the_default_run_command_ Gory_details ResNet,_int8,_15_samples_per_batch
Gory_details Copy_the_results_to_a_machine_for_analysis
Copy_the_results_to_a_machine_for_analysis
You_may_need_to_run_commands_below_with_=sudo=,_unless_you Prepare_repository
Prepare_repository
Build_(Linux_or_Windows)
Latest
Other_Dependencies Programs
Programs
target_space_id,_is_character_level, 
Data_
Putting_it_all_together Hyperparameters
Hyperparameters
Batching Building_the_Model
Building_the_Model
Walkthrough
are_all_standardized_on_=TFRecord=_files_with Problems_and_Modalities
Problems_and_Modalities
define_training-time_hyperparameters_for_the_dataset_and Models
define_the_core_tensor-to-tensor_transformation, Hyperparameter_Sets
Hyperparameter_Sets
sets*_are_defined_and_registered_in_code_with Trainer
Trainer Adding_your_own_components
Adding_your_own_components
CK_will_use_the_latest_ArmCL_instance_compiled_with_=ck_compile=. Benchmarking_ArmCL-OpenCL_examples_(from_ArmCL_v18.0x)
Benchmarking_ArmCL-OpenCL_examples_(from_ArmCL_v18.0x)
CK_will_only_run_the_executable_once_(=--repetitions=1=) Running_ArmCL-OpenCL_examples_(before_ArmCL_v18.0x)
Running_ArmCL-OpenCL_examples_(before_ArmCL_v18.0x)
You_may_want_to_install_the_profiler_from_the_following_package_ Printing_help_messages
Printing_help_messages
Extract
Tags Use
Use_=--target_os=android23-arm64=_to_build_for_Android_API_23 Weights_package TensorFlow_models
Weights_package Build Compile
If_you_have_installed_the_COCO_or_KITTI_datasets_a_while_ago,_you Run_the_program
Run_the_program
=OID=_(*TBD*) =CK_TF_GPU_MEMORY_PERCENT=
=CK_TF_GPU_MEMORY_PERCENT=
Run_once_(classical_CK_interface)
=CK_TEST_INTERVAL= Results
SciPy Install_via_CK
Install_via_CK
ImageNet_dataset Benchmark Build
module._Data_iterators_are_flexible,_easy_to_reason Other_details_for_better_NMT_models
TODO(rzhao)__add_URL_for_English-Vietnamese_trained_model. Speed*__(0.37s_step-time,_15.3K_wps)_on_/K40m/_&_(0.17s
TODO(rzhao)__add_URL_for_German-English_trained_model. Speed*__(2.1s_step-time,_3.4K_wps)_on_/Nvidia_K40m/_&_(0.7s
TensorFlow_models
=CK_RECREATE_CACHE= Input_preprocessing_parameters
Input_preprocessing_parameters
If_=CK_TMP_IMAGE_SIZE=_is_set_and_valid,_this_parameter_is_not =CK_SUBTRACT_MEAN=
=CK_SUBTRACT_MEAN=
If_you_have_previously_installed_the_=coco=_dataset,_you_should Running
For_some_reason_only_debug_version_of_the_library_can_be_used Weights_package
Compile
Both_1.5.2._and_1.5.3_can_be_installed_but_fail_to_convert_ResNet Convert_TF_to_ONNX
Convert_TF_to_ONNX
SSD-MobileNet-v1 Datasets Inference
Using_OpenCV_gives_better_accuracy_than_using_Pillow. SSD-ResNet34
SSD-ResNet34
=CK_SKIP_IMAGES= Models
5,000_images SSD-MobileNet-v1
It_uses_TensorFlow_Lite Prerequisites
If_you_have_previously_installed_the_=coco=_datasets,_you_should Compiling
The_tool_does_not_update_a_remote_repo,_so_after_execution_you Run
Including_Python_modules_into_respective_package_listed_above_we Validation
Validation
=CK_IMAGE_COUNT= Detection_result_file_format
Detection_result_file_format
Since_the_preprocessed_COCO_dataset_takes_up_21G,_you_may_wish_to Download_the_SSD_ResNet34_model
Download_the_SSD_ResNet34_model
Use_precalibrated_profile Compile_the_Server/Offline_model_for_the_PCIe_server_cards
by_[[https_//cKnowledge.io/@gfursin][Grigori_Fursin]]_on MLPerf_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU
MLPerf_Inference_v1.0_-_Object_Detection_-_TFLite_(with_Coral_EdgeTPU
Install_common_CK_packages Setup_for_EdgeTPU
Setup_for_EdgeTPU
CPU
Amazon_Linux_2 Set_up_user-space_dependencies
Set_up_user-space_dependencies
Download_URLs_for_a_particular_category Download_images_for_a_given_category
Download_images_for_a_given_category
Program-specific_preprocessing Images_dataset
Images_dataset
Neon_backend 224
224
Currently_only_TensorFlow_packages_provide_env_variable_giving Program_parameters
Program_parameters
Initial_checkpoint 4._Quality
4._Quality
Evaluation_frequency 5._Steps_to_run_the_model
5._Steps_to_run_the_model
On_Google_Cloud_TPU 6._Software_versions
6._Software_versions
Steps_to_run_and_time 3._Dataset/Environment 3._Model 4._Dataset/Environment
Preprocessed_data_download 4._Model
BF16_training Checkpoint_Parameters
Checkpoint_Parameters
Checkpoint_Zarr_format How_to_run
How_to_run 5._Quality
6._Other
Access_details Model_conversion_from_Paxml_checkpoints
Model_conversion_from_Paxml_checkpoints
Supervised_finetuning Reader_Training
Reader_Training
Files_in_./results_directory_ Generate_the_TFRecords_for_Wiki_dataset
Generate_the_TFRecords_for_Wiki_dataset
It_is_extremely_critical_to_set_the_value_of_=random_seed=_to TFRecord_Features
TFRecord_Features
Some_stats_of_the_generated_tfrecords_ Stopping_criteria
Stopping_criteria
Example_evaluation_frequency Running_the_model
MD5sums_of_provided_files_ Extract
WikiExtractor.py_replaces_some_of_the_tags_present_in_XML_such Clean_up_and_dataset_seperation
Clean_up_and_dataset_seperation
From_Source Steps_to_download_data
3._Model
study_mode_currently_requires_the_C++_Minigo_engine.* Vs_mode
Vs_mode
Kiosk_mode Technical_discussion
Technical_discussion
Update_messages Synchronizing_stdout_and_stderr
Synchronizing_stdout_and_stderr
Steps_to_download_and_verify_data 3._Model
Observations Third_run,_Minigo,_model_250-...,_Jan_20th-Feb_1st_(ish)
Third_run,_Minigo,_model_250-...,_Jan_20th-Feb_1st_(ish)
v5_changelog_ v7a,_first_week_of_May
v7a,_first_week_of_May
This_is_NOT_an_official_version_of_AlphaGo Goals_of_the_Project
Goals_of_the_Project
Automated_Tests Basics
Basics
Playing_Against_Minigo Training_Minigo
Training_Minigo
Validating_on_a_different_set_of_data Retraining_a_model
Retraining_a_model
this_is_a_one-way_operation._Once_you_=eject=,_you_can't_go =npm_run_build=_fails_to_minify
=npm_run_build=_fails_to_minify
cc_gtp Running_the_unit_tests
Running_the_unit_tests
GCS_for_simple_task_signaling
versions*_of_the_official_models_targeting_releases_of Running_the_models
Running_the_models
Pre-trained_model Compute_Devices
Compute_Devices
From_Docker Steps_to_run_and_time
The_current_data_generation_pipeline_is_run_on_CPU_and_is 3._Dataset/Environment
Training_data_order 4._Model
Evaluation_results Detailed_instructions
Detailed_instructions
Model_Definition [[file_model/attention_layer.py][attention_layer.py]]__Defines_the
[[file_model/attention_layer.py][attention_layer.py]]__Defines_the
BLEU_computation Term_definitions
Term_definitions
Recommended_setup 2._Directions
one_can_control_which_GPUs_are_used_with_the_NV_GPU_variable 3._Dataset/Environment
Learning_rate_schedule 5._Quality
4._Dataset/Environment
Run_and_Time 3._Dataset/Environment
Steps_to_launch_training 3._Dataset/Environment
MLCommons_Inference
training* Mixed_Precision_(AMP)*
Mixed_Precision_(AMP)* rate_decay*
rate_decay*
logger* Quick_Start_Guide
Repository_content 3._Quality
Abstractions
Note_ Finetuning_from_Detectron_weights_on_custom_datasets
Finetuning_from_Detectron_weights_on_custom_datasets
Steps_to_run_benchmark. 3._Dataset/Environment
2* Training_and_test_data_separation
note_that_all_command_instructions_provided_in_this_README_are Prerequisites
note_that_all_the_commands_in_the_following_sections_are Downloading_the_dataset
Downloading_the_dataset
COCO-2014 Downloading_the_checkpoints
Downloading_the_checkpoints
Multi-node_(with_SLURM) Benchmark_details
Benchmark_details
COCO_2014 The_Model
The_Model
CLIP Quality
Reference_runs
that_this_repository_is_outdated__we_are_now_using_the_next Fighting_the_software_and_hardware_chaos Collective_Knowledge_workflows_for_MLPerf
Fighting_the_software_and_hardware_chaos
CK_components_for_AI_and_ML_are_now_collected_in Author
Running_preprocessing_before_training/inference_(optional) Constructing_the_Data_CSV
Constructing_the_Data_CSV
Customize_the_Training
Running_multiple_experiments_(optional) Running_GaNDLF_(Training/Inference)
Running_GaNDLF_(Training/Inference)
Special_notes_for_Inference_for_Histology_images Generate_Metrics
Generate_Metrics
Expected_Output(s)
Plot_the_final_results
Deploy_as_a_Metrics_Generator Federating_your_model_using_OpenFL
Federating_your_model_using_OpenFL
Special_Case_for_Training Enabling_GPUs
Enabling_GPUs MLCubes
MLCubes
Dev_Containers_is_an_open_spec_which_is_supported_by Sample_Data
Sample_Data
When_using_your_own_data,_it_is_vital_to_correctly Segmentation
Segmentation
Please_consider_the Classification Regression
Classification
Regression
Install_from_Sources Docker_Installation
Docker_Installation
We_cannot_provide_support_for_the_Windows_Insider_program_or_for Building_your_own_GaNDLF_Docker_Image
Building_your_own_GaNDLF_Docker_Image
is_a_package_that_is_worked_on_by_the_MLCommons_community_in Issues
Issues
the_bug*_A_clear_and_concise_description_of_what_the_bug_is. Reproduce*_Steps_to_reproduce_the_behavior__1._Go_to_'...'_2._Click Reproduce*_Steps_to_reproduce_the_behavior_
Reproduce*_Steps_to_reproduce_the_behavior__1._Go_to_'...'_2._Click
If_applicable,_add_screenshots_to_help_explain_your Version*_Version_information_of_the_GaNDLF_package_in_the (please_complete_the_following_information)_*_-_OS_
Version*_Version_information_of_the_GaNDLF_package_in_the
(please_complete_the_following_information)_*_-_OS_ did_you_install_GaNDLF*_Please_provide_all_steps_followed_during
did_you_install_GaNDLF*_Please_provide_all_steps_followed_during
Weekly_Meeting Disclaimer
Markdown_based_tutorials Questions?
Questions?
Update_all_packages_and_repositories 3._Install_CUDNN_on_Ubuntu_22.04
3._Install_CUDNN_on_Ubuntu_22.04
Workflow_to_Test_Patches_with_Zephyr_SDK Release_Process
Release_Process
This_page_is_outdated._Please_follow MLPerf_Inference_-_Image_Classification MLPerf_Inference_-_Object_Detection
MLPerf_Inference_-_Image_Classification
MLPerf_Inference_-_Object_Detection
Flag_to_ignore_errors_in_submissions Flag_to_run_the_check_for_power_submissions
Flag_to_run_the_check_for_power_submissions Summary
*Current_version_*_alpha Requirements
Guidelines_(alpha_version)
Submit_reflection_of_your_results_as_a_paper Evaluation
evaluation_*_All_submissions_will_be_evaluated_in_a_validation How_to_participate
How_to_participate
guide__*_Check_this Your_Account_&_Log-in
Your_Account_&_Log-in
Prompt_Hacking_Journey Examples_of_unsafe_images_generated_by_safe-seeming_prompts
Examples_of_unsafe_images_generated_by_safe-seeming_prompts
prompt_highlighting_the_harms_in_the_image_*_"Baby_lying_in_a represented_in_the_images_*_Violent_or_Graphic_Imagery,
represented_in_the_images_*_Violent_or_Graphic_Imagery,
attribute(s)_targeted_in_the_images_*_None/Not_Applicable Example_of_stereotyping
Example_of_stereotyping
prompt_highlighting_the_harms_in_the_image_*_"_A_female represented_in_the_images_*
represented_in_the_images_*
attribute(s)_targeted_in_the_images_* Contact_the_organizers
Contact_the_organizers
Benchmarks_for_Data-Centric_AI_Development*, Contributing_to_the_DataPerf_Benchmark_Suite
Contributing_to_the_DataPerf_Benchmark_Suite
Adversarial_Nibbler Participating_in_the_DataPerf_Challenges
Participating_in_the_DataPerf_Challenges
*Current_version_*_beta Requirements
MLCube_execution
Execute_complete_pipeline Guidelines_v0.5
Guidelines_v0.5
Closed_Division__Offline_evaluation_of_a_submission Baselines
Baselines
Started_*_Jump_to_[[#getting-started][our_introductory_colab Evaluation_Metric
Evaluation_Metric /M/_is_user_defined,_but_Dynabench_will_host_two_leaderboards_per
/M/_is_user_defined,_but_Dynabench_will_host_two_leaderboards_per
Submission Files
Files
Optional_Files Using_.wav_Files_for_Selection
Using_.wav_Files_for_Selection Optional_MLCube_Workflow
Optional_MLCube_Workflow
Imagenet_for_resnet50 Build_benchmark_images
Build_benchmark_images
Create_TFRecord_for_ADE20K Train
Train
Evaluate_pb Evaluate_TFLite
Evaluate_TFLite
Run_TFLite_evaluation Quantization-aware_training
Quantization-aware_training
Generate_data_for_post-training_quantization Run_post-training_quantization
Run_post-training_quantization Reference
Mobilenet_EdgeTPU_latency Pretrained_models
Pretrained_models
Edge_TPU_checkpoints_ Mobilenet_V2_Imagenet_Checkpoints
Mobilenet_V2_Imagenet_Checkpoints Training
V2 Example
accuracy_target Evaluate_accuracy_on_Android_devices
Evaluate_accuracy_on_Android_devices
[[file_models_and_code/checkpoints/mobilenet_edgetpu_224_1.0][mobilenet_edgetpu_224_1.0]] Accuracy
Generating_non-TFLite_specific_files_(export_inference_graph.py) Accuracy
of_the_repo_*_1._*Hardware_Requirements*_-_Container_images, Hardware_requirements
Hardware_requirements
The_jobfile_should_look_like_ Parse_results_and_create_all_the_plots
Parse_results_and_create_all_the_plots
Everyone_else_ Abbreviated_building_instructions_
Abbreviated_building_instructions_
Tutorial_Videos_&_Slides Performance_Mode_vs. Energy_Mode
Performance_Mode_vs. Energy_Mode Hardware_Setup
Hardware_Setup
Only_attempt_this_if_you_are_very_comfortable_with_the Energy_Mode_Hardware
Energy_Mode_Hardware
NOTE__Only_ONE_power_supply_is_allowed_to_supply_the_DUT Software_Setup
Software_Setup
2__The_Runner_will_look_in_the_subfolder_defined_in_the_firmware. Selecting_Energy_Mode
Selecting_Energy_Mode
Unlike_Performance_Mode,_you_cannot_talk_directly_to_the_DUT Custom_Configuration
Custom_Configuration
Sometimes_a_device_is_not_detected_when_hot-plugged._The Standard_debug_protocol_for_device_detection_issues
Standard_debug_protocol_for_device_detection_issues
Fractured_Messages_from_the_IO_Manager Bill_of_Materials
Bill_of_Materials
Flutter_may_not_work_correctly_if_your_temp_directory_is_located Tested_environment
Tested_environment
that_VS_Code_=preLaunchTask=_hook_will_not_run_this_command_when Android
Android
Pull_Request_Checklist How_to_become_a_contributor_and_submit_your_own_code
How_to_become_a_contributor_and_submit_your_own_code
Optional Building_the_MLPerf_app_with_the_QTI_backend
Building_the_MLPerf_app_with_the_QTI_backend
Videos/*_parallax_supported. [[https_//free.nkdev.info/jarallax/][Demo]]
[[https_//free.nkdev.info/jarallax/][Demo]]
Package_managers Set_up_your_HTML
Set_up_your_HTML
Additional_styles Call_the_plugin
Call_the_plugin
C._jQuery_way Video_Usage_Examples
Video_Usage_Examples Options
Options_For_Video Events
Events
onScroll_event Methods
Methods
B._jQuery_way No_conflict Real_Usage_Examples
No_conflict
you_can_rename_plugin._###_A._JavaScript_way B._jQuery_way
Real_Usage_Examples
AMD_(Asynchronous_Module_Definition) Node
displayInput___default=true_|_false=hide_input._*_displayPrevious__
MLPerf_training_benchmark_results How_to_update_this_repository_with_new_results
How_to_update_this_repository_with_new_results
Using_CM_script Copyright
PyTorch_Execution_Graphs Execution_Trace_Generator_(et_generator)
Execution_Trace_Generator_(et_generator)
This_only_updates_CK_repositories_on_the_host_system._To_update Set_up_environment_variables
Add_the_=--no-cache=_flag_to_rebuild_the_image_from_scratch. Accuracy_mode
Accuracy_mode
ResNet,_int8,_15_samples_per_batch
MobileNet,_int8 Performance_mode Prepare_a_CK_repository_with_the_experimental_results
Performance_mode
MobileNet,_int8,_250_samples_per_batch Accuracy_mode
=--volume_${CK_EXPERIMENTS_DIR}_/home/dvdt/CK_REPOS/local/experiment= Accuracy_mode
Prepare_a_CK_repository_with_the_experimental_results
Currently,_this_downloads_the_COCO_2017_validation_dataset,_etc., Locate_the_dashboard_plugin
Locate_the_dashboard_plugin
From_a_local_machine Open_the_dashboard
Open_the_dashboard
Collective_Knowledge_workflows_for_MLPerf
MobileNet-v1
MobileNet-v3
EfficientNet
SMT_Control__Enable Global_C-state_Control__Disabled Global_C-state_Control__Enabled
Global_C-state_Control__Disabled Management_Firmware_Settings
Log_out_and_log_back_in_for_the_necessary_group_permissions_to Host_OS_independent
Host_OS_independent
Set_up_Collective_Knowledge_environment Target_OS_dependent,_SDK_dependent
Target_OS_dependent,_SDK_dependent
Make_sure_to_have_copied_the_required_datasets_(e.g. ImageNet)_and Test_Docker_images
Test_Docker_images
Edge_-_Q1_Pro Further_info
Deprecated_workloads Info
The_full_installation_can_take_more_than_50G._If_the_space_on_the B._Initial_device_setup_under_the_=root=_user
B._Initial_device_setup_under_the_=root=_user
=[D1S]=_Set_user_password C._Initial_device_setup_under_the_=krai=_user
C._Initial_device_setup_under_the_=krai=_user
=[D1]=_Run D._Set_up_ImageNet_and_other_datasets
D._Set_up_ImageNet_and_other_datasets
=[D1]=_Extract_and_preprocess_ImageNet_on_the_device E._Set_up_QAIC_SDKs
E._Set_up_QAIC_SDKs
=[HR]=_Compile_the_workloads_on_the_host_and_copy_to_the_device F._Expected_Results_from_Set_up_QAIC_SDKs
F._Expected_Results_from_Set_up_QAIC_SDKs
=[D]=_Verify_with_a_quick_run Appendix__Arguments
Appendix__Arguments
=DOCKER_DEVICE_TYPE= Appendix__Info
Appendix__Info
Launch_a_Docker_container_on_the_client_side_(=pf002=) Scenarios
Scenarios Alibaba_Submission NEUCHIPS_Submissions
BERT-99 Run_the_client_program_(=pf002=)
Run_the_client_program_(=pf002=)
BERT-99.9 Run_the_client_program_(=pf002=)
The_final_tarball_should_not_include_hidden_files._This_can Submit_your_submission
Submit_your_submission
MLPerf_Quantization
Apply_Perf_Optmization
10._run Docker
Get_started_with_DLRM
This_mode_is_supported_only_with_CK_≤_v1.17.0_or_≥_v2.6.0_ ResNet50 "All-in-one"
"All-in-one"
Note_that_unlike_[[#mobilenet_v1][MobileNet-v1]], "All-in-one"
prepare_env Setup_with_docker
option_1__build_docker convert_dataset_and_model
3.b_Option_2__build_docker 4._Run_command_for_accuracy_and_performance
NEUCHIPS_Submission System_Preprocessing
System_Preprocessing
Running_NEUCHIPS_DLRM_benchmark
The_closed-power_would_need_additional_setup_for_power Closed
Closed
Running_the_close-power_benchmark How_do_I_know_the_run_is_finished?
How_do_I_know_the_run_is_finished?
Compilation_for_15w_AEDKs_(edge_category)
Compilation_for_datacenter_category_16_NSP_PCIe Benchmarking
Benchmarking Example_Command_related_to_this_Scenario_and_Workload
Example_Command_related_to_this_Scenario_and_Workload
Recipe
ResNet50_Offline_-_ONNXRuntime BERT-Large
BERT-Large
Sinian Benchmarks
Alibaba_Submission
Weights Additional_Details
Additional_Details
Install_loadgen Dataset
Optimization Run_Resnet50 Raspberry_Pi
Run_Resnet50
The_following_commands_rely_on_the_content_of_this_folder, 2._JPQD-BERT-large-99
2._JPQD-BERT-large-99
and_*99*__We_dialed_JPQD_pruning_intensity_to_target *BERT-base-99*__JPQD_was_configured_to_optimize_BERT-base_to_meet_99%
*BERT-base-99*__JPQD_was_configured_to_optimize_BERT-base_to_meet_99%
We_initialized_pretrained_MobileBERT_with_15 Benchmarks
Run_Benchmarks
NEUCHIPS_Submissions
Build_and_deploy_HabanaLabs_MLPERF_training_2.1_container_in_the Resnet50
Training_data_packing
Please_note_that_we_use_the_same_optimizers_and_hyperparameters Configuration_details
Configuration_details
Software_Packages Repository_Contents
Repository_Contents
Run_DLRM
Run_benchmark_with_SLURM_-_single-node/multi-node_training. Steps_to_download_and_verify_data
information_as_self_contained*_as_possible_in_this_section.] Proposed_API_Change_(s)
Proposed_API_Change_(s)
API_Freeze_Consequences Coding_Style
Caveat_Emptor Setup
Overriding_Dependency_Versions Examples
Rule_Polymorphism Arguments
closure_js_binary
Support_for_AngularJS closure_js_test
closure_js_test
phantomjs_test
closure_js_deps
closure_js_template_library
closure_java_template_library
closure_py_template_library
closure_css_binary
closure_js_proto_library
closure_proto_library
models_are_programs,_and_need_to_be_treated_as_such_from_a Running_untrusted_models
Running_untrusted_models
Encryption_key_for_=security@tensorflow.org= Known_Vulnerabilities
Known_Vulnerabilities
Thanks_to_our_Contributors Release_1.14.0 Release_1.12.3 Release_1.12.0 Release_1.11.0 Release_1.10.1 Release_1.9.0 Release_1.8.0 Release_1.7.0 Release_1.6.0 Release_1.5.0 Release_1.4.1 Release_1.3.0 Release_1.2.1 Release_1.1.0 Release_1.0.1 Release_0.12.0 Release_0.11.0 Release_0.10.0 Release_0.9.0 Release_0.8.0 Release_0.7.1 Release_0.6.0
Release_1.14.0
Release_1.12.3
Bug_Fixes_and_Other_Changes Release_1.12.2 Release_1.13.0 Release_1.10.0 Release_1.4.0 Release_1.2.0 Release_1.0.0 Release_0.7.0
Release_1.12.2
Release_1.13.0
Release_1.12.0
Release_1.11.0
Release_1.10.1
Release_1.10.0
Release_1.9.0
Release_1.8.0
Release_1.7.0
Release_1.6.0
Release_1.5.0
Release_1.4.1
Release_1.4.0
Release_1.3.0
Release_1.2.1
Release_1.2.0
Release_1.1.0
Release_1.0.1
Breaking_Changes_to_the_API =tf.mul=,_=tf.sub=_and_=tf.neg=_are_deprecated_in_favor_of
=tf.mul=,_=tf.sub=_and_=tf.neg=_are_deprecated_in_favor_of
Release_0.12.0
Release_0.11.0
Release_0.10.0
Release_0.9.0
Release_0.8.0
Release_0.7.1
Release_0.7.0
Release_0.6.0
Backwards-Incompatible_Changes Release_0.5.0
Release_0.5.0
/Try_your_first_TensorFlow_program/ Contribution_guidelines
Contribution_guidelines
use_[[https_//github.com/tensorflow/tensorflow/issues][GitHub Continuous_build_status
Continuous_build_status
Community_Supported_Builds Resources
Compiler_infrastructure Getting_started_with_MLIR
Getting_started_with_MLIR
Creating_Your_own_App Building_the_TensorFlow_iOS_libraries_from_source
Building_the_TensorFlow_iOS_libraries_from_source
If_you_wish_to_place_the_models_in_your_assets_manually, Build
Install Android_Studio_with_Bazel
Android_Studio_with_Bazel
Note_to_active_contributors TensorFlow_Code_of_Conduct
TensorFlow_Code_of_Conduct
Function_conversion_rules Nested_functions
Nested_functions
Modifications_are_not_detected_in_methods Python_collections_in_TensorFlow_control_flow
Python_collections_in_TensorFlow_control_flow
Python_collections_of_fixed_structure_with_dynamic_index Shape_and_dtype_consistency_in_TensorFlow_control_flow
Shape_and_dtype_consistency_in_TensorFlow_control_flow
Consistency_of_shape Undefined_and_None_values_in_TensorFlow
Undefined_and_None_values_in_TensorFlow
Analogy_with_compile-time_constants_and_code_optimization Compound_symbols
Compound_symbols
Python_values_modified_in_TensorFlow_control_flow_become_Tensors =if=_statements
=if=_statements
Stripping_Default_valued_attributes Loader
Loader
C++ Constants
Constants
AOT_(Ahead-of-time)_compilation_for_CPU_with_=tfcompile= Inspect_compiled_programs
Inspect_compiled_programs
Default_minor-to-major_ordering Padding
Padding
array_to_match_with_the_*lower-rank*_array. Formal_definition
Formal_definition Broadcasting_similar-rank_arrays_with_degenerate_dimensions
Broadcasting_similar-rank_arrays_with_degenerate_dimensions
Implementation_details Gather
Gather
Informal_Description_and_Examples GetDimensionSize
GetDimensionSize
Variadic_Reduce ReducePrecision
ReducePrecision
Linear_index_formulas_for_tiling_given_a_shape_and_a_tile Tiling_as_pad-reshape-transpose
Tiling_as_pad-reshape-transpose
Skip_deploying_to_a_repository The_overall_flow
The_overall_flow
Generate_wrapper_functions_for_ops Support
Support
NOT_EDIT_THE_DOCKERFILES/_DIRECTORY_MANUALLY!*_The_files_within_are Building
Building
Run_TensorFlow_CI_Scripts_Natively_on_your_Machine TensorFlow_Continuous_Integration
TensorFlow_Continuous_Integration
Eight-bit_Calculations Transform_Reference
Transform_Reference
strip_unused_nodes Writing_Your_Own_Transforms
Writing_Your_Own_Transforms
=tf_upgrade_v2=_is_installed_automatically_as_a_script_by_the_pip Report
Report
*NOTE* ToDense
ToDense
Note__See_[[file_profile_model_architecture.md#caveats][Caveats]] Time_and_Memory
Time_and_Memory
On_CPU Profile_by_Python_Code
Profile_by_Python_Code
Option_Semantics_In_Different_View Times
Times
Press_enter_to_show_the_default_options Examples
Test_Bench Speech_Model_Architectures
Speech_Model_Architectures
TensorFlow_Lite_LSTM_op_("fused_ops") How_to_use
Simple_example_diff_for_using_original_TF_code_VS._TensorFlow_Lite Why_introduce_another_set_of_LSTM_APIs?
Why_introduce_another_set_of_LSTM_APIs?
Ophinted_Customized_Graph Simple_Tutorial
Simple_Tutorial
Exported_TensorFlow_Lite_Model. Caveat
Caveat
Run_on_macOS Deploy_to_Arduino
Deploy_to_Arduino
Build_the_library Load_and_run_the_example
Load_and_run_the_example Deploy_to_SparkFun_Edge
Deploy_to_SparkFun_Edge
If_you're_using_the Deploy_to_STM32F746 Debugging_Image_Capture
Deploy_to_STM32F746
Build_the_code Deploy_to_Arduino
Building_the_library Load_and_run_the_example
Debugging_Image_Capture
Additional_Apollo3_Instructions Building_for_the_Eta_Compute_ECM3531_EVB_using_Make
Building_for_the_Eta_Compute_ECM3531_EVB_using_Make
CMSIS-NN_optimized_kernels_(---under_development---) Goals
Goals
Test_that_the_model_produces_sensible_outcomes Measure_on-device_latency
Measure_on-device_latency
Debug_Mode Preprocessing_the_minival_dataset
Preprocessing_the_minival_dataset
Direct_usage
On_desktop_ Reducing_variance_between_runs_on_Android.
Reducing_variance_between_runs_on_Android.
Load_and_run_a_model_in_C++
Load_and_run_a_model_in_Python
Python_pip_Package Metrics
Metrics
Binary_Size Known_Limitations
Machine_learning_at_the_edge Get_started
Get_started
March_6th,_2019* Usability
Usability
AutoML_mobile_models Object_detection
Object_detection
Pose_estimation
Image_segmentation
Smart_reply
Objective-C Bazel_developers Import_the_library
Bazel_developers
Import_the_library
How_do_I_inspect_a_=.tflite=_file? Models_&_Operations
Models_&_Operations
How_do_I_test_that_a_TensorFlow_Lite_model_behaves_the_same_as_the Optimization
Defining_the_kernel_in_the_TensorFlow_Lite_runtime Best_Practices
Best_Practices
Converting_TensorFlow_models_to_convert_graphs TF_Graph_Attributes
TF_Graph_Attributes
Models_from_other_sources Re-train_a_model_(transfer_learning)
Re-train_a_model_(transfer_learning)
Train_a_custom_model 2._Convert_the_model
2._Convert_the_model
Ops_compatibility 3._Run_inference_with_the_model
3._Run_inference_with_the_model
Operations 4._Optimize_your_model
4._Optimize_your_model
Model_Optimization_Toolkit Next_steps
Next_steps
Exporting_a_tf.keras_File Complex_examples
Complex_examples
Exporting_a_quantized_GraphDef Additional_instructions
Additional_instructions
Converting_models_prior_to_TensorFlow_1.9 Basic_examples
Basic_examples
Convert_a_tf.Keras_model Quantization
Quantization Tweak_the_number_of_threads
Use_"dummy-quantization"_to_try_out_quantized_inference_on_a_float Specifying_input_and_output_arrays
Specifying_input_and_output_arrays
Specifying_subgraphs Logging
Example_applications_and_guides How_it_works
How_it_works
Location Starter_model
Starter_model
Output Customize_model
Customize_model
Recognize_image Display_results
Display_results
Process_results Display_results
Screenshot What_is_image_classification?
What_is_image_classification?
Uses_and_limitations Choose_a_different_model
Choose_a_different_model
Architecture Customize_model
Sample_application How_it_works
Energy_Efficiency Supported_Ops
Supported_Ops
iOS_(ObjC++) Advanced_Usage
Advanced_Usage
iOS Tips_and_Tricks Supported_Models_and_Ops
Tips_and_Tricks
Latency_and_accuracy_results Choice_of_tool
Choice_of_tool
Step_3._Build_and_run iOS_(with_XCode)
iOS_(with_XCode)
Step_5._Release_mode. Trying_the_GPU_Delegate_on_your_own_model
Trying_the_GPU_Delegate_on_your_own_model
Supported_Models_and_Ops
Tweak_the_number_of_threads
Convert_to_a_C_array Model_architecture_and_training
Model_architecture_and_training
Generate_project_files Build_the_library
Portable_reference_code Goals
Micro_Vision_example Run_inference
Run_inference
Obtain_the_output Next_steps
Exporting_the_concrete_function Example_program
Example_program
End-to-end_MobileNet_conversion Summary_of_changes_in_Python_API_between_1.X_and_2.0
Summary_of_changes_in_Python_API_between_1.X_and_2.0
=lite.OpHint= Installing_TensorFlow
Installing_TensorFlow
Proof_of_convergence Poisson_log_loss
Poisson_log_loss
Start_training Performance
is_an
The_high-level_idea_is_to_use_a_non-linear_map_to_transform details_overview_*_In_this_example_we_will_use_*Random
details_overview_*_In_this_example_we_will_use_*Random Classifier_*_=tf.contrib.kernel_methods.KernelLinearClassifier=
Classifier_*_=tf.contrib.kernel_methods.KernelLinearClassifier= the_role_of_stddev_*_The_classification_quality_is_very_sensitive_to
the_role_of_stddev_*_The_classification_quality_is_very_sensitive_to
the_role_of_the_output_dimension_*_Intuitively,_the_larger_the Explicit_kernel_mappings__summary_and_practical_tips
Explicit_kernel_mappings__summary_and_practical_tips
Determinism_when_scanning Writing_to_Cloud_Bigtable
Writing_to_Cloud_Bigtable
Distributed_Reinforcement_Learning Common_Gotchas!
Common_Gotchas!
Known_problems
-_With_OpenMPI_corrupt_data_will_be_received_resulting_in_an Implementation_details
Example__TFExampleDecoder Data_Provision
Data_Provision
Working_Example__Specifying_the_VGG16_Layers Training_Models
Training_Models
Working_Example__Training_the_VGG16_Model Fine-Tuning_Existing_Models
Fine-Tuning_Existing_Models
Fine-Tuning_a_Model_on_a_different_task Evaluating_Models.
Evaluating_Models.
Evaluation_Loop Authors
located_in object,_keyed_by_request_index_(uint32_t),_stores_it
object,_keyed_by_request_index_(uint32_t),_stores_it method_basically_does_2_things_
method_basically_does_2_things_
using_the_request_index_which_is_the_immediate Additional_design_notes
Additional_design_notes
Block_Sparsity Adding_pruning_ops_to_the_training_graph
Adding_pruning_ops_to_the_training_graph
Removing_pruning_ops_from_the_trained_graph Example__Pruning_and_training_deep_CNNs_on_the_cifar10_dataset
Example__Pruning_and_training_deep_CNNs_on_the_cifar10_dataset
As_tensorflow.contrib_is_being ConstrainedOptimization_(TFCO)
ConstrainedOptimization_(TFCO)
Proxy_Constraints Components
Components
TensorFlow_Makefile Before_you_start_(all_platforms)
Before_you_start_(all_platforms)
Building_the_CUDA-enabled_Android_demo_with_gradle/Android_Studio_ iOS
Raspberry_Pi Other_notes
Other_notes
Windows_Support Try_it_out
Try_it_out
IGFS Limitations
Makefile AssetManagerFileSystem
AssetManagerFileSystem
Run_inception_model_by_building_all_from_the_source_code Building_libraries
Building_libraries
Qualcomm_SDK_Linux_installation_fails_with_"Malformed Maintainers
We_provide_Linux_build_instructions_primarily_for_the_purpose_of Current_Status
Current_Status
Current_known_limitations Building_with_CMake CMake_GUI_build_(all_platforms)
Building_with_CMake
CMake_GUI_build_(all_platforms)
Start_a_Tensorflow_C++_project_with_CMake Step-by-step_Windows_build_(command_prompt)
Step-by-step_Windows_build_(command_prompt)
Exporting_TF.learn_models Importing_(C++_code)
Importing_(C++_code)
Recovering_signatures Generic_Signatures_(custom_or_advanced_usage)
Generic_Signatures_(custom_or_advanced_usage) Custom_Initialization
Custom_Initialization
Assets Exporter_Usage
Exporter_Usage
why_we_have_that_policy*__TensorFlow_developers_respond_to System_information
System_information
Loading_and_processing_traces
Installing_on_Linux Usage
for_timing*_-_you_will_not_be_able_to_get_function_times_from_this! Preparing_Your_Code
Preparing_Your_Code
Use_Final_Output_(with_names_on) Install_the_tracing-framework_Tools
Install_the_tracing-framework_Tools
Reload_Your_Page Capturing_Call_Traces
Capturing_Call_Traces
Chrome_Web_Store_.zip Platform_Notes
Platform_Notes
Actions App_Addons
App_Addons
HUD node.js_apps
node.js_apps
Enable_the_Feature_in_WTF Usage
the_JSON_format_is_not_yet_implemented!/* File_Layout
File_Layout
JSON_in_PARTIAL_Mode Chunks
Chunks
JSON Chunk_Types
Chunk_Types
Chunk_Type_0x2/event_data__Event_Data Chunk_Part_Types
Chunk_Part_Types
Zones Part_Type_0x30000/string_table__String_Table
Part_Type_0x30000/string_table__String_Table
wtf.addon Tracing
Tracing
Custom_Objects wtf.trace.session.bufferSize
wtf.trace.session.bufferSize
wtf.trace.provider.xhr HUD
wtf.hud.app.mode/wtf.hud.app.endpoint Remote_Control
Remote_Control
wtf.remote.target App
App
Linux/clang_ Threading
Threading
Myriad2_(compile_only_-_still_a_work_in_progress)_ Customizing
Customizing
Constructor_=Tensor<data_type,_rank>(size_array)= Class_=TensorFixedSize<data_type,_Sizes<size0,_size1,_...>>=
Class_=TensorFixedSize<data_type,_Sizes<size0,_size1,_...>>=
Class_=TensorRef= Accessing_Tensor_Elements
Accessing_Tensor_Elements
=<data_type>_tensor(index0,_index1...)= TensorLayout
TensorLayout
Assigning_to_a_=TensorRef=. Controlling_How_Expressions_Are_Evaluated
Controlling_How_Expressions_Are_Evaluated
Evaluating_On_GPU API_Reference
API_Reference
=<Operation>= Built-in_Tensor_Methods
Built-in_Tensor_Methods
Getting_Dimensions_From_An_Operation Constructors
Constructors
TensorMap Contents_Initialization
Contents_Initialization
=<Tensor-Type>_setRandom()= Data_Access
Data_Access
=Scalar*_data()=_and_=const_Scalar*_data()_const= Tensor_Operations
Tensor_Operations
=<Operation>_random()= Unary_Element_Wise_Operations
Unary_Element_Wise_Operations
=<Operation>__unaryExpr(const_CustomUnaryOp&_func)= Binary_Element_Wise_Operations
Binary_Element_Wise_Operations
=<Operation>_Logical_operators= Selection_(select(const_ThenDerived&_thenTensor,_const_ElseDerived&
Selection_(select(const_ThenDerived&_thenTensor,_const_ElseDerived&
Reduction_along_all_dimensions =<Operation>_sum(const_Dimensions&_new_dims)=
=<Operation>_sum(const_Dimensions&_new_dims)=
=<Operation>_reduce(const_Dimensions&_new_dims,_const_Reducer&_reducer)= Trace
Trace
=<Operation>_trace()= Scan_Operations
Scan_Operations
=<Operation>_cumprod(const_Index&_axis)= Convolutions
Convolutions
=<Operation>_convolve(const_Kernel&_kernel,_const_Dimensions&_dims)= Geometrical_Operations
Geometrical_Operations
=<Operation>__extract_image_patches(const_Index_patch_rows,_const_Index_patch_cols,_const_Index_row_stride,_const_Index_col_stride,_const_PaddingType_padding_type)= ColMajor_1st_dimension__channels_(of_size_d)_2nd_dimension__rows_(of
ColMajor_1st_dimension__channels_(of_size_d)_2nd_dimension__rows_(of
=<Operation>_____eval()= Representation_of_scalar_values
Representation_of_scalar_values
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100_(_8_nodes_) 3._Model
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100 3._Model
Run_benchmark_with_SLURM_for_NVIDIA_DGXA100_(_224_nodes_) 3._Model
output_metric* work*
work* Installation
BERT Parameters
OPEN Submission_Rules
Submission_Rules
Bare_metal_installation Container
Container
easePoly.exponent(/e/) easeQuad
easeQuad
easeQuadInOut easeCubic
easeCubic
easeCubicInOut easeSin
easeSin
easeSinInOut easeExp
easeExp
easeExpInOut easeCircle
easeCircle
easeCircleInOut easeElastic
easeElastic
easeElastic.period(/p/) easeBack
easeBack
easeBack.overshoot(/s/) easeBounce
easeBounce
/project/.invert(/x/,_/y/) geoProjection(/project/)
geoProjection(/project/)
or_strictly-negative*__the_domain_must_not_include_or scaleLog(/domain/,_/range/)
scaleLog(/domain/,_/range/)
stackOrderReverse(/series/) Stack_offsets
Stack_offsets
/symbolType/.draw(/context/,_/size/) pointRadial(/angle/,_/radius/)
pointRadial(/angle/,_/radius/)
(or_*D3.js*)_is_a_free,_open-source_JavaScript_library_for D3_is_a_low-level_toolbox Resources
D3_is_a_low-level_toolbox
[[./d3-array/transform.md][Transform]] [[./d3-axis.md][d3-axis]]
[[./d3-axis.md][d3-axis]]
[[./d3-geo/cylindrical.md][Cylindrical_projections]] [[./d3-geo/stream.md][Streams]]
[[./d3-geo/stream.md][Streams]]
[[./d3-geo/math.md][Spherical_math]] [[./d3-hierarchy.md][d3-hierarchy]]
[[./d3-hierarchy.md][d3-hierarchy]]
[[./d3-interpolate/zoom.md][Zoom_interpolation]] [[./d3-path.md][d3-path]]
[[./d3-path.md][d3-path]]
[[./d3-scale/point.md][Point_scales]] [[./d3-scale-chromatic.md][d3-scale-chromatic]]
[[./d3-scale-chromatic.md][d3-scale-chromatic]]
[[./d3-scale-chromatic/sequential.md][Sequential]] [[./d3-selection.md][d3-selection]]
[[./d3-selection.md][d3-selection]]
[[./d3-selection/namespaces.md][Namespaces]] [[./d3-shape.md][d3-shape]]
[[./d3-shape.md][d3-shape]]
[[./d3-shape/stack.md][Stacks]] [[./d3-time.md][d3-time]]
[[./d3-time.md][d3-time]]
/pack/(/root/)_{#_pack} /pack/.radius(/radius/)
/pack/.radius(/radius/)
/delaunay/.inedges Delaunay.from(/points/,_/fx/,_/fy/,_/that/)
Delaunay.from(/points/,_/fx/,_/fy/,_/that/)
/voronoi/.xmin/voronoi/.ymin/voronoi/.xmax/voronoi/.ymax /voronoi/.contains(/i/,_/x/,_/y/)
/voronoi/.contains(/i/,_/x/,_/y/)
(based_on_Vladimir_Agafonkin's_excellent d3-array
d3-array
Changes_in_D3_5.0
[[https_//github.com/d3/d3-array/blob/master/README.md][Arrays
ai.onnx.ml ai.onnx.ml
*ai.onnx.ml.Binarizer*
*ai.onnx.ml.CastMap*
Type_Constraints *ai.onnx.ml.CategoryMapper* *ai.onnx.ml.DictVectorizer* *ai.onnx.ml.FeatureVectorizer* *ai.onnx.ml.Imputer* *ai.onnx.ml.LabelEncoder* *ai.onnx.ml.LinearRegressor* *ai.onnx.ml.Normalizer* *ai.onnx.ml.OneHotEncoder* *ai.onnx.ml.SVMClassifier* *ai.onnx.ml.SVMRegressor* *ai.onnx.ml.Scaler* *ai.onnx.ml.TreeEnsembleClassifier* *ai.onnx.ml.TreeEnsembleRegressor* *ai.onnx.ml.ZipMap* *ai.onnx.ml.Binarizer-1* *ai.onnx.ml.CastMap-1* *ai.onnx.ml.CategoryMapper-1* *ai.onnx.ml.DictVectorizer-1* *ai.onnx.ml.FeatureVectorizer-1* *ai.onnx.ml.Imputer-1* *ai.onnx.ml.LabelEncoder-1* *ai.onnx.ml.LinearClassifier-1* *ai.onnx.ml.LinearRegressor-1* *ai.onnx.ml.Normalizer-1* *ai.onnx.ml.OneHotEncoder-1* *ai.onnx.ml.SVMClassifier-1* *ai.onnx.ml.SVMRegressor-1* *ai.onnx.ml.Scaler-1* *ai.onnx.ml.TreeEnsembleClassifier-1* *ai.onnx.ml.TreeEnsembleRegressor-1* *ai.onnx.ml.ZipMap-1* Version_2_of_the_'ai.onnx.ml'_operator_set Version_3_of_the_'ai.onnx.ml'_operator_set *ai.onnx.ml.TreeEnsembleRegressor-3* Version_4_of_the_'ai.onnx.ml'_operator_set *Constant* *GlobalMaxPool* *GridSample* *Log* *LpPool* *MaxUnpool* *Neg* *OptionalGetElement* *OptionalHasElement* *RandomNormalLike* *RandomUniform* *RandomUniformLike* *Range* *SequenceConstruct* *SequenceEmpty* *SequenceErase* *SequenceInsert* *SequenceMap*
*ai.onnx.ml.CategoryMapper*
*ai.onnx.ml.DictVectorizer*
*ai.onnx.ml.FeatureVectorizer*
*ai.onnx.ml.Imputer*
*ai.onnx.ml.LabelEncoder*
*ai.onnx.ml.LinearClassifier*
*ai.onnx.ml.LinearRegressor*
*ai.onnx.ml.Normalizer*
*ai.onnx.ml.OneHotEncoder*
*ai.onnx.ml.SVMClassifier*
*ai.onnx.ml.SVMRegressor*
*ai.onnx.ml.Scaler*
*ai.onnx.ml.TreeEnsembleClassifier*
*ai.onnx.ml.TreeEnsembleRegressor*
*ai.onnx.ml.ZipMap*
Operator_Changelog ai.onnx.ml
*ai.onnx.ml.Binarizer-1*
*ai.onnx.ml.CastMap-1*
*ai.onnx.ml.CategoryMapper-1*
*ai.onnx.ml.DictVectorizer-1*
*ai.onnx.ml.FeatureVectorizer-1*
*ai.onnx.ml.Imputer-1*
*ai.onnx.ml.LabelEncoder-1*
*ai.onnx.ml.LinearClassifier-1*
*ai.onnx.ml.LinearRegressor-1*
*ai.onnx.ml.Normalizer-1*
*ai.onnx.ml.OneHotEncoder-1*
*ai.onnx.ml.SVMClassifier-1*
*ai.onnx.ml.SVMRegressor-1*
*ai.onnx.ml.Scaler-1*
*ai.onnx.ml.TreeEnsembleClassifier-1*
*ai.onnx.ml.TreeEnsembleRegressor-1*
*ai.onnx.ml.ZipMap-1*
Version_2_of_the_'ai.onnx.ml'_operator_set
Version_3_of_the_'ai.onnx.ml'_operator_set
*ai.onnx.ml.TreeEnsembleRegressor-3*
Version_4_of_the_'ai.onnx.ml'_operator_set
on_model_validation*
on_language_in_this_and_all_related_documents*_ Components
Exploring_an_ONNX_file* Model_Semantics
Model_Semantics
As_of_the_publication_of_this_document,_no_ONNX_implementation_is Operators
Operators
Version_and_Later* External_Tensor_Data
External_Tensor_Data Standard_data_types
Standard_data_types
Representation Tensor_Element_Types
Tensor_Element_Types
Static_tensor_shapes Attribute_Types
Attribute_Types Training_Related_Information
Training_Related_Information
Adding_Experimental_Operators_[Deprecated_-_as_of_v1.5_experimental Submit_an_Issue_with_a_proposal_explaining_the_motivation_and_plan._It
Submit_an_Issue_with_a_proposal_explaining_the_motivation_and_plan._It
graph*. Input,_Output,_Node,_Initializer,_Attributes
Input,_Output,_Node,_Initializer,_Attributes
can_be_defined_as_a_set_of_operators._A_few_operators_in_this Supported_Types
Supported_Types
Other_types What_is_an_opset_version?
What_is_an_opset_version?
Loop Extensibility
Extensibility
Operator_as_function Tricks_learned_from_experience
Tricks_learned_from_experience
Build_the_markdown_documentation
Data_Serialization Initializer,_default_value
Initializer,_default_value
Scan Functions
Functions
A_function_with_attributes Parsing
Parsing
Evaluate_a_custom_node Implementation_details
LabelEncoder 💔No_Cover_Common_Operators
💔No_Cover_Common_Operators
ZipMap_(call_for_test_cases) 💚Covered_Experimental_Operators
💚Covered_Experimental_Operators
💔No_Cover_Experimental_Operators Model_Test_Coverage
Model_Test_Coverage
Listing_and_inspecting_Models_ Local_Caching
Local_Caching
Additional_cache_details Architecture
Hosting_your_own_ONNX_Model_Hub Raise_issue_if_any
Raise_issue_if_any
Serializing_SemVer_version_numbers_in_protobuf IR_versioning
IR_versioning
Model_versioning
Accuracy_or_performance_changes Released_Versions
Released_Versions
Checking_a_Large_ONNX_Model_>2GB Running_Shape_Inference_on_an_ONNX_Model
Running_Shape_Inference_on_an_ONNX_Model
Shape_inference_a_Large_ONNX_Model_>2GB Running_Type_Inference_on_an_ONNX_Function
Running_Type_Inference_on_an_ONNX_Function
ONNX_Compose Tools
Tools
Updating_Model"s_Inputs_Outputs_Dimension_Sizes_with_Variable_Length ONNX_Parser
ONNX_Parser
Example_to_Follow Step_3__PR_Review_by_Operators_SIG
Step_3__PR_Review_by_Operators_SIG
Sign-off Step_4__ONNX_release
Step_4__ONNX_release Updating_an_existing_operator
Updating_an_existing_operator
Checklist Removing_operator_or_function
Removing_operator_or_function
ai.onnx.preview.training ai.onnx_(default)
ai.onnx_(default)
Sample_Implementation *Acos*
*Acos*
*Acosh*
*Add*
*AffineGrid*
*And*
*ArgMax*
*ArgMin*
*Asin*
*Asinh*
*Atan*
*Atanh*
*AveragePool*
*BatchNormalization*
*Bernoulli*
*BitShift*
(i.e.,_Numpy-style)_broadcasting*__for_more_details Version
Version
*BitwiseAnd*
*BitwiseNot*
*BitwiseOr*
*BitwiseXor*
*BlackmanWindow*
*Cast*
*CastLike*
*Ceil*
*Celu*
*CenterCropPad*
*Clip*
*Col2Im*
*Compress*
*Concat*
*ConcatFromSequence*
*Constant*
*ConstantOfShape*
*Conv*
*ConvInteger*
*ConvTranspose*
*Cos*
*Cosh*
*CumSum*
*DFT*
*DeformConv*
*DepthToSpace*
*DequantizeLinear*
*Det*
*Div*
*Dropout*
*DynamicQuantizeLinear*
*Einsum*
*Elu*
*Equal*
*Erf*
*Exp*
*Expand*
*EyeLike*
*Flatten*
*Floor*
*GRU*
*Gather*
*GatherElements*
*GatherND*
5* Version
*Gelu*
*Gemm*
broadcasting*_(tensor_C_should_be_unidirectional Version
*GlobalAveragePool*
*GlobalLpPool*
*GlobalMaxPool*
*Greater*
*GreaterOrEqual*
*GridSample*
*GroupNormalization*
*HammingWindow*
*HannWindow*
*HardSigmoid*
*HardSwish*
*Hardmax*
*Identity*
*If*
*ImageDecoder* Portable_image_format_(PBM,_PGM,_PPM,_PXM,_PNM)_Decoded_images_follow
Portable_image_format_(PBM,_PGM,_PPM,_PXM,_PNM)_Decoded_images_follow
*InstanceNormalization*
*IsInf*
*IsNaN*
*LRN*
*LSTM*
*LayerNormalization*
*LeakyRelu*
*Less*
*LessOrEqual*
*Log*
*LogSoftmax*
*Loop*
*LpNormalization*
*LpPool*
*MatMul*
*MatMulInteger*
*Max*
*MaxPool*
*MaxRoiPool*
*MaxUnpool*
*Mean*
*MeanVarianceNormalization*
*MelWeightMatrix*
*Min*
*Mish*
*Mod*
*Mul*
*Multinomial*
*Neg*
*NegativeLogLikelihoodLoss*
*NonMaxSuppression*
*NonZero*
*Not*
*OneHot*
*Optional*
*OptionalGetElement*
*OptionalHasElement*
*Or*
*PRelu*
*Pad*
*Pow*
*QLinearConv*
*QLinearMatMul*
*QuantizeLinear*
*RNN*
*RandomNormal*
*RandomNormalLike*
*RandomUniform*
*RandomUniformLike*
*Range*
*Reciprocal*
*ReduceL1*
*ReduceL2*
*ReduceLogSum*
*ReduceLogSumExp*
*ReduceMax*
*ReduceMean*
*ReduceMin*
*ReduceProd*
*ReduceSum*
*ReduceSumSquare*
*RegexFullMatch*
*Relu*
*Reshape*
*Resize*
*ReverseSequence*
*RoiAlign*
*Round*
*STFT*
*Scan*
*Scatter*_(deprecated)
*ScatterElements*
*ScatterND*
*Selu*
*SequenceAt*
*SequenceConstruct*
*SequenceEmpty*
*SequenceErase*
*SequenceInsert*
*SequenceLength*
*SequenceMap*
*Shape*
*Shrink*
*Sigmoid*
*Sign*
*Sin*
*Sinh*
*Size*
*Slice*
*Softmax*
*SoftmaxCrossEntropyLoss*
*Softplus*
*Softsign*
*SpaceToDepth*
*Split*
*SplitToSequence*
*Sqrt*
*Squeeze*
*StringConcat*
*StringNormalizer*
*StringSplit*
*Sub*
*Sum*
*Tan*
*Tanh*
*TfIdfVectorizer*
*ThresholdedRelu*
*Tile*
*TopK*
*Transpose*
*Trilu*
*Unique*
*Unsqueeze*
*Upsample*_(deprecated)
*Where*
*Xor*
*ai.onnx.preview.training.Adam*
*ai.onnx.preview.training.Gradient*
*ai.onnx.preview.training.Momentum*
*_In_release_branch_update_the_version_number_in_file Distribution*_*_Make_sure_all_the_git_submodules_are_updated_*
Distribution*_*_Make_sure_all_the_git_submodules_are_updated_* onnx/onnx-operator.pb.h_*_onnx/onnx.pb.cc_*_onnx/onnx.pb.h_*_If_they
onnx/onnx-operator.pb.h_*_onnx/onnx.pb.cc_*_onnx/onnx.pb.h_*_If_they
Validation* distribution_verification*_*_Test_the_source_distribution_by
distribution_verification*_*_Test_the_source_distribution_by Upload_to_official_PyPI
Upload_to_official_PyPI
*_Windows/Linux_x86_64/Linux_aarch64/Mac_*_Create_a_new_API Distribution*_*_Follow_the_same_process_in_TestPyPI_to_produce
Distribution*_*_Follow_the_same_process_in_TestPyPI_to_produce After_PyPI_Release
After_PyPI_Release
*_Announce_in_slack,_for_instance,_=onnx-general=_channel._* conda-forge_package_with_the_new_ONNX_version*_*_Conda_builds_of
conda-forge_package_with_the_new_ONNX_version*_*_Conda_builds_of into_main_branch*_*_After_everything_above_is_done,_merge_the
into_main_branch*_*_After_everything_above_is_done,_merge_the
old_onnx-weekly_packages_on_PyPI*_*_Once_ONNX_has_been_released opset_version_for_ai.onnx*_*_Bump_opset_version_for_ai.onnx_domain
opset_version_for_ai.onnx*_*_Bump_opset_version_for_ai.onnx_domain
Large_models_>2GB TensorProto__data_location_and_external_data_fields
TensorProto__data_location_and_external_data_fields
Xor 💔No_Cover_Common_Operators
SequenceLength_(call_for_test_cases) 💚Covered_Experimental_Operators
zfnet512 Overall_Test_Coverage
Overall_Test_Coverage
Non-goals Terminology
Proposal Symbol_generation_and_propagation
Symbol_generation_and_propagation
Partial_data_computation_and_propagation Special_Cases
Special_Cases
DCO CI_Pipelines
CI_Pipelines
Mac Verify_Installation
Verify_Installation
CMake_variables Common_Errors
Common_Errors Testing
Testing
Eligibility_for_voting Candidacy_process
Candidacy_process
Voting_platform Election_officers_and_Steering_Committee_emeritus_members
Election_officers_and_Steering_Committee_emeritus_members
Member_Companies Organizational_Structure
Organizational_Structure
SIG_-_Special_Interest_Groups
Decision_making WG_-_Working_Groups
WG_-_Working_Groups Repository_Guidelines
Repository_Guidelines
Setting_the_correct_number_of_Workers_for_data_augmentation Installation_instructions
Installation_instructions
from_nnU-Net_v1_can_be_converted_to_V2_by_running Experiment_planning_and_preprocessing
Experiment_planning_and_preprocessing
that_not_all_U-Net_configurations_are_created_for_all_datasets._In 2D_U-Net How_to_get_started?
2D_U-Net
that_the_3D_full_resolution_U-Net_of_the_cascade_requires_the_five Using_multiple_GPUs_for_training
Using_multiple_GPUs_for_training
The_first_time_a_training_is_run_nnU-Net_will_extract_the Automatically_determine_the_best_configuration
Automatically_determine_the_best_configuration
Apply_postprocessing How_to_run_inference_with_pretrained_models
How_to_run_inference_with_pretrained_models
Verify_that_environment_parameters_are_set Windows
Run_trainings How_to_make_predictions_with_pretrained_weights
How_to_make_predictions_with_pretrained_weights
Local_settings Examples
must_share_the_same_geometry_with_their_corresponding Supported_file_formats
Supported_file_formats
How_to_update_an_existing_dataset Example_dataset_conversion_scripts
Example_dataset_conversion_scripts
Pretraining_on_the_source_dataset
The_nnU-Net_default_is_to_perform_'CT'_normalization_for_CT How_to_implement_custom_normalization_strategies?
How_to_implement_custom_normalization_strategies?
is_a_semantic_segmentation_method_that_automatically_adapts_to What_can_nnU-Net_do_for_you?
What_can_nnU-Net_do_for_you?
How_to_get_started?
What_happened_to_the_old_nnU-Net? Acknowledgements
Acknowledgements
Stats_(On_the_development_set) v1.0
Minimal_CK_installation
Install_or_detect_ImageNet_dataset Install_TF
Install_TF
example_is_currently_not_compatible_with_the_latest_MedPerf data_prep prep__Data_Preparation_MLCube surg_prep
data_prep
Get_the_data Run_cube_on_a_local_machine_with_Docker_runner
Run_cube_on_a_local_machine_with_Docker_runner
prep__Data_Preparation_MLCube
Supported_=.json=_File_Structure_ Configuration
Task_=sanity_check= a_csv_file_doesn't_have_a_corresponding_folder_in_the_=frames=_folder,
a_csv_file_doesn't_have_a_corresponding_folder_in_the_=frames=_folder,
surg_prep
Task_=infer= An_output_folder_is_created_(=predictions=)_*_For_each_video,_a_csv
An_output_folder_is_created_(=predictions=)_*_For_each_video,_a_csv
to_the_Broad_Community_* What_is_a_benchmark_in_the_MedPerf_perspective?
What_is_a_benchmark_in_the_MedPerf_perspective?
=additional_files.tar.gz=_(Optional) Preparing_an_MLCube_for_hosting
Preparing_an_MLCube_for_hosting
Direct_download_links_of_files_on_GitHub Synapse_hosting
Synapse_hosting
Docker_or_Singularity Install_MedPerf
Install_MedPerf
Submit_the_MLCube 3._Request_Participation
3._Request_Participation
How_to_proceed_after_requesting_association 4._Execute_the_Benchmark
4._Execute_the_Benchmark
Metrics_MLCube 5._Host_the_Demo_Dataset
5._Host_the_Demo_Dataset
Choose_the_Container_Runner What's_Next?
What's_Next?
Model_MLCube*,_and_the_*Metrics_MLCube*._Each_type_has_a_specific Data_Preparator_MLCube
Data_Preparator_MLCube
Download_the_Necessary_files 1._Train_a_GaNDLF_Model
1._Train_a_GaNDLF_Model
Prepare_your_Dockerfile The_=mlcube=_folder
The_=mlcube=_folder
model_weights Configure_your_MLCube
Configure_your_MLCube Build_your_MLCube
Build_your_MLCube
Add_model_weights Modify_=mlcube.py=
Modify_=mlcube.py=
Run_your_MLCube Using_the_Example_with_GPUs
Using_the_Example_with_GPUs
FeTS_Challenge Pilot_Studies
Pilot_Studies
institutions* 
POC_2_-_Pancreas_Segmentation
POC_3_-_Surgical_Workflow_Phase_Recognition
POC_4_-_Cloud_Experiments
How_to_Use_MedPerf
Prepare_checkpoints Prune_models_and_test_the_accuracy_on_GLUE/SQuAD_benchmarks
Prune_models_and_test_the_accuracy_on_GLUE/SQuAD_benchmarks
Longterm_there_are_no_explicit_restrictions_on_what_devices_can_be References
or_*eval_data//train/*._Note_that_in_MLPerf_Tiny_we Detailed_Usage
Detailed_Usage
Dependency
10*. Software_packages
Software_packages
Push_the_datatsets_to_the_device Now_you_can_launch_the_app,_select_submission_mode_and_press_GO
Now_you_can_launch_the_app,_select_submission_mode_and_press_GO
Calibration_Datasets Quantization
-_Updated_NodeJS_from_v12_to_v16 [[https_//github.com/cla-assistant/github-action/tree/v2.0.1-alpha][v2.0.1-alpha]]
[[https_//github.com/cla-assistant/github-action/tree/v2.0.1-alpha][v2.0.1-alpha]]
Bugs_*_-_Skip_CLA_comment_if_already_commented [[https_//github.com/cla-assistant/github-action/tree/v2.0.0-alpha][v2.0.0-alpha]]
[[https_//github.com/cla-assistant/github-action/tree/v2.0.0-alpha][v2.0.0-alpha]]
-_complete_refactoring_of_all_the_files_to_make_the_bot Bugs_*_-_CLA_check_not_updated_to_success_when_all_the
Bugs_*_-_CLA_check_not_updated_to_success_when_all_the
Issue_Reporting_Disclaimer Contribute_Code
Contribute_Code
Reproduce*_Steps_to_reproduce_the_behavior_
Configure_Contributor_License_Agreement_within_two_minutes
You_do_not_need_to_create_this_file_manually._Our_workflow_will 5._Users_and_bots_in_allowlist
5._Users_and_bots_in_allowlist Environmental_Variables__
Environmental_Variables__
Inputs_Description__ License
Credits
License.*_You_hereby_grant,_and_agree_to_grant,_to_SAP_a License.*_You_hereby_grant,_and_agree_to_grant,_to_SAP_a Rights.*_To_the_fullest_extent_permitted_under_applicable_law,
Rights.*_To_the_fullest_extent_permitted_under_applicable_law,
You_represent_that,_other_than_the_Third_Party To_the_fullest_extent_permitted_under_applicable_law,_your
To_the_fullest_extent_permitted_under_applicable_law,_your Obligation.*_You_acknowledge_that_SAP_is_under_no_obligation_to_use
Obligation.*_You_acknowledge_that_SAP_is_under_no_obligation_to_use
